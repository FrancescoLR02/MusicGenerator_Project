{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c35efb12",
   "metadata": {
    "executionInfo": {
     "elapsed": 16815,
     "status": "ok",
     "timestamp": 1752507170686,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "c35efb12"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn #neural network module\n",
    "import torch.optim as optim #optimizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import time as time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "import gc\n",
    "import os\n",
    "\n",
    "from Preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b90129f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1752507178325,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "b90129f7",
    "outputId": "5f2841eb-b5b9-47ee-d574-d8194664e215"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU available')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print('mps available')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('GPU not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059d7f64",
   "metadata": {
    "id": "059d7f64"
   },
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1977ccbb",
   "metadata": {
    "id": "1977ccbb"
   },
   "outputs": [],
   "source": [
    "datasetpath=os.path.realpath('Dataset_CP.pt')\n",
    "PolDataset = os.path.realpath('PolyphonicDataset.pt')\n",
    "\n",
    "#Loading monophonic and polyphonic classes\n",
    "class MonophonicDataset(Dataset):\n",
    "\n",
    "   def __init__(self, Instruments):\n",
    "\n",
    "      DS = torch.load(datasetpath)\n",
    "      self.Data = []\n",
    "      self.Instruments = Instruments\n",
    "\n",
    "      for inst in Instruments:\n",
    "\n",
    "        RandomData = np.random.choice(DS[inst], int(len(DS[inst])*0.7))\n",
    "        self.Data.extend(RandomData)\n",
    "\n",
    "      del DS\n",
    "      gc.collect()\n",
    "\n",
    "\n",
    "   def __len__(self):\n",
    "      return len(self.Data)\n",
    "\n",
    "   def __getitem__(self, idx):\n",
    "\n",
    "      PreviousBars = self.Data[idx]['Bars'][0].to_dense()\n",
    "      Bars = self.Data[idx]['Bars'][1].to_dense()\n",
    "\n",
    "      prog = self.Data[idx]['Program']\n",
    "      tempo = self.Data[idx]['Tempo'][0]\n",
    "\n",
    "      Cond1D = torch.tensor([tempo, prog], dtype=torch.int, device=Bars.device)\n",
    "      return Bars, PreviousBars, Cond1D\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class PolyphonicDataset(Dataset):\n",
    "\n",
    "   def __init__(self, Genre, EightBars = False):\n",
    "\n",
    "         DS = torch.load(PolDataset, weights_only=False)\n",
    "         self.Data = []\n",
    "         self.Genre = Genre\n",
    "         self.EightBars = EightBars\n",
    "\n",
    "         for gen in Genre:\n",
    "            self.Data.extend(DS[gen])\n",
    "\n",
    "         if self.EightBars:\n",
    "            self.EightDataset = EightBarsDataset(self.Data, Mono = False)\n",
    "\n",
    "         del DS\n",
    "         gc.collect()\n",
    "\n",
    "   def __len__(self):\n",
    "\n",
    "      if self.EightBars:\n",
    "         return len(self.EightDataset)\n",
    "      else:\n",
    "         return len(self.Data)\n",
    "\n",
    "   def __getitem__(self, idx):\n",
    "\n",
    "      if not self.EightBars:\n",
    "\n",
    "         PreviousBars = self.Data[idx]['Bars'][0].to_dense()\n",
    "         Bars = self.Data[idx]['Bars'][1].to_dense()\n",
    "\n",
    "         prog = self.Data[idx]['Program'][0]\n",
    "         tempo = self.Data[idx]['Tempo'][0]\n",
    "\n",
    "         TEMPO_MIN, TEMPO_MAX = 60, 200\n",
    "         PROGRAM_MIN, PROGRAM_MAX = 1, 128\n",
    "\n",
    "         tempo_norm = (tempo - TEMPO_MIN) / (TEMPO_MAX - TEMPO_MIN)\n",
    "         prog_norm = [(p - PROGRAM_MIN) / (PROGRAM_MAX - PROGRAM_MIN) for p in prog]\n",
    "\n",
    "         Cond1D = torch.tensor([tempo_norm] + prog_norm, dtype=torch.float, device=Bars.device)\n",
    "         return Bars, PreviousBars, Cond1D\n",
    "      \n",
    "      else:         \n",
    "         Bars = self.EightDataset[idx]['Bars'].to_dense()\n",
    "         return Bars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45854c0",
   "metadata": {
    "id": "a45854c0"
   },
   "source": [
    "### Concatenation\n",
    "\n",
    "Definition of the concatenation functions that are used in the hidden layers to concatenate the output and the 1_d and 2_d conditions.\n",
    "\n",
    "1_d conditioning vector of shape $[n,1]$ with an output of shape $[batch,features,a,b]$:\n",
    "* first we have to duplicate the vector $a\\cdot b$ times to get a tensor of shape $[batch,n,a,b]$\n",
    "* then we can concatenate the two tensors in the depth dimension (i.e dim=1)\n",
    "\n",
    "2_d conditioning matrix of the same shape of the output $[batch,features,a,b]$ except the depth dim (it must be that because how we build the conditioner CNN):\n",
    "* first we check that the dimensions are correct\n",
    "* we concatenate the two tensors in the depth dimension (i.e dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1acf0ac5",
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1752507185813,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "1acf0ac5"
   },
   "outputs": [],
   "source": [
    "def conv_cond_concat(x, y):\n",
    "    \"\"\"Concatenate conditioning vector on feature map axis.\"\"\"\n",
    "    x_shapes = x.shape  #[batch,n_features,a,b]\n",
    "    y_shapes = y.shape  #[batch,n]\n",
    "    y2 = y.view(x_shapes[0],y_shapes[1],1,1)                              #[batch,n,1,1]\n",
    "    y2 = y2.expand(x_shapes[0],y_shapes[1],x_shapes[2],x_shapes[3])      #[batch,n,a,b]\n",
    "\n",
    "    return torch.cat((x, y2),dim=1)                                     #[batch,n_features+n,a,b]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dae68f7",
   "metadata": {
    "id": "5dae68f7"
   },
   "source": [
    "### The Generator and the Conditioner\n",
    "\n",
    "The generator uses `ConvTranspose2d` (upsampling) layers to produce an image from a seed (random noise). Start with two `Dense` layers that take this seed as input and transform it to a tensor of shape $[batch size,]$, then upsample several times until we reach the desired size of a bar of $[instrument,128,16]$. We use  the `ReLU` activation for each layer, except the output layer which can use `Sigmoid` to predict pixel values in the [0, 1] range.\n",
    "\n",
    "Coupled to the generator there is the conditioner that uses `Conv2d` (sampling) layers to produce the 2_d tensors that serve as informations from the preaviou bar. The conditioner can be viewed as the reverse of the generator because it uses filters with the same shapes of the ones in the generator. In this case we use  the `LeakyReLU` activation for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a88728a6",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752507280126,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "a88728a6"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, cond_1d_size, instrument_size=1, n_hlayers=128):\n",
    "            super().__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.instrument_size = instrument_size\n",
    "            self.cond1d_dim = cond_1d_size\n",
    "            self.nhlayers=n_hlayers\n",
    "\n",
    "            #generator layers\n",
    "            #as said in the DCGAN paper always ReLU ctivation function in the generator excluded the last layer\n",
    "            #as said in the DCGAN paper always batchnorm in the generator excluded the last layer\n",
    "            self.ff1 = nn.Sequential(\n",
    "                nn.Linear(input_size+cond_1d_size, n_hlayers*5*5),                                                                            #[batch,n_hlayers*5*5]\n",
    "                nn.BatchNorm1d(n_hlayers*5*5),\n",
    "                nn.ReLU(inplace=False)\n",
    "                )\n",
    "\n",
    "            #reshape to [batch size,128,5,5]\n",
    "            #+condition [batch,128+cond_1d_size,5,5]\n",
    "            self.cnn1 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size, 128, kernel_size=3, stride=1, bias=False, padding=0),           #[batch,128,7,7]\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU(inplace=False)\n",
    "                )\n",
    "            #+condition [batch,128+cond_1d_size,13,9]\n",
    "            self.cnn2 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(128+cond_1d_size, 64, kernel_size=3, stride=2, bias=False, padding=1),           #[batch,64,13,13]\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(inplace=False)\n",
    "                )\n",
    "            #+condition [batch,64+cond_1d_size,13,13]\n",
    "            self.cnn3h = nn.Sequential(\n",
    "                nn.ConvTranspose2d(64+cond_1d_size, 64, kernel_size=(1,7), stride=(1,3), bias=False, padding=(0,1), output_padding=(0,1)),           #[batch,64,42,13]\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(inplace=False)\n",
    "                )\n",
    "            #+condition [batch,64+cond_1d_size,42,13]\n",
    "            self.cnn3v = nn.Sequential(\n",
    "                nn.ConvTranspose2d(64+cond_1d_size, 64, kernel_size=(7,1), stride=(3,1), bias=False, padding=(1,0), output_padding=(1,0)),           #[batch,64,42,42]\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(inplace=False)\n",
    "                )\n",
    "            #+condition [batch,64+cond_1d_size,42,42]\n",
    "            self.cnn4 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(64+cond_1d_size, instrument_size, kernel_size=5, stride=3, bias=False, padding=0),       #[batch,instrument_size,128,128]\n",
    "                nn.Sigmoid()\n",
    "                #Sigmoid funciotn because we want to generate the matrixes of music without velocity, i.e. only (0,1)\n",
    "                #Thus we use the sigmoid which is a smoother version of the sign function\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, z, cond_1d, batch_size):\n",
    "\n",
    "\n",
    "\n",
    "            #single cond_1d size =[n,1], batch_cond_1d size = [batch_size,n]\n",
    "\n",
    "            input = torch.cat((z,cond_1d), dim=1)   #[batch_size, input_size+cond_1d_size]\n",
    "\n",
    "            h1 = self.ff1(input)                    #[batch,3200]\n",
    "            h1 = h1.reshape(batch_size, self.nhlayers, 5, 5)  #[batch,128,5,5]\n",
    "            h1 = conv_cond_concat(h1,cond_1d)       #[batch,128+cond_1d_size,5,5]\n",
    "\n",
    "\n",
    "            h2 = self.cnn1(h1)                      #[batch,128,7,7]\n",
    "            h2 = conv_cond_concat(h2,cond_1d)       #[batch,128+cond_1d_size,7,7]\n",
    "\n",
    "\n",
    "            h3 = self.cnn2(h2)                      #[batch,64,13,13]\n",
    "            h3 = conv_cond_concat(h3,cond_1d)       #[batch,64+cond_1d_size,13,13]\n",
    "\n",
    "\n",
    "            h4 = self.cnn3h(h3)                     #[batch,64,42,13]\n",
    "            h4 = conv_cond_concat(h4,cond_1d)       #[batch,64+cond_1d_size,42,13]\n",
    "\n",
    "            h5 = self.cnn3v(h4)                     #[batch,64,42,42]\n",
    "            h5 = conv_cond_concat(h5,cond_1d)       #[batch,64+cond_1d_size,42,42]\n",
    "\n",
    "            out = self.cnn4(h5)                     #[batch,instrument_size,128,128]\n",
    "\n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4727b52",
   "metadata": {
    "id": "a4727b52"
   },
   "source": [
    "### The Discriminator\n",
    "\n",
    "The discriminator uses `Conv2d` (sampling) layers to produce a scalar output from a bar input. Start with two `Conv2d` layers that reduce the size of the input, then use two `Dense` layers. We use  the `LeakyReLU` activation for each layer, except the output layer which can use `Sigmoid` to predict true-false probability value in the [0, 1] range. Note that the activation is included in the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6646d974",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1752507397544,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "6646d974"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, cond_1d_size, instrument_size=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.instrument_size = instrument_size\n",
    "        self.cond1d_dim = cond_1d_size\n",
    "\n",
    "        #as said in the DCGAN paper always batchnorm in the discriminator layers excluded the first layer\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(instrument_size+cond_1d_size, 32, kernel_size=5, stride=3, padding=0),        #[batch,32,42,42]\n",
    "            nn.LeakyReLU(inplace=False)\n",
    "        )\n",
    "        #+condition [batch,64+cond_1d_size,42,12]\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv2d(32+cond_1d_size, 64, kernel_size=5, stride=3, padding=1),                       #[batch,64,13,13]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(inplace=False)\n",
    "        )\n",
    "        #+condition [batch,64+cond_1d_size,19,8]\n",
    "        self.cnn3 = nn.Sequential(\n",
    "            nn.Conv2d(64+cond_1d_size, 128, kernel_size=3, stride=2, padding=1),                             #[batch,128,7,7]\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(inplace=False)\n",
    "        )\n",
    "        #+condition [batch,64+cond_1d_size,19,8]\n",
    "        self.cnn4 = nn.Sequential(\n",
    "            nn.Conv2d(128+cond_1d_size, 128, kernel_size=3, stride=2, padding=0),                             #[batch,128,3,3]\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(inplace=False)\n",
    "        )\n",
    "\n",
    "        #+condition [batch,1152+cond_1d_size]\n",
    "        self.ffnn1 = nn.Linear(1152+cond_1d_size, 1)      #no sigmoid activation function because it is already in the definition of the cross entropy loss function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, cond_1d):\n",
    "        input = conv_cond_concat(x,cond_1d)         #[batch,instrument_size+cond_1d_size,128,128]\n",
    "\n",
    "        h0 = self.cnn1(input)                       #[batch,32,42,42]\n",
    "        fm=h0\n",
    "        h0 = conv_cond_concat(h0, cond_1d)          #[batch,32+cond_1d_size,42,42]\n",
    "\n",
    "        h1 = self.cnn2(h0)                          #[batch,64,13,13]\n",
    "        h1 = conv_cond_concat(h1,cond_1d)           #[batch,64+cond_1d_size,13,13]\n",
    "\n",
    "        h2 = self.cnn3(h1)                          #[batch,128,7,7]\n",
    "        h2 = conv_cond_concat(h2,cond_1d)           #[batch,128+cond_1d_size,7,7]\n",
    "\n",
    "        h3 = self.cnn4(h2)                          #[batch,128,3,3]\n",
    "        h3 = torch.flatten(h3, 1)                   #[batch,1152]\n",
    "        h3 = torch.cat((h3,cond_1d),dim=1)          #[batch,1152+cond_1d_size]\n",
    "\n",
    "        h4 = self.ffnn1(h3)                         #[batch,1]\n",
    "        h4_sigmoid = torch.sigmoid(h4)\n",
    "\n",
    "\n",
    "        return h4_sigmoid, h4, fm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d02a387",
   "metadata": {
    "id": "8d02a387"
   },
   "source": [
    "### Weights initialization\n",
    "\n",
    "Is this ok?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9237a67a",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752507354824,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "9237a67a"
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.2)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9059e917",
   "metadata": {
    "id": "9059e917"
   },
   "source": [
    "### Creation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64e61f6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1752507336458,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "64e61f6a",
    "outputId": "fb59ae91-ccfd-49b0-ceb6-216842939804"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (ff1): Sequential(\n",
       "    (0): Linear(in_features=105, out_features=3200, bias=True)\n",
       "    (1): BatchNorm1d(3200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (cnn1): Sequential(\n",
       "    (0): ConvTranspose2d(133, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (cnn2): Sequential(\n",
       "    (0): ConvTranspose2d(133, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (cnn3h): Sequential(\n",
       "    (0): ConvTranspose2d(69, 64, kernel_size=(1, 7), stride=(1, 3), padding=(0, 1), output_padding=(0, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (cnn3v): Sequential(\n",
       "    (0): ConvTranspose2d(69, 64, kernel_size=(7, 1), stride=(3, 1), padding=(1, 0), output_padding=(1, 0), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (cnn4): Sequential(\n",
       "    (0): ConvTranspose2d(69, 4, kernel_size=(5, 5), stride=(3, 3), bias=False)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator(input_size=100, cond_1d_size=5, instrument_size=4, n_hlayers=128)\n",
    "generator.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "307a37f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1752507401305,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "307a37f6",
    "outputId": "d53115e0-31cc-49c2-a511-92efd0cc551a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (cnn1): Sequential(\n",
       "    (0): Conv2d(9, 32, kernel_size=(5, 5), stride=(3, 3))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (cnn2): Sequential(\n",
       "    (0): Conv2d(37, 64, kernel_size=(5, 5), stride=(3, 3), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (cnn3): Sequential(\n",
       "    (0): Conv2d(69, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (cnn4): Sequential(\n",
       "    (0): Conv2d(133, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (ffnn1): Linear(in_features=1157, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = Discriminator(cond_1d_size=5, instrument_size=4)\n",
    "discriminator.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a4dac3",
   "metadata": {
    "id": "d6a4dac3"
   },
   "source": [
    "### Dimension testing\n",
    "\n",
    "Produce a noise vector of size `[10, 100]`, a noise 1d condition vector of size `[10, 15]`, and a noise 2d condition tensor of size `[10, 1, 128,16]`. Note that we need a 1d and a 2d contions for each batch input. Then we use the (as yet **untrained**) generator to create an image of expected output shape $[10,1,128,16]$.\n",
    "\n",
    "Then use the (yet **untrained**) discriminator to classify the generated images as real or fake. The model will be trained to output the probability that the image is real in the first output component, thus we expect an output vector of size `[10, 1]` with $x_i \\in [0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4075ff07",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1752507435372,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "4075ff07",
    "outputId": "2d1e6c3c-df32-4a9a-a562-54957ecbfe06"
   },
   "outputs": [],
   "source": [
    "# ############################ input (batch_size=10, vector_size=100) ###############################\n",
    "# noise = torch.normal(0, 1, [50, 100])\n",
    "# print(noise.shape)\n",
    "# ############################ conditions ###############################\n",
    "# cond_1d =  torch.normal(0,1,[50,2])\n",
    "# ############################ generator ###############################\n",
    "# generated_bar = generator(noise, cond_1d, batch_size=50).detach()\n",
    "# print(generated_bar.shape)\n",
    "# ############################ discriminator ###############################\n",
    "# decision, __, __= discriminator(generated_bar, cond_1d)\n",
    "# print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cf78a3",
   "metadata": {
    "id": "26cf78a3"
   },
   "source": [
    "### Discriminator loss\n",
    "\n",
    "This method quantifies how well the discriminator is able to distinguish real images from fakes. It compares the discriminator's predictions on real images to an array of 1s, and the discriminator's predictions on fake (generated) images to an array of 0s.\n",
    "The discriminator loss is of the form:\n",
    "\n",
    "$\\frac{1}{m}\\sum_{i=1}^{m}-[\\log D(\\boldsymbol{x}^{(i)}) +\\log(1-D(G(\\boldsymbol{z}^{(i)})))]$\n",
    "\n",
    "We inplement one-sided label smoothing to penalize self confidence and imporve the convergence of the training. Thus we substitute the discriminator's predictions on real images to an array of 1s with an array of (1-$\\alpha$)s and the loss function becomes:\n",
    "\n",
    "$\\frac{1}{m}\\sum_{i=1}^{m}-[(1-\\alpha) \\log D(\\boldsymbol{x}^{(i)}) +\\alpha \\log (1-D(\\boldsymbol{x}^{(i)}))+\\log(1-D(G(\\boldsymbol{z}^{(i)})))]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa9329bd",
   "metadata": {
    "id": "fa9329bd"
   },
   "outputs": [],
   "source": [
    "cross_entropy = nn.BCEWithLogitsLoss()\n",
    "MSE=nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "778a6afc",
   "metadata": {
    "id": "778a6afc"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output, device, alpha=0.1):\n",
    "\n",
    "    #real_targets = torch.ones_like(real_output, device=device)                 #no label smoothing -> True output expected output is 1\n",
    "    real_targets = torch.full_like(real_output, 1.0 - alpha, device=device)     #one side label smoothing to penalize self confidence\n",
    "    fake_targets = torch.zeros_like(fake_output, device=device)                 #no label smoothing -> Fake output expected output is 0\n",
    "\n",
    "    real_loss = cross_entropy(real_output, real_targets)\n",
    "    fake_loss = cross_entropy(fake_output, fake_targets)\n",
    "\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04bd362",
   "metadata": {
    "id": "f04bd362"
   },
   "source": [
    "### Generator loss\n",
    "\n",
    "The generator's loss quantifies how well it was able to trick the discriminator. Intuitively, if the generator is performing well, the discriminator will classify the fake images as real (or 1).\n",
    "The generator loss is of the form:\n",
    "\n",
    "$\\frac{1}{m}\\sum_{i=1}^{m}\\log(1-D(G(\\boldsymbol{z}^{(i)})))$\n",
    "\n",
    "However this loss has some convergence issues due to vanishing gradients. So instead we use the following loss which has the same trend but stronger gradient when the discriminator is too good at recognizing fake samples.\n",
    "\n",
    "$\\frac{1}{m}\\sum_{i=1}^{m}-\\log(D(G(\\boldsymbol{z}^{(i)})))$\n",
    "\n",
    "Which is the Binary crossentropy between $D(G(\\boldsymbol{z}^{(i)}))$ and the probability distribution that has $y^{(i)} = 1 \\forall i$, i.e. we are forcing the generator to produce samples that will make the discriminator predict that fake samples are real.\n",
    "\n",
    "Moreover we add a regularizer term so-called feature matching such that the distributions of the real and generated data are enforced to be close.\n",
    "\n",
    "$\\lambda_1 ||E_{x \\sim p(x)} [x] - E_{z\\sim p(z)} [G(z)] ||^2 + \\lambda_2 ||E_{x \\sim p(x)} [f(x)] - E_{z \\sim p(z)} [f(G(z))] ||^2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "367712ab",
   "metadata": {
    "id": "367712ab"
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output, real_bar, fake_bar, real_f, fake_f, device, lambda1=0.01, lambda2=0.01):\n",
    "\n",
    "    gen_loss = cross_entropy(fake_output, torch.ones_like(fake_output, device=device))\n",
    "\n",
    "    mean_real = torch.mean(real_bar, dim=0, dtype=torch.float)\n",
    "    mean_fake = torch.mean(fake_bar, dim=0, dtype=torch.float)\n",
    "    l2_data = MSE(mean_real, mean_fake)\n",
    "\n",
    "    mean_real_feat = torch.mean(real_f, dim=0, dtype=torch.float)\n",
    "    mean_fake_feat = torch.mean(fake_f, dim=0, dtype=torch.float)\n",
    "    l2_feat = MSE(mean_real_feat, mean_fake_feat)\n",
    "\n",
    "    return gen_loss+lambda1*l2_data+lambda2*l2_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873c39af",
   "metadata": {
    "id": "873c39af"
   },
   "source": [
    "### Optimizers\n",
    "\n",
    "With DCGAN the training is very diffuclt so we decide to use Adam optimizer as suggested by the paper. Note that with Adam we use both momentum and RMSprop to normalized velocities. Discriminator and generator need two different optimizers (conditioner is included in the generator training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3bc9be6",
   "metadata": {
    "id": "e3bc9be6"
   },
   "outputs": [],
   "source": [
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "gen_opt = optim.Adam(generator.parameters(), lr=2e-4)\n",
    "dis_opt = optim.Adam(discriminator.parameters(), lr=2e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a476d",
   "metadata": {
    "id": "5c2a476d"
   },
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b61b71e9",
   "metadata": {
    "id": "b61b71e9"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "noise_dim = 100\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "\n",
    "Data = PolyphonicDataset(Genre=['rock'], EightBars = True)\n",
    "dataloader = DataLoader(Data, BATCH_SIZE, shuffle=True, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02958e21",
   "metadata": {
    "id": "02958e21"
   },
   "outputs": [],
   "source": [
    "def train_step(bars, cond_1d, generator, discriminator, batch_size, noise_dim, device, dis_opt, gen_opt):\n",
    "   noise = torch.randn([batch_size, noise_dim], device=device)\n",
    "\n",
    "   # Generate Images\n",
    "   generated_bars = generator(noise, cond_1d, batch_size)\n",
    "\n",
    "   # Train Discriminator\n",
    "   # Classify true and fake images (detach fake images for discriminator training)\n",
    "   output, D, fm = discriminator(bars, cond_1d)\n",
    "   fake_output, fake_D, fake_fm = discriminator(generated_bars.detach(), cond_1d)\n",
    "\n",
    "   # Compute discriminator loss and update discriminator\n",
    "   disc_loss = discriminator_loss(D, fake_D, device)\n",
    "   discriminator.zero_grad()\n",
    "   disc_loss.backward()\n",
    "   dis_opt.step()\n",
    "\n",
    "   # Train Generator\n",
    "   # Get fresh feature maps for generator training (both real and fake)\n",
    "   real_output, real_D, real_fm = discriminator(bars, cond_1d)\n",
    "   fake_output, fake_D, fake_fm = discriminator(generated_bars, cond_1d)\n",
    "\n",
    "   # Compute generator loss and update generator\n",
    "   gen_loss = generator_loss(fake_D, bars, generated_bars, real_fm, fake_fm, device)\n",
    "   generator.zero_grad()\n",
    "   gen_loss.backward()\n",
    "   gen_opt.step()\n",
    "\n",
    "   return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3313e656",
   "metadata": {
    "id": "3313e656"
   },
   "source": [
    "supponendo che nel dataloader ogni dato sia una bar + la preavious bar + 1d condition sugli strumenti utilizzati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a670270f",
   "metadata": {
    "id": "a670270f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator loss: 0.3417219817638397, Generator loss: 6.015914440155029: 100%|██████████| 54/54 [00:11<00:00,  4.57it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 1 is 11.832403898239136 sec\n",
      "#################\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator loss: 0.3335947096347809, Generator loss: 6.328534126281738: 100%|██████████| 54/54 [00:09<00:00,  5.43it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 2 is 9.94576096534729 sec\n",
      "#################\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator loss: 0.3323092460632324, Generator loss: 6.547445774078369:  63%|██████▎   | 34/54 [00:06<00:03,  5.24it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m instrument_batch \u001b[38;5;241m=\u001b[39m instrument_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     22\u001b[0m gen_loss, disc_loss \u001b[38;5;241m=\u001b[39m train_step(bar_batch, instrument_batch, generator, discriminator, BATCH_SIZE, noise_dim, device, dis_opt, gen_opt)\n\u001b[0;32m---> 23\u001b[0m gen_losses\u001b[38;5;241m.\u001b[39mappend(gen_loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     24\u001b[0m disc_losses\u001b[38;5;241m.\u001b[39mappend(disc_loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     26\u001b[0m iterator\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiscriminator loss: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Generator loss: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(disc_loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(),gen_loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gloss = []\n",
    "dloss = []\n",
    "cond_1d = torch.normal(0,1,[BATCH_SIZE,5])\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    start = time.time()\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    gen_losses = []\n",
    "    disc_losses = []\n",
    "    print('#################')\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "\n",
    "    iterator = tqdm(dataloader)\n",
    "    for bar_batch in iterator:\n",
    "        bar_batch = bar_batch.to(device)\n",
    "        #prev_bar_batch = prev_bar_batch.to(device)\n",
    "        instrument_batch = torch.zeros_like(cond_1d)\n",
    "        instrument_batch = instrument_batch.to(device)\n",
    "\n",
    "        gen_loss, disc_loss = train_step(bar_batch, instrument_batch, generator, discriminator, BATCH_SIZE, noise_dim, device, dis_opt, gen_opt)\n",
    "        gen_losses.append(gen_loss.detach().cpu().numpy())\n",
    "        disc_losses.append(disc_loss.detach().cpu().numpy())\n",
    "\n",
    "        iterator.set_description('Discriminator loss: {}, Generator loss: {}'.format(disc_loss.detach().cpu().numpy(),gen_loss.detach().cpu().numpy()))\n",
    "\n",
    "    gloss.append(np.mean(gen_losses))\n",
    "    dloss.append(np.mean(disc_losses))\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60125f78",
   "metadata": {
    "id": "60125f78"
   },
   "source": [
    "### Weights and loss analysis\n",
    "\n",
    "First let's plot the 2 losses over the epochs, if it works correctly the generator loss would have to decrease and the discriminator one would have to increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a427ac8",
   "metadata": {
    "id": "1a427ac8"
   },
   "outputs": [],
   "source": [
    "plt.plot(gloss, label='Generator loss')\n",
    "plt.plot(dloss, label='Discriminator loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6bd62a",
   "metadata": {
    "id": "2a6bd62a"
   },
   "source": [
    "Then we can analyze the weights distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8287f8",
   "metadata": {
    "id": "2c8287f8"
   },
   "outputs": [],
   "source": [
    "# First hidden layer\n",
    "h1_w = net.fc1.weight.data.cpu().numpy()\n",
    "h1_b = net.fc1.bias.data.cpu().numpy()\n",
    "\n",
    "# Second hidden layer\n",
    "h2_w = net.fc2.weight.data.cpu().numpy()\n",
    "h2_b = net.fc2.bias.data.cpu().numpy()\n",
    "\n",
    "# Output layer\n",
    "out_w = net.out.weight.data.cpu().numpy()\n",
    "out_b = net.out.bias.data.cpu().numpy()\n",
    "\n",
    "# Weights histogram\n",
    "fig, axs = plt.subplots(3, 1, figsize=(12,8))\n",
    "axs[0].hist(h1_w.flatten(), 50)\n",
    "axs[0].set_title('First hidden layer weights')\n",
    "axs[1].hist(h2_w.flatten(), 50)\n",
    "axs[1].set_title('Second hidden layer weights')\n",
    "axs[2].hist(out_w.flatten(), 50)\n",
    "axs[2].set_title('Output layer weights')\n",
    "[ax.grid() for ax in axs]\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa3c488",
   "metadata": {
    "id": "5fa3c488"
   },
   "outputs": [],
   "source": [
    "# lo avevmo fatto nel lab2 forse adesso un po' complicato visto che come input abbiamo un vettore con 100 componenti\n",
    "\n",
    "def get_activation(layer, input, output):\n",
    "    global activation\n",
    "    activation = torch.sigmoid(output)\n",
    "\n",
    "### Register hook\n",
    "hook_handle = generator.cnn1.register_forward_hook(get_activation)\n",
    "\n",
    "### Analyze activations\n",
    "generator = generator.to(device)\n",
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    x1 = torch.tensor([0.1]).float().to(device)\n",
    "    y1 = net(x1)\n",
    "    z1 = activation\n",
    "    x2 = torch.tensor([0.9]).float().to(device)\n",
    "    y2 = net(x2)\n",
    "    z2 = activation\n",
    "    x3 = torch.tensor([2.5]).float().to(device)\n",
    "    y3 = net(x3)\n",
    "    z3 = activation\n",
    "\n",
    "### Remove hook\n",
    "hook_handle.remove()\n",
    "\n",
    "### Plot activations\n",
    "fig, axs = plt.subplots(3, 1, figsize=(12,6))\n",
    "axs[0].stem(z1.cpu().numpy())\n",
    "axs[0].set_title('Last layer activations for input x=%.2f' % x1)\n",
    "axs[1].stem(z2.cpu().numpy())\n",
    "axs[1].set_title('Last layer activations for input x=%.2f' % x2)\n",
    "axs[2].stem(z3.cpu().numpy())\n",
    "axs[2].set_title('Last layer activations for input x=%.2f' % x3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a2cae3",
   "metadata": {
    "id": "24a2cae3"
   },
   "source": [
    "#### Generator output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d0b9bd",
   "metadata": {
    "id": "66d0b9bd"
   },
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "noise = torch.randn([1, noise_dim], device=device)\n",
    "instrument =\n",
    "prev_bar =\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "   generated_bar = generator(noise, prev_bar, instrument, 1)\n",
    "\n",
    "generated_bar=generated_bar.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f70a8b",
   "metadata": {
    "id": "51f70a8b"
   },
   "source": [
    "Save networks and optimizers states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c479e2c",
   "metadata": {
    "id": "4c479e2c"
   },
   "outputs": [],
   "source": [
    "torch.save(discriminator.state_dict(), 'discriminator_parameters.torch')\n",
    "torch.save(generator.state_dict(), 'generator_parameters.torch')\n",
    "print('Saved Model')\n",
    "\n",
    "torch.save(dis_opt.state_dict(), 'dis_opt_state.torch')\n",
    "torch.save(gen_opt.state_dict(), 'gen_opt_state.torch')\n",
    "print('Saved Optimizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6ea829",
   "metadata": {
    "id": "cb6ea829"
   },
   "source": [
    "Reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20674212",
   "metadata": {
    "id": "20674212"
   },
   "outputs": [],
   "source": [
    "discriminator = Discriminator(input_size=100, cond_1d_size=15, instrument_size=1)\n",
    "discriminator.apply(weights_init)\n",
    "discriminator.to(device)\n",
    "# Load the state dict previously saved\n",
    "discriminator_state_dict = torch.load('discriminator_parameters.torch')\n",
    "# Update the network parameters\n",
    "discriminator.load_state_dict(discriminator_state_dict)\n",
    "\n",
    "generator = Generator(input_size=100, cond_1d_size=15, instrument_size=1, n_hlayers=128)\n",
    "generator.apply(weights_init)\n",
    "generator.to(device)\n",
    "# Load the state dict previously saved\n",
    "generator_state_dict = torch.load('generator_parameters.torch')\n",
    "# Update the network parameters\n",
    "generator.load_state_dict(generator_state_dict)\n",
    "\n",
    "\n",
    "dis_opt = optim.Adam(discriminator.parameters(), lr=2e-4)\n",
    "# Load the state dict previously saved\n",
    "dis_opt_state_dict = torch.load('dis_opt_state.torch')\n",
    "# Update the network parameters\n",
    "dis_opt.load_state_dict(dis_opt_state_dict)\n",
    "\n",
    "gen_opt = optim.Adam(generator.parameters(), lr=2e-4)\n",
    "# Load the state dict previously saved\n",
    "gen_opt_state_dict = torch.load('gen_opt_state.torch')\n",
    "# Update the network parameters\n",
    "gen_opt.load_state_dict(gen_opt_state_dict)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
