{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36ae9d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn #neural network module\n",
    "import torch.optim as optim #optimizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import time as time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aaea092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_prev_concat(x, y):\n",
    "    if x is None or y is None:\n",
    "      raise ValueError(\"x or prev_bar is None\")\n",
    "    \"\"\"Concatenate conditioning vector on feature map axis.\"\"\"\n",
    "    x_shapes = x.shape  #[batch,n_features,a,b]\n",
    "    y_shapes = y.shape  #[batch,16,a,b]\n",
    "\n",
    "    if x_shapes[2:] == y_shapes[2:]:\n",
    "        return torch.cat((x, y),dim=1)                                 #[batch,n_features+16,a,b]\n",
    "\n",
    "    else:\n",
    "        print(x_shapes[2:])\n",
    "        print(y_shapes[2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a82ea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, instrument_size=1, n_hlayers=128):\n",
    "            super().__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.instrument_size = instrument_size\n",
    "\n",
    "            #generator layers\n",
    "            #as said in the DCGAN paper always ReLU activation function in the generator excluded the last layer\n",
    "            #as said in the DCGAN paper always batchnorm iin the generator excluded the last layer\n",
    "            self.ff1 = nn.Sequential(\n",
    "                nn.Linear(input_size, 1024),                                                               #[batch,1024]\n",
    "                #nn.BatchNorm1d(1024),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            self.ff2 = nn.Sequential(\n",
    "                nn.Linear(1024,n_hlayers*2),                                                               #[batch,256]\n",
    "                #nn.BatchNorm1d(n_hlayers*2),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #reshape to [batch size,128,1,2]\n",
    "            #+condition 2d [batch,128+16,1,2]\n",
    "            self.cnn1 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,4]\n",
    "                #nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition 2d [batch,128+16,1,2]\n",
    "            self.cnn2 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,8]\n",
    "                #nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition 2d [batch,128+16,1,2]\n",
    "            self.cnn3 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,16]\n",
    "                #nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition 2d [batch,128+16,1,2]\n",
    "            self.cnn4 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+16, instrument_size, kernel_size=(128,1), stride=(2,1), bias=False, padding=0),       #[batch,instrument_size,128,16]\n",
    "                nn.Sigmoid()\n",
    "                #Sigmoid funciotn because we want to generate the matrixes of music without velocity, i.e. only (0,1)\n",
    "                #Thus we use the sigmoid which is a smoother version of the sign function\n",
    "                )\n",
    "            #conditioner layers\n",
    "            #as in Midinet model we use the Leaky activation funciton for the conditioner\n",
    "            self.h0_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=instrument_size, out_channels=16, kernel_size=(128,1), stride=(2,1)),                  #[batch,16,1,16]\n",
    "                #nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU(0.2)          #note: in the original paper leak=0.2, default leak=0.01\n",
    "                )\n",
    "            self.h1_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,8]\n",
    "                #nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU(0.2)\n",
    "                )\n",
    "            self.h2_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,4]\n",
    "                #nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU(0.2)\n",
    "                )\n",
    "            self.h3_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,2]\n",
    "                #nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU(0.2)\n",
    "                )\n",
    "\n",
    "    def forward(self, z, prev_bar, batch_size):\n",
    "\n",
    "            #2d condition\n",
    "            cond0 = self.h0_prev(prev_bar)          #[batch,16,1,16]\n",
    "            cond1 = self.h1_prev(cond0)             #[batch,16,1,8]\n",
    "            cond2 = self.h2_prev(cond1)             #[batch,16,1,4]\n",
    "            cond3 = self.h3_prev(cond2)             #[batch,16,1,2]\n",
    "\n",
    "\n",
    "\n",
    "            h0 = self.ff1(z)                        #[batch,1024]\n",
    "\n",
    "            h1 = self.ff2(h0)                       #[batch,256]\n",
    "            h1 = h1.reshape(batch_size, 128, 1, 2)  #[batch,128,1,2]\n",
    "            h1 = conv_prev_concat(h1,cond3)         #[batch,128+16,1,2]\n",
    "\n",
    "            h2 = self.cnn1(h1)                      #[batch,128,1,4]\n",
    "            h2 = conv_prev_concat(h2,cond2)         #[batch,128+16,1,4]\n",
    "\n",
    "            h3 = self.cnn2(h2)                      #[batch,128,1,8]\n",
    "            h3 = conv_prev_concat(h3,cond1)         #[batch,128+16,1,8]\n",
    "\n",
    "            h4 = self.cnn3(h3)                      #[batch,128,1,16]\n",
    "            h4 = conv_prev_concat(h4,cond0)         #[batch,128+16,1,16]\n",
    "\n",
    "            out = self.cnn4(h4)                     #[batch,instrument_size,128,16]\n",
    "\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab6b0218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.2)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "652fde5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Generator:\n\tUnexpected key(s) in state_dict: \"ff1.1.weight\", \"ff1.1.bias\", \"ff1.1.running_mean\", \"ff1.1.running_var\", \"ff1.1.num_batches_tracked\", \"ff2.1.weight\", \"ff2.1.bias\", \"ff2.1.running_mean\", \"ff2.1.running_var\", \"ff2.1.num_batches_tracked\", \"cnn1.1.weight\", \"cnn1.1.bias\", \"cnn1.1.running_mean\", \"cnn1.1.running_var\", \"cnn1.1.num_batches_tracked\", \"cnn2.1.weight\", \"cnn2.1.bias\", \"cnn2.1.running_mean\", \"cnn2.1.running_var\", \"cnn2.1.num_batches_tracked\", \"cnn3.1.weight\", \"cnn3.1.bias\", \"cnn3.1.running_mean\", \"cnn3.1.running_var\", \"cnn3.1.num_batches_tracked\", \"h0_prev.1.weight\", \"h0_prev.1.bias\", \"h0_prev.1.running_mean\", \"h0_prev.1.running_var\", \"h0_prev.1.num_batches_tracked\", \"h1_prev.1.weight\", \"h1_prev.1.bias\", \"h1_prev.1.running_mean\", \"h1_prev.1.running_var\", \"h1_prev.1.num_batches_tracked\", \"h2_prev.1.weight\", \"h2_prev.1.bias\", \"h2_prev.1.running_mean\", \"h2_prev.1.running_var\", \"h2_prev.1.num_batches_tracked\", \"h3_prev.1.weight\", \"h3_prev.1.bias\", \"h3_prev.1.running_mean\", \"h3_prev.1.running_var\", \"h3_prev.1.num_batches_tracked\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generator\n\u001b[1;32m     34\u001b[0m                                                     \u001b[38;5;66;03m#MOnophonic or polyphonic\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m generator \u001b[38;5;241m=\u001b[39m LoadModel(instrumentSize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, Which\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 24\u001b[0m, in \u001b[0;36mLoadModel\u001b[0;34m(instrumentSize, Which)\u001b[0m\n\u001b[1;32m     22\u001b[0m generator_state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(Path, files[Which][\u001b[38;5;241m0\u001b[39m]), map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Update the network parameters\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m generator\u001b[38;5;241m.\u001b[39mload_state_dict(generator_state_dict)\n\u001b[1;32m     26\u001b[0m gen_opt \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(generator\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-4\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Load the state dict previously saved\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:2581\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2573\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2574\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2575\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2576\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2577\u001b[0m             ),\n\u001b[1;32m   2578\u001b[0m         )\n\u001b[1;32m   2580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2583\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2584\u001b[0m         )\n\u001b[1;32m   2585\u001b[0m     )\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Generator:\n\tUnexpected key(s) in state_dict: \"ff1.1.weight\", \"ff1.1.bias\", \"ff1.1.running_mean\", \"ff1.1.running_var\", \"ff1.1.num_batches_tracked\", \"ff2.1.weight\", \"ff2.1.bias\", \"ff2.1.running_mean\", \"ff2.1.running_var\", \"ff2.1.num_batches_tracked\", \"cnn1.1.weight\", \"cnn1.1.bias\", \"cnn1.1.running_mean\", \"cnn1.1.running_var\", \"cnn1.1.num_batches_tracked\", \"cnn2.1.weight\", \"cnn2.1.bias\", \"cnn2.1.running_mean\", \"cnn2.1.running_var\", \"cnn2.1.num_batches_tracked\", \"cnn3.1.weight\", \"cnn3.1.bias\", \"cnn3.1.running_mean\", \"cnn3.1.running_var\", \"cnn3.1.num_batches_tracked\", \"h0_prev.1.weight\", \"h0_prev.1.bias\", \"h0_prev.1.running_mean\", \"h0_prev.1.running_var\", \"h0_prev.1.num_batches_tracked\", \"h1_prev.1.weight\", \"h1_prev.1.bias\", \"h1_prev.1.running_mean\", \"h1_prev.1.running_var\", \"h1_prev.1.num_batches_tracked\", \"h2_prev.1.weight\", \"h2_prev.1.bias\", \"h2_prev.1.running_mean\", \"h2_prev.1.running_var\", \"h2_prev.1.num_batches_tracked\", \"h3_prev.1.weight\", \"h3_prev.1.bias\", \"h3_prev.1.running_mean\", \"h3_prev.1.running_var\", \"h3_prev.1.num_batches_tracked\". "
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU available')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('GPU not available')\n",
    "\n",
    "\n",
    "def LoadModel(instrumentSize, Which):\n",
    "\n",
    "    Path = os.path.realpath('ModelParameters')\n",
    "\n",
    "    files = [\n",
    "        ['generator_no1d7-2.torch', 'gen_opt_state_no1d7-2.torch'],\n",
    "        ['generator_no1d2.torch', 'gen_opt_state_no1d2.torch']\n",
    "    ]\n",
    "\n",
    "    generator = Generator(input_size=100, instrument_size=instrumentSize, n_hlayers=128)\n",
    "    generator.apply(weights_init)\n",
    "    generator.to(device)\n",
    "    # Load the state dict previously saved\n",
    "    generator_state_dict = torch.load(os.path.join(Path, files[Which][0]), map_location=torch.device('cpu'))\n",
    "    # Update the network parameters\n",
    "    generator.load_state_dict(generator_state_dict)\n",
    "\n",
    "    gen_opt = optim.Adam(generator.parameters(), lr=2e-4)\n",
    "    # Load the state dict previously saved\n",
    "    gen_opt_state_dict = torch.load(os.path.join(Path, files[Which][1]), map_location=torch.device('cpu'))\n",
    "    # Update the network parameters\n",
    "    gen_opt.load_state_dict(gen_opt_state_dict)\n",
    "\n",
    "    return generator\n",
    "\n",
    "                                                    #MOnophonic or polyphonic\n",
    "generator = LoadModel(instrumentSize=1, Which=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f2aa628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:  70%|███████   | 35/50 [00:04<00:01,  8.03it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 2\u001b[0m Dataset \u001b[38;5;241m=\u001b[39m PreProcessing(nDir \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Università/PhysicsOfData/Neural Network and Deep Learning/MusicGenerator_Project/Preprocessing.py:328\u001b[0m, in \u001b[0;36mPreProcessing\u001b[0;34m(nDir, Velocity)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogFolder/Debug.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    326\u001b[0m    f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mdir\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 328\u001b[0m mid \u001b[38;5;241m=\u001b[39m Func_CorruptedFile(FilePath, file, \u001b[38;5;28mdir\u001b[39m)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mid \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    331\u001b[0m    \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Università/PhysicsOfData/Neural Network and Deep Learning/MusicGenerator_Project/Preprocessing.py:72\u001b[0m, in \u001b[0;36mFunc_CorruptedFile\u001b[0;34m(FilePath, file, dir, LogFolder)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mFunc_CorruptedFile\u001b[39m(FilePath, file, \u001b[38;5;28mdir\u001b[39m, LogFolder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogFolder\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m     71\u001b[0m    \u001b[38;5;28;01mtry\u001b[39;00m :\n\u001b[0;32m---> 72\u001b[0m       mid \u001b[38;5;241m=\u001b[39m mido\u001b[38;5;241m.\u001b[39mMidiFile(FilePath)\n\u001b[1;32m     73\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m mid\n\u001b[1;32m     75\u001b[0m    \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m, KeySignatureError, \u001b[38;5;167;01mEOFError\u001b[39;00m, \u001b[38;5;167;01mIndexError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/mido/midifiles/midifiles.py:320\u001b[0m, in \u001b[0;36mMidiFile.__init__\u001b[0;34m(self, filename, file, type, ticks_per_beat, charset, debug, clip, tracks)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m--> 320\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load(file)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/mido/midifiles/midifiles.py:371\u001b[0m, in \u001b[0;36mMidiFile._load\u001b[0;34m(self, infile)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m    369\u001b[0m     _dbg(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrack \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracks\u001b[38;5;241m.\u001b[39mappend(read_track(infile,\n\u001b[1;32m    372\u001b[0m                               debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug,\n\u001b[1;32m    373\u001b[0m                               clip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/mido/midifiles/midifiles.py:198\u001b[0m, in \u001b[0;36mread_track\u001b[0;34m(infile, debug, clip)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m debug:\n\u001b[1;32m    196\u001b[0m     _dbg(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-> delta=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelta\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 198\u001b[0m status_byte \u001b[38;5;241m=\u001b[39m read_byte(infile)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status_byte \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0x80\u001b[39m:\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m last_status \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/mido/midifiles/midifiles.py:65\u001b[0m, in \u001b[0;36mread_byte\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtell\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_byte\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     66\u001b[0m     byte \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m byte \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from Preprocessing import *\n",
    "Dataset = PreProcessing(nDir = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1236150e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01347965095192194 0.055734749883413315\n",
      "0.014046840369701385 0.060140207409858704\n",
      "0.013673161156475544 0.0596754290163517\n",
      "0.013621464371681213 0.060238827019929886\n",
      "0.013456868007779121 0.06185677647590637\n",
      "0.013504620641469955 0.06092710793018341\n",
      "0.013615358620882034 0.06156109645962715\n",
      "0.013608302921056747 0.061391692608594894\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "generator.eval()\n",
    "\n",
    "Instrument = 'Piano'\n",
    "bar = np.random.randint(0, 100)\n",
    "\n",
    "prev_bar = Dataset[Instrument][bar]['Bars'][0].to_dense().float().to(device)\n",
    "InstrumentCode = Dataset[Instrument][bar]['Program']\n",
    "Tempo = Dataset[Instrument][bar]['Tempo'][0]\n",
    "\n",
    "Bars = []\n",
    "Bars.append(prev_bar)\n",
    "#If polyphonic only 1 unsqueeze\n",
    "prev_bar = prev_bar.unsqueeze(0).unsqueeze(0) \n",
    "\n",
    "\n",
    "for i in range(8):\n",
    "   noise = torch.rand([1, 100], device=device)*0.2\n",
    "\n",
    "   #print(np.mean(np.array(noise)))\n",
    "\n",
    "   with torch.no_grad():\n",
    "      generated_bar = generator(noise, prev_bar, 1)\n",
    "\n",
    "   binary_bar = (generated_bar > 0.7).float()  # still a tensor\n",
    "   Bars.append(binary_bar.squeeze(0).squeeze(0).cpu().numpy())  # only now for MIDI\n",
    "   print(generated_bar.mean().item(), generated_bar.std().item())\n",
    "   prev_bar = binary_bar.detach()\n",
    "\n",
    "\n",
    "\n",
    "PolyConcBars = np.concatenate(Bars, axis = 1)\n",
    "\n",
    "MonoBarsToMIDI(PolyConcBars, title='No1DCond', Instrument=InstrumentCode)\n",
    "\n",
    "print(InstrumentCode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a2df27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Bars[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc4c5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b483dcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
