{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ae9d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn #neural network module\n",
    "import torch.optim as optim #optimizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import time as time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "import gc\n",
    "import os\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aaea092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_prev_concat(x, y):\n",
    "    if x is None or y is None:\n",
    "      raise ValueError(\"x or prev_bar is None\")\n",
    "    \"\"\"Concatenate conditioning vector on feature map axis.\"\"\"\n",
    "    x_shapes = x.shape  #[batch,n_features,a,b]\n",
    "    y_shapes = y.shape  #[batch,16,a,b]\n",
    "\n",
    "    if x_shapes[2:] == y_shapes[2:]:\n",
    "        return torch.cat((x, y),dim=1)                                 #[batch,n_features+16,a,b]\n",
    "\n",
    "    else:\n",
    "        print(x_shapes[2:])\n",
    "        print(y_shapes[2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a82ea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, instrument_size=1, n_hlayers=128):\n",
    "            super().__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.instrument_size = instrument_size\n",
    "\n",
    "            #generator layers\n",
    "            #as said in the DCGAN paper always ReLU activation function in the generator excluded the last layer\n",
    "            #as said in the DCGAN paper always batchnorm iin the generator excluded the last layer\n",
    "            self.ff1 = nn.Sequential(\n",
    "                nn.Linear(input_size, 1024),                                                               #[batch,1024]\n",
    "                nn.BatchNorm1d(1024),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            self.ff2 = nn.Sequential(\n",
    "                nn.Linear(1024,n_hlayers*2),                                                               #[batch,256]\n",
    "                nn.BatchNorm1d(n_hlayers*2),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #reshape to [batch size,128,1,2]\n",
    "            #+condition 2d [batch,128+16,1,2]\n",
    "            self.cnn1 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,4]\n",
    "                nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition 2d [batch,128+16,1,2]\n",
    "            self.cnn2 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,8]\n",
    "                nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition 2d [batch,128+16,1,2]\n",
    "            self.cnn3 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,16]\n",
    "                nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition 2d [batch,128+16,1,2]\n",
    "            self.cnn4 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+16, instrument_size, kernel_size=(128,1), stride=(2,1), bias=False, padding=0),       #[batch,instrument_size,128,16]\n",
    "                nn.Sigmoid()\n",
    "                #Sigmoid funciotn because we want to generate the matrixes of music without velocity, i.e. only (0,1)\n",
    "                #Thus we use the sigmoid which is a smoother version of the sign function\n",
    "                )\n",
    "            #conditioner layers\n",
    "            #as in Midinet model we use the Leaky activation funciton for the conditioner\n",
    "            self.h0_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=instrument_size, out_channels=16, kernel_size=(128,1), stride=(2,1)),                  #[batch,16,1,16]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU(0.2)          #note: in the original paper leak=0.2, default leak=0.01\n",
    "                )\n",
    "            self.h1_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,8]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU(0.2)\n",
    "                )\n",
    "            self.h2_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,4]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU(0.2)\n",
    "                )\n",
    "            self.h3_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,2]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU(0.2)\n",
    "                )\n",
    "\n",
    "    def forward(self, z, prev_bar, batch_size):\n",
    "\n",
    "            #2d condition\n",
    "            cond0 = self.h0_prev(prev_bar)          #[batch,16,1,16]\n",
    "            cond1 = self.h1_prev(cond0)             #[batch,16,1,8]\n",
    "            cond2 = self.h2_prev(cond1)             #[batch,16,1,4]\n",
    "            cond3 = self.h3_prev(cond2)             #[batch,16,1,2]\n",
    "\n",
    "\n",
    "\n",
    "            h0 = self.ff1(z)                        #[batch,1024]\n",
    "\n",
    "            h1 = self.ff2(h0)                       #[batch,256]\n",
    "            h1 = h1.reshape(batch_size, 128, 1, 2)  #[batch,128,1,2]\n",
    "            h1 = conv_prev_concat(h1,cond3)         #[batch,128+16,1,2]\n",
    "\n",
    "            h2 = self.cnn1(h1)                      #[batch,128,1,4]\n",
    "            h2 = conv_prev_concat(h2,cond2)         #[batch,128+16,1,4]\n",
    "\n",
    "            h3 = self.cnn2(h2)                      #[batch,128,1,8]\n",
    "            h3 = conv_prev_concat(h3,cond1)         #[batch,128+16,1,8]\n",
    "\n",
    "            h4 = self.cnn3(h3)                      #[batch,128,1,16]\n",
    "            h4 = conv_prev_concat(h4,cond0)         #[batch,128+16,1,16]\n",
    "\n",
    "            out = self.cnn4(h4)                     #[batch,instrument_size,128,16]\n",
    "\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab6b0218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.2)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "652fde5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU available')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('GPU not available')\n",
    "\n",
    "\n",
    "def LoadModel(instrumentSize, Which):\n",
    "\n",
    "    Path = os.path.realpath('ModelParameters')\n",
    "\n",
    "    files = [\n",
    "        ['generator_no1dnoise.torch', 'gen_opt_state_no1dnoise.torch'],\n",
    "        ['generator_no1d2.torch', 'gen_opt_state_no1d2.torch']\n",
    "    ]\n",
    "\n",
    "    generator = Generator(input_size=100, instrument_size=instrumentSize, n_hlayers=128)\n",
    "    generator.apply(weights_init)\n",
    "    generator.to(device)\n",
    "    # Load the state dict previously saved\n",
    "    generator_state_dict = torch.load(os.path.join(Path, files[Which][0]), map_location=torch.device('cpu'))\n",
    "    # Update the network parameters\n",
    "    generator.load_state_dict(generator_state_dict)\n",
    "\n",
    "    gen_opt = optim.Adam(generator.parameters(), lr=2e-4)\n",
    "    # Load the state dict previously saved\n",
    "    gen_opt_state_dict = torch.load(os.path.join(Path, files[Which][1]), map_location=torch.device('cpu'))\n",
    "    # Update the network parameters\n",
    "    gen_opt.load_state_dict(gen_opt_state_dict)\n",
    "\n",
    "    return generator\n",
    "\n",
    "                                                    #MOnophonic or polyphonic\n",
    "generator = LoadModel(instrumentSize=1, Which=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f2aa628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 50/50 [00:11<00:00,  4.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from Preprocessing import *\n",
    "Dataset = PreProcessing(nDir = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1236150e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07682120054960251 0.19310049712657928\n",
      "0.07805368304252625 0.18510711193084717\n",
      "0.0753619521856308 0.17833036184310913\n",
      "0.0736963301897049 0.1861092746257782\n",
      "0.07616700232028961 0.19217918813228607\n",
      "0.07618725299835205 0.19694870710372925\n",
      "0.07230650633573532 0.192580446600914\n",
      "0.0678374245762825 0.18772608041763306\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "generator.eval()\n",
    "\n",
    "Instrument = 'Piano'\n",
    "bar = np.random.randint(0, 100)\n",
    "\n",
    "prev_bar = Dataset[Instrument][bar]['Bars'][0].to_dense().float().to(device)\n",
    "InstrumentCode = Dataset[Instrument][bar]['Program']\n",
    "Tempo = Dataset[Instrument][bar]['Tempo'][0]\n",
    "\n",
    "Bars = []\n",
    "Bars.append(prev_bar)\n",
    "#If polyphonic only 1 unsqueeze\n",
    "prev_bar = prev_bar.unsqueeze(0).unsqueeze(0) \n",
    "\n",
    "\n",
    "for i in range(8):\n",
    "   noise = torch.rand([1, 100], device=device)*0.2\n",
    "\n",
    "   #print(np.mean(np.array(noise)))\n",
    "\n",
    "   with torch.no_grad():\n",
    "      generated_bar = generator(noise, prev_bar, 1)\n",
    "\n",
    "   binary_bar = (generated_bar > 0.7).float()  # still a tensor\n",
    "   Bars.append(binary_bar.squeeze(0).squeeze(0).cpu().numpy())  # only now for MIDI\n",
    "   print(generated_bar.mean().item(), generated_bar.std().item())\n",
    "   prev_bar = binary_bar.detach()\n",
    "\n",
    "\n",
    "\n",
    "PolyConcBars = np.concatenate(Bars, axis = 1)\n",
    "\n",
    "MonoBarsToMIDI(PolyConcBars, title='No1DCond', Instrument=InstrumentCode)\n",
    "\n",
    "print(InstrumentCode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47a2df27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Bars[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc4c5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b483dcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
