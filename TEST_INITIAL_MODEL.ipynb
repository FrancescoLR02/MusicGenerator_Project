{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c35efb12",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1752583241686,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "c35efb12"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn #neural network module\n",
    "import torch.optim as optim #optimizer\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "\n",
    "import time as time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "h9nnFhaJi3W1",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1752583242973,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "h9nnFhaJi3W1"
   },
   "outputs": [],
   "source": [
    "datasetpath=os.path.realpath('MonophonicDataset.pt')\n",
    "PolDataset = os.path.realpath('PolyphonicDataset.pt')\n",
    "\n",
    "Mono = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "h8DZrVQOhioM",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1752583242974,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "h8DZrVQOhioM"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list expected at most 1 argument, got 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Loading monophonic and polyphonic classes\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMonophonicDataset\u001b[39;00m(Dataset):\n\u001b[1;32m      4\u001b[0m    \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, Instruments):\n\u001b[1;32m      6\u001b[0m       DS \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(datasetpath)\n",
      "\u001b[0;31mTypeError\u001b[0m: list expected at most 1 argument, got 3"
     ]
    }
   ],
   "source": [
    "#Loading monophonic and polyphonic classes\n",
    "class MonophonicDataset(Dataset):\n",
    "\n",
    "   def __init__(self, Instruments):\n",
    "\n",
    "      DS = torch.load(datasetpath)\n",
    "      self.Data = []\n",
    "      self.Instruments = Instruments\n",
    "\n",
    "      for inst in Instruments:\n",
    "\n",
    "        self.Data.extend(DS[inst])\n",
    "\n",
    "      del DS\n",
    "      gc.collect()\n",
    "\n",
    "\n",
    "   def __len__(self):\n",
    "      return len(self.Data)\n",
    "\n",
    "   def __getitem__(self, idx):\n",
    "\n",
    "      PreviousBars = self.Data[idx]['Bars'][0].to_dense()\n",
    "      Bars = self.Data[idx]['Bars'][1].to_dense()\n",
    "\n",
    "      prog = self.Data[idx]['Program']\n",
    "      tempo = self.Data[idx]['Tempo'][0]\n",
    "\n",
    "      TEMPO_MIN, TEMPO_MAX = 60, 200\n",
    "      PROGRAM_MIN, PROGRAM_MAX = 1, 128\n",
    "\n",
    "      tempo_norm = (tempo - TEMPO_MIN) / (TEMPO_MAX - TEMPO_MIN)\n",
    "      prog_norm = (prog - PROGRAM_MIN) / (PROGRAM_MAX - PROGRAM_MIN)\n",
    "\n",
    "\n",
    "      Cond1D = torch.tensor([tempo_norm] + [prog_norm], dtype=torch.float, device=Bars.device)\n",
    "      return Bars, PreviousBars, Cond1D\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class PolyphonicDataset(Dataset):\n",
    "\n",
    "   def __init__(self):\n",
    "\n",
    "         DS = torch.load(PolDataset, weights_only=False)\n",
    "         self.Data = []\n",
    "\n",
    "         self.Data.extend(DS)\n",
    "\n",
    "         del DS\n",
    "         gc.collect()\n",
    "\n",
    "   def __len__(self):\n",
    "      return len(self.Data)\n",
    "\n",
    "   def __getitem__(self, idx):\n",
    "\n",
    "      PreviousBars = self.Data[idx]['Bars'][0].to_dense()\n",
    "      Bars = self.Data[idx]['Bars'][1].to_dense()\n",
    "\n",
    "      prog = self.Data[idx]['Program']\n",
    "      tempo = self.Data[idx]['Tempo']\n",
    "      genre = self.Data[idx]['Genre']\n",
    "\n",
    "\n",
    "      TEMPO_MIN, TEMPO_MAX = 60, 200\n",
    "      PROGRAM_MIN, PROGRAM_MAX = 1, 130\n",
    "      GENRE_MIN, GENRE_MAX = 0, 9\n",
    "\n",
    "      tempo_norm = (tempo - TEMPO_MIN) / (TEMPO_MAX - TEMPO_MIN)\n",
    "      genre_norm = (genre - GENRE_MIN) / (GENRE_MAX - GENRE_MIN)\n",
    "      prog_norm = [(p - PROGRAM_MIN) / (PROGRAM_MAX - PROGRAM_MIN) for p in prog]\n",
    "\n",
    "\n",
    "      Cond1D = torch.tensor([tempo_norm, genre_norm] + prog_norm, dtype=torch.float, device=Bars.device)\n",
    "      return Bars, PreviousBars, Cond1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cbede03",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "noise_dim = 100\n",
    "BATCH_SIZE = 72\n",
    "\n",
    "if Mono: Data = MonophonicDataset(Instruments=['Piano'])\n",
    "else: Data = PolyphonicDataset()\n",
    "\n",
    "def getDataloader(dataset, batch_size, num_batches):\n",
    "    # Total samples to use per epoch\n",
    "    subset_size = batch_size * num_batches\n",
    "    indices = np.random.choice(len(dataset), size=subset_size, replace=False)\n",
    "    sampler = SubsetRandomSampler(indices)\n",
    "    return DataLoader(dataset, batch_size=batch_size, sampler=sampler, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90129f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1752583242975,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "b90129f7",
    "outputId": "cb9ff5a2-5eea-42c3-9bd6-9399046235cf"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU available')\n",
    "\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print('mps available')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('GPU not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45854c0",
   "metadata": {
    "id": "a45854c0"
   },
   "source": [
    "### Concatenation\n",
    "\n",
    "Definition of the concatenation functions that are used in the hidden layers to concatenate the output and the 1_d and 2_d conditions.\n",
    "\n",
    "1_d conditioning vector of shape $[n,1]$ with an output of shape $[batch,features,a,b]$:\n",
    "* first we have to duplicate the vector $a\\cdot b$ times to get a tensor of shape $[batch,n,a,b]$\n",
    "* then we can concatenate the two tensors in the depth dimension (i.e dim=1)\n",
    "\n",
    "2_d conditioning matrix of the same shape of the output $[batch,features,a,b]$ except the depth dim (it must be that because how we build the conditioner CNN):\n",
    "* first we check that the dimensions are correct\n",
    "* we concatenate the two tensors in the depth dimension (i.e dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1acf0ac5",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1752583242975,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "1acf0ac5"
   },
   "outputs": [],
   "source": [
    "def conv_cond_concat(x, y):\n",
    "    \"\"\"Concatenate conditioning vector on feature map axis.\"\"\"\n",
    "    x_shapes = x.shape  #[batch,n_features,a,b]\n",
    "    y_shapes = y.shape  #[batch,n]\n",
    "    y2 = y.view(x_shapes[0],y_shapes[1],1,1)                              #[batch,n,1,1]\n",
    "    y2 = y2.expand(x_shapes[0],y_shapes[1],x_shapes[2],x_shapes[3])      #[batch,n,a,b]\n",
    "\n",
    "    return torch.cat((x, y2),dim=1)                                     #[batch,n_features+n,a,b]\n",
    "\n",
    "def conv_prev_concat(x, y):\n",
    "    \"\"\"Concatenate conditioning vector on feature map axis.\"\"\"\n",
    "    x_shapes = x.shape  #[batch,n_features,a,b]\n",
    "    y_shapes = y.shape  #[batch,16,a,b]\n",
    "    if x_shapes[2:] == y_shapes[2:]:\n",
    "        y2 = y.expand(x_shapes[0],y_shapes[1],x_shapes[2],x_shapes[3])  #[batch,16,a,b]\n",
    "\n",
    "        return torch.cat((x, y2),dim=1)                                 #[batch,n_features+16,a,b]\n",
    "\n",
    "    else:\n",
    "        print(x_shapes[2:])\n",
    "        print(y_shapes[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dae68f7",
   "metadata": {
    "id": "5dae68f7"
   },
   "source": [
    "### The Generator and the Conditioner\n",
    "\n",
    "The generator uses `ConvTranspose2d` (upsampling) layers to produce an image from a seed (random noise). Start with two `Dense` layers that take this seed as input and transform it to a tensor of shape $[batch size,128,1,2]$, then upsample several times until we reach the desired size of a bar of $[instrument,128,16]$. We use  the `ReLU` activation for each layer, except the output layer which can use `Sigmoid` to predict pixel values in the [0, 1] range.\n",
    "\n",
    "Coupled to the generator there is the conditioner that uses `Conv2d` (sampling) layers to produce the 2_d tensors that serve as informations from the preaviou bar. The conditioner can be viewed as the reverse of the generator because it uses filters with the same shapes of the ones in the generator. In this case we use  the `LeakyReLU` activation for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a88728a6",
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1752583243005,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "a88728a6"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, cond_1d_size, instrument_size=1, n_hlayers=128):\n",
    "            super().__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.instrument_size = instrument_size\n",
    "            self.cond1d_dim = cond_1d_size\n",
    "\n",
    "            #generator layers\n",
    "            #as said in the DCGAN paper always ReLU activation function in the generator excluded the last layer\n",
    "            #as said in the DCGAN paper always batchnorm iin the generator excluded the last layer\n",
    "            self.ff1 = nn.Sequential(\n",
    "                nn.Linear(input_size+cond_1d_size, 1024),                                                               #[batch,1024]\n",
    "                nn.BatchNorm1d(1024),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            self.ff2 = nn.Sequential(\n",
    "                nn.Linear(1024+cond_1d_size,n_hlayers*2),                                                                                    #[batch,512]\n",
    "                nn.BatchNorm1d(n_hlayers*2),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #reshape to [batch size,128,1,2]\n",
    "            # #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn1 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,4]\n",
    "                nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn2 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,8]\n",
    "                nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn3 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,16]\n",
    "                nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn4 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, instrument_size, kernel_size=(128,1), stride=(2,1), bias=False, padding=0),       #[batch,instrument_size,128,16]\n",
    "                nn.Sigmoid()\n",
    "                #Sigmoid funciotn because we want to generate the matrixes of music without velocity, i.e. only (0,1)\n",
    "                #Thus we use the sigmoid which is a smoother version of the sign function\n",
    "                )\n",
    "            #conditioner layers\n",
    "            # #as in Midinet model we use the Leaky activation funciton for the conditioner\n",
    "            self.h0_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=instrument_size, out_channels=16, kernel_size=(128,1), stride=(2,1)),                  #[batch,16,1,16]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()          #note: in the original paper leak=0.2, default leak=0.01\n",
    "                )\n",
    "            self.h1_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,8]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "            self.h2_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,4]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "            self.h3_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,2]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "\n",
    "    def forward(self, z, prev_bar, cond_1d, batch_size):\n",
    "\n",
    "            #2d condiiton\n",
    "            cond0 = self.h0_prev(prev_bar)          #[batch,16,1,16]\n",
    "            cond1 = self.h1_prev(cond0)             #[batch,16,1,8]\n",
    "            cond2 = self.h2_prev(cond1)             #[batch,16,1,4]\n",
    "            cond3 = self.h3_prev(cond2)             #[batch,16,1,2]\n",
    "\n",
    "            #single cond_1d size =[n,1], batch_cond_1d size = [batch_size,n]\n",
    "\n",
    "            input = torch.cat((z,cond_1d), dim=1)   #[batch_size, input_size+cond_1d_size]\n",
    "\n",
    "            h0 = self.ff1(input)                    #[batch,1024]\n",
    "            h0 = torch.cat((h0,cond_1d), dim=1)     #[batch,1024+cond_1d_size]\n",
    "\n",
    "            h1 = self.ff2(h0)                       #[batch,256]\n",
    "            h1 = h1.reshape(batch_size, 128, 1, 2)  #[batch,128,1,2]\n",
    "            h1 = conv_cond_concat(h1,cond_1d)       #[batch,128+cond_1d_size,1,2]\n",
    "            h1 = conv_prev_concat(h1,cond3)         #[batch,128+cond_1d_size+16,1,2]\n",
    "\n",
    "            h2 = self.cnn1(h1)                      #[batch,128,1,4]\n",
    "            h2 = conv_cond_concat(h2,cond_1d)       #[batch,128+cond_1d_size,1,4]\n",
    "            h2 = conv_prev_concat(h2,cond2)         #[batch,128+cond_1d_size+16,1,4]\n",
    "\n",
    "            h3 = self.cnn2(h2)                      #[batch,128,1,8]\n",
    "            h3 = conv_cond_concat(h3,cond_1d)       #[batch,128+cond_1d_size,1,8]\n",
    "            h3 = conv_prev_concat(h3,cond1)         #[batch,128+cond_1d_size+16,1,8]\n",
    "\n",
    "            h4 = self.cnn3(h3)                      #[batch,128,1,16]\n",
    "            h4 = conv_cond_concat(h4,cond_1d)       #[batch,128+cond_1d_size,1,16]\n",
    "            h4 = conv_prev_concat(h4,cond0)         #[batch,128+cond_1d_size+16,1,16]\n",
    "\n",
    "            out = self.cnn4(h4)             #[batch,instrument_size,128,16]\n",
    "\n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4727b52",
   "metadata": {
    "id": "a4727b52"
   },
   "source": [
    "### The Discriminator\n",
    "\n",
    "The discriminator uses `Conv2d` (sampling) layers to produce a scalar output from a bar input. Start with two `Conv2d` layers that reduce the size of the input, then use two `Dense` layers. We use  the `LeakyReLU` activation for each layer, except the output layer which can use `Sigmoid` to predict true-false probability value in the [0, 1] range. Note that the activation is included in the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e5cae21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinibatchDiscrimination(nn.Module):\n",
    "    def __init__(self, in_features, out_features, kernel_dim):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.kernel_dim = kernel_dim\n",
    "        self.T = nn.Parameter(torch.randn(in_features, out_features, kernel_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is batch_sizexA\n",
    "        # T is AxBxC\n",
    "        matrices = x @ self.T.view(self.in_features, -1)                # matrix moltiplication, result shape: [batch_size, B*C]\n",
    "        matrices = matrices.view(-1, self.out_features, self.kernel_dim)    #M shape [batch, B, C]\n",
    "\n",
    "        # compute L1 distances between samples\n",
    "        M = matrices.unsqueeze(0)  # [1,batch,B,C]\n",
    "        M_T = M.permute(1, 0, 2, 3)  # [batch,1,B,C]\n",
    "        norm = torch.abs(M - M_T).sum(3)  # first broadcast [batch,batch,B,C], then [batch,batch,B]\n",
    "        cbij = torch.exp(-norm)\n",
    "        o_b = cbij.sum(0)   # [batch,B], if j !=0 i in teh sum then subtract self distance (cbij.sum(0) - 1)\n",
    "\n",
    "        x = torch.cat([x, o_b], 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6646d974",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1752583243006,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "6646d974"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, cond_1d_size, instrument_size=1, mini_size=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.instrument_size = instrument_size\n",
    "        self.cond1d_dim = cond_1d_size\n",
    "\n",
    "        #as said in the DCGAN paper always batchnorm in the discriminator layers excluded the first layer\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(2*instrument_size+cond_1d_size, 32, kernel_size=(128,2), stride=(2,2), padding=0),        #[batch,32,1,8]\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        #+condition [batch,14+cond_1d_size,1,8]\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv2d(32+cond_1d_size, 77, kernel_size=(1,4), stride=2, padding=0),                             #[batch,77,1,3]\n",
    "            #Adding residual block\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "        self.ffnn1 = nn.Sequential(\n",
    "             #+condition [batch,231+cond_1d_size]\n",
    "            nn.Linear(231+cond_1d_size, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        self.minibatch = MinibatchDiscrimination(in_features=1024, out_features=mini_size,kernel_dim=3)\n",
    "\n",
    "        #+condition [batch,1024+mini_size+cond_1d_size]\n",
    "        self.ffnn2 = nn.Linear(1024+cond_1d_size+mini_size, 1)      #no sigmoid activation function because it is already in the definition of the cross entropy loss function\n",
    "\n",
    "\n",
    "    def forward(self, x, prev_bar, cond_1d):\n",
    "        input = conv_cond_concat(x,cond_1d)         #[batch,instrument_size+cond_1d_size,128,16]\n",
    "        input = conv_prev_concat(input,prev_bar)    #[batch,2*instrument_size+cond_1d_size,128,16]\n",
    "\n",
    "        h0 = self.cnn1(input)                       #[batch,14,1,8]\n",
    "        fm = h0\n",
    "        h0 = conv_cond_concat(h0, cond_1d)          #[batch,14+cond_1d_size,1,8]\n",
    "\n",
    "        h1 = self.cnn2(h0)                          #[batch,77,1,3]\n",
    "        h1 = torch.flatten(h1, 1)                   #[batch,77*3*1]\n",
    "        h1 = torch.cat((h1,cond_1d),dim=1)          #[batch,231+cond_1d_size]\n",
    "\n",
    "        h2 = self.ffnn1(h1)                         #[batch,1024]\n",
    "        h2 = self.minibatch(h2)                     #[batch,1024+mini_size]\n",
    "        h2 = torch.cat((h2,cond_1d),dim=1)          #[batch,1024+mini_size+cond_1d_size]\n",
    "\n",
    "        h3 = self.ffnn2(h2)                         #[batch,1]\n",
    "        h3_sigmoid = torch.sigmoid(h3)\n",
    "\n",
    "\n",
    "        return h3_sigmoid, h3, fm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d02a387",
   "metadata": {
    "id": "8d02a387"
   },
   "source": [
    "### Weights initialization\n",
    "\n",
    "Is this ok?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9237a67a",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752583243006,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "9237a67a"
   },
   "outputs": [],
   "source": [
    "# def weights_init(m):\n",
    "#     classname = m.__class__.__name__\n",
    "#     if classname.find('Conv') != -1:\n",
    "#         nn.init.xavier_uniform_(m.weight.data)*0\n",
    "#     if classname.find('Linear') != -1:\n",
    "#         nn.init.xavier_uniform_(m.weight.data)*0\n",
    "#     elif classname.find('BatchNorm') != -1:\n",
    "#         nn.init.normal_(m.weight.data, 1.0, 0.2)*0\n",
    "#         nn.init.constant_(m.bias.data, 0)*0\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.ConvTranspose2d, nn.Conv2d)):\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)  # DCGAN standard\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9059e917",
   "metadata": {
    "id": "9059e917"
   },
   "source": [
    "### Creation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64e61f6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1752583243012,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "64e61f6a",
    "outputId": "8b8629be-30e1-4679-fc01-f66e513213bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (ff1): Sequential(\n",
       "    (0): Linear(in_features=106, out_features=1024, bias=True)\n",
       "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (ff2): Sequential(\n",
       "    (0): Linear(in_features=1030, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (cnn1): Sequential(\n",
       "    (0): ConvTranspose2d(150, 128, kernel_size=(1, 2), stride=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (cnn2): Sequential(\n",
       "    (0): ConvTranspose2d(150, 128, kernel_size=(1, 2), stride=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (cnn3): Sequential(\n",
       "    (0): ConvTranspose2d(150, 128, kernel_size=(1, 2), stride=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (cnn4): Sequential(\n",
       "    (0): ConvTranspose2d(150, 4, kernel_size=(128, 1), stride=(2, 1), bias=False)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       "  (h0_prev): Sequential(\n",
       "    (0): Conv2d(4, 16, kernel_size=(128, 1), stride=(2, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (h1_prev): Sequential(\n",
       "    (0): Conv2d(16, 16, kernel_size=(1, 2), stride=(2, 2))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (h2_prev): Sequential(\n",
       "    (0): Conv2d(16, 16, kernel_size=(1, 2), stride=(2, 2))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (h3_prev): Sequential(\n",
       "    (0): Conv2d(16, 16, kernel_size=(1, 2), stride=(2, 2))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if Mono:\n",
    "  generator = Generator(input_size=100, cond_1d_size=2, instrument_size=1, n_hlayers=128)\n",
    "else:\n",
    "  generator = Generator(input_size=100, cond_1d_size=6, instrument_size=4, n_hlayers=128)\n",
    "generator.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "307a37f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1752583243021,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "307a37f6",
    "outputId": "308c1fd6-2907-45c4-b81d-02d6fe727ed4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (cnn1): Sequential(\n",
       "    (0): Conv2d(14, 32, kernel_size=(128, 2), stride=(2, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (cnn2): Sequential(\n",
       "    (0): Conv2d(38, 77, kernel_size=(1, 4), stride=(2, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (ffnn1): Sequential(\n",
       "    (0): Linear(in_features=237, out_features=1024, bias=True)\n",
       "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (minibatch): MinibatchDiscrimination()\n",
       "  (ffnn2): Linear(in_features=1130, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if Mono:\n",
    "  discriminator = Discriminator(cond_1d_size=2, instrument_size=1)\n",
    "else:\n",
    "  discriminator = Discriminator(cond_1d_size=6, instrument_size=4)\n",
    "discriminator.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a4dac3",
   "metadata": {
    "id": "d6a4dac3"
   },
   "source": [
    "### Dimension testing\n",
    "\n",
    "Produce a noise vector of size `[10, 100]`, a noise 1d condition vector of size `[10, 15]`, and a noise 2d condition tensor of size `[10, 1, 128,16]`. Note that we need a 1d and a 2d contions for each batch input. Then we use the (as yet **untrained**) generator to create an image of expected output shape $[10,1,128,16]$.\n",
    "\n",
    "Then use the (yet **untrained**) discriminator to classify the generated images as real or fake. The model will be trained to output the probability that the image is real in the first output component, thus we expect an output vector of size `[10, 1]` with $x_i \\in [0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4075ff07",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1752583243043,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "4075ff07",
    "outputId": "f94b2760-d3c8-46a3-c40b-95a04dccc008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100])\n",
      "torch.Size([10, 4, 128, 16])\n",
      "tensor([[0.5908],\n",
      "        [0.6582],\n",
      "        [0.3681],\n",
      "        [0.4791],\n",
      "        [0.3525],\n",
      "        [0.6121],\n",
      "        [0.1656],\n",
      "        [0.6174],\n",
      "        [0.4862],\n",
      "        [0.4991]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "############################ input (batch_size=10, vector_size=100) ###############################\n",
    "noise = torch.normal(0, 1, [10, 100])\n",
    "print(noise.shape)\n",
    "############################ conditions ###############################\n",
    "if Mono:\n",
    "  cond_1d = torch.normal(0,1,[10,2])\n",
    "  prev_bar = torch.normal(0, 1, [10, 1, 128, 16])\n",
    "else:\n",
    "  cond_1d = torch.normal(0,1,[10,6])\n",
    "  prev_bar = torch.normal(0, 1, [10, 4, 128, 16])\n",
    "\n",
    "\n",
    "############################ generator ###############################\n",
    "generated_bar = generator(noise, prev_bar, cond_1d, batch_size=10).detach()\n",
    "print(generated_bar.shape)\n",
    "############################ discriminator ###############################\n",
    "decision, __, __= discriminator(generated_bar, prev_bar, cond_1d)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e8b2ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4541, 0.5012, 0.5011,  ..., 0.4202, 0.4675, 0.4239],\n",
       "        [0.4139, 0.4806, 0.3858,  ..., 0.4001, 0.4306, 0.4693],\n",
       "        [0.5372, 0.5582, 0.5603,  ..., 0.5381, 0.6020, 0.5458],\n",
       "        ...,\n",
       "        [0.4588, 0.4646, 0.5102,  ..., 0.4447, 0.4528, 0.4843],\n",
       "        [0.5228, 0.5080, 0.4965,  ..., 0.6051, 0.5192, 0.5094],\n",
       "        [0.4600, 0.4283, 0.5494,  ..., 0.5242, 0.4691, 0.5199]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_bar[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cf78a3",
   "metadata": {
    "id": "26cf78a3"
   },
   "source": [
    "### Discriminator loss\n",
    "\n",
    "This method quantifies how well the discriminator is able to distinguish real images from fakes. It compares the discriminator's predictions on real images to an array of 1s, and the discriminator's predictions on fake (generated) images to an array of 0s.\n",
    "The discriminator loss is of the form:\n",
    "\n",
    "$\\frac{1}{m}\\sum_{i=1}^{m}-[\\log D(\\boldsymbol{x}^{(i)}) +\\log(1-D(G(\\boldsymbol{z}^{(i)})))]$\n",
    "\n",
    "We inplement one-sided label smoothing to penalize self confidence and imporve the convergence of the training. Thus we substitute the discriminator's predictions on real images to an array of 1s with an array of (1-$\\alpha$)s and the loss function becomes:\n",
    "\n",
    "$\\frac{1}{m}\\sum_{i=1}^{m}-[(1-\\alpha) \\log D(\\boldsymbol{x}^{(i)}) +\\alpha \\log (1-D(\\boldsymbol{x}^{(i)}))+\\log(1-D(G(\\boldsymbol{z}^{(i)})))]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa9329bd",
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1752583243086,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "fa9329bd"
   },
   "outputs": [],
   "source": [
    "cross_entropy = nn.BCEWithLogitsLoss()\n",
    "MSE=nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "778a6afc",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1752583243092,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "778a6afc"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output, device, alpha=0.1):\n",
    "\n",
    "    #real_targets = torch.ones_like(real_output, device=device)                 #no label smoothing -> True output expected output is 1\n",
    "    real_targets = torch.full_like(real_output, 1.0 - alpha, device=device)     #one side label smoothing to penalize self confidence\n",
    "    fake_targets = torch.zeros_like(fake_output, device=device)                 #no label smoothing -> Fake output expected output is 0\n",
    "\n",
    "    real_loss = cross_entropy(real_output, real_targets)\n",
    "    fake_loss = cross_entropy(fake_output, fake_targets)\n",
    "\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04bd362",
   "metadata": {
    "id": "f04bd362"
   },
   "source": [
    "### Generator loss\n",
    "\n",
    "The generator's loss quantifies how well it was able to trick the discriminator. Intuitively, if the generator is performing well, the discriminator will classify the fake images as real (or 1).\n",
    "The generator loss is of the form:\n",
    "\n",
    "$\\frac{1}{m}\\sum_{i=1}^{m}\\log(1-D(G(\\boldsymbol{z}^{(i)})))$\n",
    "\n",
    "However this loss has some convergence issues due to vanishing gradients. So instead we use the following loss which has the same trend but stronger gradient when the discriminator is too good at recognizing fake samples.\n",
    "\n",
    "$\\frac{1}{m}\\sum_{i=1}^{m}-\\log(D(G(\\boldsymbol{z}^{(i)})))$\n",
    "\n",
    "Which is the Binary crossentropy between $D(G(\\boldsymbol{z}^{(i)}))$ and the probability distribution that has $y^{(i)} = 1 \\forall i$, i.e. we are forcing the generator to produce samples that will make the discriminator predict that fake samples are real.\n",
    "\n",
    "Moreover we add a regularizer term so-called feature matching such that the distributions of the real and generated data are enforced to be close.\n",
    "\n",
    "$\\lambda_1 ||E_{x \\sim p(x)} [x] - E_{z\\sim p(z)} [G(z)] ||^2 + \\lambda_2 ||E_{x \\sim p(x)} [f(x)] - E_{z \\sim p(z)} [f(G(z))] ||^2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "367712ab",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1752583243102,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "367712ab"
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output, real_bar, fake_bar, real_f, fake_f, device, lambda1=0.1, lambda2=0.01):\n",
    "\n",
    "    gen_loss = cross_entropy(fake_output, torch.ones_like(fake_output, device=device))\n",
    "\n",
    "    mean_real = torch.mean(real_bar, dim=0)\n",
    "    mean_fake = torch.mean(fake_bar, dim=0)\n",
    "    l2_data = MSE(mean_real, mean_fake)\n",
    "\n",
    "    mean_real_feat = torch.mean(real_f, dim=0)\n",
    "    mean_fake_feat = torch.mean(fake_f, dim=0)\n",
    "    l2_feat = MSE(mean_real_feat, mean_fake_feat)\n",
    "\n",
    "    return gen_loss+lambda1*l2_data+lambda2*l2_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873c39af",
   "metadata": {
    "id": "873c39af"
   },
   "source": [
    "### Optimizers\n",
    "\n",
    "With DCGAN the training is very diffuclt so we decide to use Adam optimizer as suggested by the paper. Note that with Adam we use both momentum and RMSprop to normalized velocities. Discriminator and generator need two different optimizers (conditioner is included in the generator training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3bc9be6",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1752583243104,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "e3bc9be6"
   },
   "outputs": [],
   "source": [
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "gen_opt = optim.Adam(generator.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "dis_opt = optim.Adam(discriminator.parameters(), lr=4e-4, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a476d",
   "metadata": {
    "id": "5c2a476d"
   },
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1216184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LossPenalty(GenBars, ActualLoss):\n",
    "\n",
    "   mean = GenBars.mean().item()\n",
    "   BinaryBar = (GenBars > mean).float().squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "   ActiveNotes = np.sum(BinaryBar, axis = 0)\n",
    "\n",
    "   Notes = (ActiveNotes > 5)\n",
    "   Sums = np.sum(Notes)\n",
    "\n",
    "   #PenaltyTerm on the loss if more that 5 notes are active at the same time\n",
    "   PenaltyTerm = ActualLoss + 0.05*ActualLoss*Sums\n",
    "\n",
    "   return PenaltyTerm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "Y8NU6yHm9LFZ",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1752583441187,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "Y8NU6yHm9LFZ"
   },
   "outputs": [],
   "source": [
    "def train_step(bars, cond_1d, prev_bar, generator, discriminator, batch_size,\n",
    "               noise_dim, device, dis_opt, gen_opt):\n",
    "    # --- Ensure all tensors are on the correct device ---\n",
    "    bars = bars.to(device)\n",
    "    cond_1d = cond_1d.to(device)\n",
    "    prev_bar = prev_bar.to(device)\n",
    "\n",
    "    # --- Discriminator training ---\n",
    "    noise = torch.randn([batch_size, noise_dim], device=device)\n",
    "\n",
    "    bars_noise = bars + torch.randn_like(bars) * 0.1\n",
    "    bars_noise = torch.clamp(bars_noise, 0, 1)\n",
    "\n",
    "    # Generate fake samples\n",
    "    generated_bars = generator(noise, prev_bar, cond_1d, batch_size)\n",
    "\n",
    "    # Forward pass (real + fake)\n",
    "    real_output, real_D, _ = discriminator(bars_noise, prev_bar, cond_1d)\n",
    "    fake_output, fake_D, _ = discriminator(generated_bars.detach(), prev_bar, cond_1d)\n",
    "\n",
    "    # Discriminator loss\n",
    "    disc_loss = discriminator_loss(real_D, fake_D, device)\n",
    "    discriminator.zero_grad()\n",
    "    disc_loss.backward()\n",
    "    dis_opt.step()\n",
    "\n",
    "    # --- Generator training (2 steps) ---\n",
    "    gen_losses = []\n",
    "    for _ in range(1):  # Consistent 2:1 update ratio\n",
    "        noise = torch.randn([batch_size, noise_dim], device=device)\n",
    "        generated_bars = generator(noise, prev_bar, cond_1d, batch_size)\n",
    "        _, fake_D, fake_fm = discriminator(generated_bars, prev_bar, cond_1d)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, real_D, real_fm = discriminator(bars_noise, prev_bar, cond_1d)\n",
    "\n",
    "        gen_loss = generator_loss(fake_D, bars, generated_bars, real_fm, fake_fm, device)\n",
    "\n",
    "        generator.zero_grad()\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "        gen_losses.append(gen_loss.item())\n",
    "\n",
    "    return sum(gen_losses) / len(gen_losses), disc_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3313e656",
   "metadata": {
    "id": "3313e656"
   },
   "source": [
    "supponendo che nel dataloader ogni dato sia una bar + la preavious bar + 1d condition sugli strumenti utilizzati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a670270f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "executionInfo": {
     "elapsed": 282,
     "status": "error",
     "timestamp": 1752583441471,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "a670270f",
    "outputId": "75d763e9-453e-4ca2-9f26-08f62701f198"
   },
   "outputs": [],
   "source": [
    "# gloss = []\n",
    "# dloss = []\n",
    "\n",
    "# for epoch in range(EPOCHS):\n",
    "\n",
    "#     start = time.time()\n",
    "#     generator.train()\n",
    "#     discriminator.train()\n",
    "#     gen_losses = []\n",
    "#     disc_losses = []\n",
    "#     print('#################')\n",
    "#     print(f\"Epoch: {epoch+1}\")\n",
    "\n",
    "#     iterator = tqdm(dataloader)\n",
    "#     for bar_batch, prev_bar_batch, instrument_batch in iterator:\n",
    "#         bar_batch = bar_batch.to(dtype=torch.float32, device=device)\n",
    "#         prev_bar_batch = prev_bar_batch.to(dtype=torch.float32, device=device)\n",
    "#         instrument_batch = instrument_batch.to(dtype=torch.float32, device=device)\n",
    "#         #instrument_batch = torch.zeros_like(cond_1d)\n",
    "\n",
    "#         if Mono:\n",
    "#             bar_batch = bar_batch.unsqueeze(1)\n",
    "#             prev_bar_batch=prev_bar_batch.unsqueeze(1)\n",
    "\n",
    "#         gen_loss, disc_loss = train_step(bar_batch, instrument_batch, prev_bar_batch, generator, discriminator,\n",
    "#                                          BATCH_SIZE, noise_dim, device, dis_opt, gen_opt)\n",
    "#         gen_losses.append(gen_loss)\n",
    "#         disc_losses.append(disc_loss)\n",
    "\n",
    "#         iterator.set_description('Discriminator loss: {}, Generator loss: {}'.format(disc_loss, gen_loss))\n",
    "\n",
    "#     gloss.append(np.mean(gen_losses))\n",
    "#     dloss.append(np.mean(disc_losses))\n",
    "#     #print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "#     print(f'dLoss: {dloss[-1]}, gLoss: {gloss[-1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60125f78",
   "metadata": {
    "id": "60125f78"
   },
   "source": [
    "### Weights and loss analysis\n",
    "\n",
    "First let's plot the 2 losses over the epochs, if it works correctly the generator loss would have to decrease and the discriminator one would have to increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a427ac8",
   "metadata": {
    "executionInfo": {
     "elapsed": 200162,
     "status": "aborted",
     "timestamp": 1752583441516,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "1a427ac8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gloss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(gloss, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenerator loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(dloss, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiscriminator loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gloss' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(gloss, label='Generator loss')\n",
    "plt.plot(dloss, label='Discriminator loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "afdace0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Preprocessing import *\n",
    "from PolyphonicPreprocessing import *\n",
    "\n",
    "Mono = True\n",
    "\n",
    "TEMPO_MIN, TEMPO_MAX = 60, 200  # Typical tempo range\n",
    "PROGRAM_MIN, PROGRAM_MAX = 1, 130  # MIDI program range\n",
    "GENRE_MIN, GENRE_MAX = 0, 9\n",
    "\n",
    "def NormCond(tempo, programs, genre, Mono):\n",
    "\n",
    "   tempo_norm = (tempo - TEMPO_MIN) / (TEMPO_MAX - TEMPO_MIN)\n",
    "    \n",
    "   if Mono:\n",
    "      programs_norm = (programs - PROGRAM_MIN) / (PROGRAM_MAX - PROGRAM_MIN)\n",
    "      return [tempo_norm] + [programs_norm]\n",
    "   else:\n",
    "      programs_norm = [(p - PROGRAM_MIN) / (PROGRAM_MAX - PROGRAM_MIN) for p in programs]\n",
    "      genre_norm = (genre - GENRE_MIN) / (GENRE_MAX - GENRE_MIN)\n",
    "      return [tempo_norm, genre_norm] + programs_norm\n",
    "    \n",
    "   \n",
    "if Mono:\n",
    "   Dataset = torch.load('MonophonicDataset.pt')\n",
    "   \n",
    "else:\n",
    "   Dataset = PolyphonicPreProcessing(nDir = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1420d77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU available')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('GPU not available')\n",
    "\n",
    "\n",
    "def LoadModel(Cond1D_Size, instrumentSize, Which):\n",
    "\n",
    "    Path = os.path.realpath('ModelParameters')\n",
    "\n",
    "    files = [\n",
    "        ['MonoGenParam.torch'],\n",
    "        ['PolyGenParam.torch']\n",
    "    ]\n",
    "\n",
    "    generator = Generator(input_size=100, cond_1d_size=Cond1D_Size, instrument_size=instrumentSize, n_hlayers=128)\n",
    "    generator.apply(weights_init)\n",
    "    generator.to(device)\n",
    "    # Load the state dict previously saved\n",
    "    generator_state_dict = torch.load(os.path.join(Path, files[Which][0]), map_location=torch.device('cpu'))\n",
    "    # Update the network parameters\n",
    "    generator.load_state_dict(generator_state_dict)\n",
    "\n",
    "    return generator\n",
    "\n",
    "                                                    #MOnophonic or polyphonic\n",
    "if Mono: generator = LoadModel(Cond1D_Size=2, instrumentSize=1, Which=0)\n",
    "else: generator = LoadModel(Cond1D_Size=6, instrumentSize=4, Which=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3fc84211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04425717145204544 0.06909490376710892\n",
      "0.04604472219944 0.07575421780347824\n",
      "0.04508315399289131 0.07025603950023651\n",
      "0.04645500332117081 0.058509524911642075\n",
      "0.04194045811891556 0.06809889525175095\n",
      "0.046523578464984894 0.05806519463658333\n",
      "0.04181010276079178 0.06807234138250351\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "generator.eval().to(device)\n",
    "\n",
    "bar = np.random.randint(0, 25000)\n",
    "\n",
    "if Mono:\n",
    "   Instrument = 'Bass'\n",
    "   prev_bar = Dataset[Instrument][bar]['Bars'][0].to_dense().float().to(device)\n",
    "   InstrumentCode = Dataset[Instrument][bar]['Program']\n",
    "   Tempo = Dataset[Instrument][bar]['Tempo'][0]\n",
    "   Cond1D_Norm = torch.tensor([NormCond(Tempo, InstrumentCode, 0, Mono)], dtype= torch.float32, device = device)\n",
    "\n",
    "\n",
    "else:\n",
    "   prev_bar = Dataset[bar]['Bars'][0].to_dense().float().to(device)\n",
    "   InstrumentCode = Dataset[bar]['Program']\n",
    "   Tempo = Dataset[bar]['Tempo']\n",
    "   Genre = Dataset[bar]['Genre']\n",
    "   Cond1D = [Tempo, Genre] + InstrumentCode\n",
    "   #Cond1D = [100, 2, 2, 24, 32, 130]\n",
    "\n",
    "   Cond1D_Norm = torch.tensor([NormCond(Tempo, InstrumentCode, Genre, Mono)], dtype= torch.float32, device = device)\n",
    "\n",
    "\n",
    "Bars = []\n",
    "Bars.append(prev_bar)\n",
    "\n",
    "if Mono:\n",
    "   prev_bar = prev_bar.unsqueeze(0).unsqueeze(0) \n",
    "else:\n",
    "   prev_bar = prev_bar.unsqueeze(0)\n",
    "\n",
    "\n",
    "for i in range(7):\n",
    "   noise = torch.rand([1, 100], device=device)*0.2\n",
    "\n",
    "   #print(np.mean(np.array(noise)))\n",
    "\n",
    "   with torch.no_grad():\n",
    "      generated_bar = generator(noise, prev_bar, Cond1D_Norm, 1)\n",
    "\n",
    "   mean = generated_bar.mean().item()\n",
    "   std = generated_bar.std().item()\n",
    "   binary_bar = (generated_bar > mean + 4*std).float()\n",
    "   if Mono: \n",
    "      Bars.append(binary_bar.squeeze(0).squeeze(0).cpu().numpy()) \n",
    "      prev_bar = Dataset[Instrument][bar + i + 1]['Bars'][0].unsqueeze(0).unsqueeze(0).to_dense().float().to(device)\n",
    "      #prev_bar = binary_bar.detach()\n",
    "   else: \n",
    "      Bars.append(binary_bar.squeeze(0).cpu().numpy()) \n",
    "      #prev_bar = Dataset[bar + i + 1]['Bars'][0].unsqueeze(0).to_dense().float().to(device)\n",
    "      prev_bar = binary_bar.detach()\n",
    "   print(mean, std)\n",
    "   \n",
    "\n",
    "\n",
    "if Mono:\n",
    "   ConcBars = np.concatenate(Bars, axis = 1)\n",
    "   MonoBarsToMIDI(ConcBars, Instrument=InstrumentCode, title='GeneratedAudio/Monotest')\n",
    "\n",
    "else:\n",
    "   PolyConcBars = np.concatenate(Bars, axis = 2)\n",
    "   PolyBarsToMIDI(PolyConcBars, Cond1D=Cond1D, title='GeneratedAudio/Polytest')\n",
    "\n",
    "\n",
    "print(InstrumentCode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0715da54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Bars[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f70a8b",
   "metadata": {
    "id": "51f70a8b"
   },
   "source": [
    "Save networks and optimizers states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c479e2c",
   "metadata": {
    "executionInfo": {
     "elapsed": 200163,
     "status": "aborted",
     "timestamp": 1752583441519,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "4c479e2c"
   },
   "outputs": [],
   "source": [
    "#torch.save(discriminator.state_dict(), 'discriminator_parameters.torch')\n",
    "torch.save(generator.state_dict(), 'generator_parameters.torch')\n",
    "print('Saved Model')\n",
    "\n",
    "#torch.save(dis_opt.state_dict(), 'dis_opt_state.torch')\n",
    "torch.save(gen_opt.state_dict(), 'gen_opt_state.torch')\n",
    "print('Saved Optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226da7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625776cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
