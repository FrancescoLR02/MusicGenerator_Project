{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c35efb12",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1752583241686,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "c35efb12"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn #neural network module\n",
    "import torch.optim as optim #optimizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import time as time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "h9nnFhaJi3W1",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1752583242973,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "h9nnFhaJi3W1"
   },
   "outputs": [],
   "source": [
    "datasetpath=os.path.realpath('Dataset_Sparse.pt')\n",
    "PolDataset = os.path.realpath('PolyphonicDataset.pt')\n",
    "\n",
    "Mono = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "h8DZrVQOhioM",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1752583242974,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "h8DZrVQOhioM"
   },
   "outputs": [],
   "source": [
    "#Loading monophonic and polyphonic classes\n",
    "class MonophonicDataset(Dataset):\n",
    "\n",
    "   def __init__(self, Instruments):\n",
    "\n",
    "      DS = torch.load(datasetpath)\n",
    "      self.Data = []\n",
    "      self.Instruments = Instruments\n",
    "\n",
    "      for inst in Instruments:\n",
    "\n",
    "        self.Data.extend(DS[inst])\n",
    "\n",
    "      del DS\n",
    "      gc.collect()\n",
    "\n",
    "\n",
    "   def __len__(self):\n",
    "      return len(self.Data)\n",
    "\n",
    "   def __getitem__(self, idx):\n",
    "\n",
    "      PreviousBars = self.Data[idx]['Bars'][0].to_dense()\n",
    "      Bars = self.Data[idx]['Bars'][1].to_dense()\n",
    "\n",
    "      prog = self.Data[idx]['Program']\n",
    "      tempo = self.Data[idx]['Tempo'][0]\n",
    "\n",
    "      TEMPO_MIN, TEMPO_MAX = 60, 200\n",
    "      PROGRAM_MIN, PROGRAM_MAX = 1, 128\n",
    "\n",
    "      tempo_norm = (tempo - TEMPO_MIN) / (TEMPO_MAX - TEMPO_MIN)\n",
    "      prog_norm = (prog - PROGRAM_MIN) / (PROGRAM_MAX - PROGRAM_MIN)\n",
    "\n",
    "\n",
    "      Cond1D = torch.tensor([tempo_norm] + [prog_norm], dtype=torch.float, device=Bars.device)\n",
    "      return Bars, PreviousBars, Cond1D\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class PolyphonicDataset(Dataset):\n",
    "\n",
    "   def __init__(self, Genre):\n",
    "\n",
    "         DS = torch.load(PolDataset, weights_only=False)\n",
    "         self.Data = []\n",
    "         self.Genre = Genre\n",
    "\n",
    "         for gen in Genre:\n",
    "            self.Data.extend(DS[gen])\n",
    "\n",
    "         del DS\n",
    "         gc.collect()\n",
    "\n",
    "   def __len__(self):\n",
    "      return len(self.Data)\n",
    "\n",
    "   def __getitem__(self, idx):\n",
    "\n",
    "      PreviousBars = self.Data[idx]['Bars'][0].to_dense()\n",
    "      Bars = self.Data[idx]['Bars'][1].to_dense()\n",
    "\n",
    "      prog = self.Data[idx]['Program'][0]\n",
    "      tempo = self.Data[idx]['Tempo'][0]\n",
    "\n",
    "\n",
    "      TEMPO_MIN, TEMPO_MAX = 60, 200\n",
    "      PROGRAM_MIN, PROGRAM_MAX = 1, 128\n",
    "\n",
    "      tempo_norm = (tempo - TEMPO_MIN) / (TEMPO_MAX - TEMPO_MIN)\n",
    "      prog_norm = [(p - PROGRAM_MIN) / (PROGRAM_MAX - PROGRAM_MIN) for p in prog]\n",
    "\n",
    "\n",
    "      Cond1D = torch.tensor([tempo_norm] + prog_norm, dtype=torch.float, device=Bars.device)\n",
    "      return Bars, PreviousBars, Cond1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cbede03",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "noise_dim = 100\n",
    "BATCH_SIZE = 72\n",
    "\n",
    "if Mono: Data = MonophonicDataset(Instruments=['Piano'])\n",
    "else: Data = PolyphonicDataset(Genre = ['rock'])\n",
    "dataloader = DataLoader(Data, BATCH_SIZE, shuffle=True, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b90129f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1752583242975,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "b90129f7",
    "outputId": "cb9ff5a2-5eea-42c3-9bd6-9399046235cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU available')\n",
    "\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print('mps available')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('GPU not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45854c0",
   "metadata": {
    "id": "a45854c0"
   },
   "source": [
    "### Concatenation\n",
    "\n",
    "Definition of the concatenation functions that are used in the hidden layers to concatenate the output and the 1_d and 2_d conditions.\n",
    "\n",
    "1_d conditioning vector of shape $[n,1]$ with an output of shape $[batch,features,a,b]$:\n",
    "* first we have to duplicate the vector $a\\cdot b$ times to get a tensor of shape $[batch,n,a,b]$\n",
    "* then we can concatenate the two tensors in the depth dimension (i.e dim=1)\n",
    "\n",
    "2_d conditioning matrix of the same shape of the output $[batch,features,a,b]$ except the depth dim (it must be that because how we build the conditioner CNN):\n",
    "* first we check that the dimensions are correct\n",
    "* we concatenate the two tensors in the depth dimension (i.e dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1acf0ac5",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1752583242975,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "1acf0ac5"
   },
   "outputs": [],
   "source": [
    "def conv_cond_concat(x, y):\n",
    "    \"\"\"Concatenate conditioning vector on feature map axis.\"\"\"\n",
    "    x_shapes = x.shape  #[batch,n_features,a,b]\n",
    "    y_shapes = y.shape  #[batch,n]\n",
    "    y2 = y.view(x_shapes[0],y_shapes[1],1,1)                              #[batch,n,1,1]\n",
    "    y2 = y2.expand(x_shapes[0],y_shapes[1],x_shapes[2],x_shapes[3])      #[batch,n,a,b]\n",
    "\n",
    "    return torch.cat((x, y2),dim=1)                                     #[batch,n_features+n,a,b]\n",
    "\n",
    "def conv_prev_concat(x, y):\n",
    "    \"\"\"Concatenate conditioning vector on feature map axis.\"\"\"\n",
    "    x_shapes = x.shape  #[batch,n_features,a,b]\n",
    "    y_shapes = y.shape  #[batch,16,a,b]\n",
    "    if x_shapes[2:] == y_shapes[2:]:\n",
    "        y2 = y.expand(x_shapes[0],y_shapes[1],x_shapes[2],x_shapes[3])  #[batch,16,a,b]\n",
    "\n",
    "        return torch.cat((x, y2),dim=1)                                 #[batch,n_features+16,a,b]\n",
    "\n",
    "    else:\n",
    "        print(x_shapes[2:])\n",
    "        print(y_shapes[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dae68f7",
   "metadata": {
    "id": "5dae68f7"
   },
   "source": [
    "### The Generator and the Conditioner\n",
    "\n",
    "The generator uses `ConvTranspose2d` (upsampling) layers to produce an image from a seed (random noise). Start with two `Dense` layers that take this seed as input and transform it to a tensor of shape $[batch size,128,1,2]$, then upsample several times until we reach the desired size of a bar of $[instrument,128,16]$. We use  the `ReLU` activation for each layer, except the output layer which can use `Sigmoid` to predict pixel values in the [0, 1] range.\n",
    "\n",
    "Coupled to the generator there is the conditioner that uses `Conv2d` (sampling) layers to produce the 2_d tensors that serve as informations from the preaviou bar. The conditioner can be viewed as the reverse of the generator because it uses filters with the same shapes of the ones in the generator. In this case we use  the `LeakyReLU` activation for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a88728a6",
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1752583243005,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "a88728a6"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, cond_1d_size, instrument_size=1, n_hlayers=128):\n",
    "            super().__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.instrument_size = instrument_size\n",
    "            self.cond1d_dim = cond_1d_size\n",
    "\n",
    "            #generator layers\n",
    "            #as said in the DCGAN paper always ReLU activation function in the generator excluded the last layer\n",
    "            #as said in the DCGAN paper always batchnorm iin the generator excluded the last layer\n",
    "            self.ff1 = nn.Sequential(\n",
    "                nn.Linear(input_size+cond_1d_size, 1024),                                                               #[batch,1024]\n",
    "                nn.BatchNorm1d(1024),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            self.ff2 = nn.Sequential(\n",
    "                nn.Linear(1024+cond_1d_size,n_hlayers*2),                                                                                    #[batch,512]\n",
    "                nn.BatchNorm1d(n_hlayers*2),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #reshape to [batch size,128,1,2]\n",
    "            # #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn1 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,4]\n",
    "                nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn2 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,8]\n",
    "                nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn3 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,16]\n",
    "                nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn4 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, instrument_size, kernel_size=(128,1), stride=(2,1), bias=False, padding=0),       #[batch,instrument_size,128,16]\n",
    "                nn.Sigmoid()\n",
    "                #Sigmoid funciotn because we want to generate the matrixes of music without velocity, i.e. only (0,1)\n",
    "                #Thus we use the sigmoid which is a smoother version of the sign function\n",
    "                )\n",
    "            #conditioner layers\n",
    "            # #as in Midinet model we use the Leaky activation funciton for the conditioner\n",
    "            self.h0_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=instrument_size, out_channels=16, kernel_size=(128,1), stride=(2,1)),                  #[batch,16,1,16]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()          #note: in the original paper leak=0.2, default leak=0.01\n",
    "                )\n",
    "            self.h1_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,8]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "            self.h2_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,4]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "            self.h3_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,2]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "\n",
    "    def forward(self, z, prev_bar, cond_1d, batch_size):\n",
    "\n",
    "            #2d condiiton\n",
    "            cond0 = self.h0_prev(prev_bar)          #[batch,16,1,16]\n",
    "            cond1 = self.h1_prev(cond0)             #[batch,16,1,8]\n",
    "            cond2 = self.h2_prev(cond1)             #[batch,16,1,4]\n",
    "            cond3 = self.h3_prev(cond2)             #[batch,16,1,2]\n",
    "\n",
    "            #single cond_1d size =[n,1], batch_cond_1d size = [batch_size,n]\n",
    "\n",
    "            input = torch.cat((z,cond_1d), dim=1)   #[batch_size, input_size+cond_1d_size]\n",
    "\n",
    "            h0 = self.ff1(input)                    #[batch,1024]\n",
    "            h0 = torch.cat((h0,cond_1d), dim=1)     #[batch,1024+cond_1d_size]\n",
    "\n",
    "            h1 = self.ff2(h0)                       #[batch,256]\n",
    "            h1 = h1.reshape(batch_size, 128, 1, 2)  #[batch,128,1,2]\n",
    "            h1 = conv_cond_concat(h1,cond_1d)       #[batch,128+cond_1d_size,1,2]\n",
    "            h1 = conv_prev_concat(h1,cond3)         #[batch,128+cond_1d_size+16,1,2]\n",
    "\n",
    "            h2 = self.cnn1(h1)                      #[batch,128,1,4]\n",
    "            h2 = conv_cond_concat(h2,cond_1d)       #[batch,128+cond_1d_size,1,4]\n",
    "            h2 = conv_prev_concat(h2,cond2)         #[batch,128+cond_1d_size+16,1,4]\n",
    "\n",
    "            h3 = self.cnn2(h2)                      #[batch,128,1,8]\n",
    "            h3 = conv_cond_concat(h3,cond_1d)       #[batch,128+cond_1d_size,1,8]\n",
    "            h3 = conv_prev_concat(h3,cond1)         #[batch,128+cond_1d_size+16,1,8]\n",
    "\n",
    "            h4 = self.cnn3(h3)                      #[batch,128,1,16]\n",
    "            h4 = conv_cond_concat(h4,cond_1d)       #[batch,128+cond_1d_size,1,16]\n",
    "            h4 = conv_prev_concat(h4,cond0)         #[batch,128+cond_1d_size+16,1,16]\n",
    "\n",
    "            out = self.cnn4(h4)             #[batch,instrument_size,128,16]\n",
    "\n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4727b52",
   "metadata": {
    "id": "a4727b52"
   },
   "source": [
    "### The Discriminator\n",
    "\n",
    "The discriminator uses `Conv2d` (sampling) layers to produce a scalar output from a bar input. Start with two `Conv2d` layers that reduce the size of the input, then use two `Dense` layers. We use  the `LeakyReLU` activation for each layer, except the output layer which can use `Sigmoid` to predict true-false probability value in the [0, 1] range. Note that the activation is included in the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e5cae21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinibatchDiscrimination(nn.Module):\n",
    "    def __init__(self, in_features, out_features, kernel_dim):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.kernel_dim = kernel_dim\n",
    "        self.T = nn.Parameter(torch.randn(in_features, out_features, kernel_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is batch_sizexA\n",
    "        # T is AxBxC\n",
    "        matrices = x @ self.T.view(self.in_features, -1)                # matrix moltiplication, result shape: [batch_size, B*C]\n",
    "        matrices = matrices.view(-1, self.out_features, self.kernel_dim)    #M shape [batch, B, C]\n",
    "\n",
    "        # compute L1 distances between samples\n",
    "        M = matrices.unsqueeze(0)  # [1,batch,B,C]\n",
    "        M_T = M.permute(1, 0, 2, 3)  # [batch,1,B,C]\n",
    "        norm = torch.abs(M - M_T).sum(3)  # first broadcast [batch,batch,B,C], then [batch,batch,B]\n",
    "        cbij = torch.exp(-norm)\n",
    "        o_b = cbij.sum(0)   # [batch,B], if j !=0 i in teh sum then subtract self distance (cbij.sum(0) - 1)\n",
    "\n",
    "        x = torch.cat([x, o_b], 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6646d974",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1752583243006,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "6646d974"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, cond_1d_size, instrument_size=1, mini_size=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.instrument_size = instrument_size\n",
    "        self.cond1d_dim = cond_1d_size\n",
    "\n",
    "        #as said in the DCGAN paper always batchnorm in the discriminator layers excluded the first layer\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(2*instrument_size+cond_1d_size, 32, kernel_size=(128,2), stride=(2,2), padding=0),        #[batch,32,1,8]\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        #+condition [batch,14+cond_1d_size,1,8]\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv2d(32+cond_1d_size, 77, kernel_size=(1,4), stride=2, padding=0),                             #[batch,77,1,3]\n",
    "            #Adding residual block\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "        self.ffnn1 = nn.Sequential(\n",
    "             #+condition [batch,231+cond_1d_size]\n",
    "            nn.Linear(231+cond_1d_size, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        self.minibatch = MinibatchDiscrimination(in_features=1024, out_features=mini_size,kernel_dim=3)\n",
    "\n",
    "        #+condition [batch,1024+mini_size+cond_1d_size]\n",
    "        self.ffnn2 = nn.Linear(1024+cond_1d_size+mini_size, 1)      #no sigmoid activation function because it is already in the definition of the cross entropy loss function\n",
    "\n",
    "\n",
    "    def forward(self, x, prev_bar, cond_1d):\n",
    "        input = conv_cond_concat(x,cond_1d)         #[batch,instrument_size+cond_1d_size,128,16]\n",
    "        input = conv_prev_concat(input,prev_bar)    #[batch,2*instrument_size+cond_1d_size,128,16]\n",
    "\n",
    "        h0 = self.cnn1(input)                       #[batch,14,1,8]\n",
    "        fm = h0\n",
    "        h0 = conv_cond_concat(h0, cond_1d)          #[batch,14+cond_1d_size,1,8]\n",
    "\n",
    "        h1 = self.cnn2(h0)                          #[batch,77,1,3]\n",
    "        h1 = torch.flatten(h1, 1)                   #[batch,77*3*1]\n",
    "        h1 = torch.cat((h1,cond_1d),dim=1)          #[batch,231+cond_1d_size]\n",
    "\n",
    "        h2 = self.ffnn1(h1)                         #[batch,1024]\n",
    "        h2 = self.minibatch(h2)                     #[batch,1024+mini_size]\n",
    "        h2 = torch.cat((h2,cond_1d),dim=1)          #[batch,1024+mini_size+cond_1d_size]\n",
    "\n",
    "        h3 = self.ffnn2(h2)                         #[batch,1]\n",
    "        h3_sigmoid = torch.sigmoid(h3)\n",
    "\n",
    "\n",
    "        return h3_sigmoid, h3, fm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d02a387",
   "metadata": {
    "id": "8d02a387"
   },
   "source": [
    "### Weights initialization\n",
    "\n",
    "Is this ok?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9237a67a",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752583243006,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "9237a67a"
   },
   "outputs": [],
   "source": [
    "# def weights_init(m):\n",
    "#     classname = m.__class__.__name__\n",
    "#     if classname.find('Conv') != -1:\n",
    "#         nn.init.xavier_uniform_(m.weight.data)*0\n",
    "#     if classname.find('Linear') != -1:\n",
    "#         nn.init.xavier_uniform_(m.weight.data)*0\n",
    "#     elif classname.find('BatchNorm') != -1:\n",
    "#         nn.init.normal_(m.weight.data, 1.0, 0.2)*0\n",
    "#         nn.init.constant_(m.bias.data, 0)*0\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.ConvTranspose2d, nn.Conv2d)):\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)  # DCGAN standard\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9059e917",
   "metadata": {
    "id": "9059e917"
   },
   "source": [
    "### Creation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64e61f6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1752583243012,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "64e61f6a",
    "outputId": "8b8629be-30e1-4679-fc01-f66e513213bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (ff1): Sequential(\n",
       "    (0): Linear(in_features=102, out_features=1024, bias=True)\n",
       "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (ff2): Sequential(\n",
       "    (0): Linear(in_features=1026, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (cnn1): Sequential(\n",
       "    (0): ConvTranspose2d(146, 128, kernel_size=(1, 2), stride=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (cnn2): Sequential(\n",
       "    (0): ConvTranspose2d(146, 128, kernel_size=(1, 2), stride=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (cnn3): Sequential(\n",
       "    (0): ConvTranspose2d(146, 128, kernel_size=(1, 2), stride=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (cnn4): Sequential(\n",
       "    (0): ConvTranspose2d(146, 1, kernel_size=(128, 1), stride=(2, 1), bias=False)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       "  (h0_prev): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(128, 1), stride=(2, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (h1_prev): Sequential(\n",
       "    (0): Conv2d(16, 16, kernel_size=(1, 2), stride=(2, 2))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (h2_prev): Sequential(\n",
       "    (0): Conv2d(16, 16, kernel_size=(1, 2), stride=(2, 2))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (h3_prev): Sequential(\n",
       "    (0): Conv2d(16, 16, kernel_size=(1, 2), stride=(2, 2))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if Mono:\n",
    "  generator = Generator(input_size=100, cond_1d_size=2, instrument_size=1, n_hlayers=128)\n",
    "else:\n",
    "  generator = Generator(input_size=100, cond_1d_size=5, instrument_size=4, n_hlayers=128)\n",
    "generator.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "307a37f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1752583243021,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "307a37f6",
    "outputId": "308c1fd6-2907-45c4-b81d-02d6fe727ed4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (cnn1): Sequential(\n",
       "    (0): Conv2d(4, 32, kernel_size=(128, 2), stride=(2, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (cnn2): Sequential(\n",
       "    (0): Conv2d(34, 77, kernel_size=(1, 4), stride=(2, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (ffnn1): Sequential(\n",
       "    (0): Linear(in_features=233, out_features=1024, bias=True)\n",
       "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (minibatch): MinibatchDiscrimination()\n",
       "  (ffnn2): Linear(in_features=1126, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if Mono:\n",
    "  discriminator = Discriminator(cond_1d_size=2, instrument_size=1)\n",
    "else:\n",
    "  discriminator = Discriminator(cond_1d_size=5, instrument_size=4)\n",
    "discriminator.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a4dac3",
   "metadata": {
    "id": "d6a4dac3"
   },
   "source": [
    "### Dimension testing\n",
    "\n",
    "Produce a noise vector of size `[10, 100]`, a noise 1d condition vector of size `[10, 15]`, and a noise 2d condition tensor of size `[10, 1, 128,16]`. Note that we need a 1d and a 2d contions for each batch input. Then we use the (as yet **untrained**) generator to create an image of expected output shape $[10,1,128,16]$.\n",
    "\n",
    "Then use the (yet **untrained**) discriminator to classify the generated images as real or fake. The model will be trained to output the probability that the image is real in the first output component, thus we expect an output vector of size `[10, 1]` with $x_i \\in [0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4075ff07",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1752583243043,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "4075ff07",
    "outputId": "f94b2760-d3c8-46a3-c40b-95a04dccc008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100])\n",
      "torch.Size([10, 1, 128, 16])\n",
      "tensor([[0.5589],\n",
      "        [0.4341],\n",
      "        [0.4864],\n",
      "        [0.4527],\n",
      "        [0.4345],\n",
      "        [0.5425],\n",
      "        [0.5500],\n",
      "        [0.6758],\n",
      "        [0.5818],\n",
      "        [0.4807]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "############################ input (batch_size=10, vector_size=100) ###############################\n",
    "noise = torch.normal(0, 1, [10, 100])\n",
    "print(noise.shape)\n",
    "############################ conditions ###############################\n",
    "if Mono:\n",
    "  cond_1d = torch.normal(0,1,[10,2])\n",
    "  prev_bar = torch.normal(0, 1, [10, 1, 128, 16])\n",
    "else:\n",
    "  cond_1d = torch.normal(0,1,[10,5])\n",
    "  prev_bar = torch.normal(0, 1, [10, 4, 128, 16])\n",
    "\n",
    "\n",
    "############################ generator ###############################\n",
    "generated_bar = generator(noise, prev_bar, cond_1d, batch_size=10).detach()\n",
    "print(generated_bar.shape)\n",
    "############################ discriminator ###############################\n",
    "decision, __, __= discriminator(generated_bar, prev_bar, cond_1d)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e8b2ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5314, 0.4836, 0.6253,  ..., 0.5552, 0.5160, 0.5786],\n",
       "        [0.4991, 0.5616, 0.4992,  ..., 0.5588, 0.4991, 0.5361],\n",
       "        [0.5091, 0.4356, 0.4559,  ..., 0.4777, 0.5257, 0.5121],\n",
       "        ...,\n",
       "        [0.4715, 0.5244, 0.4097,  ..., 0.5152, 0.4957, 0.4581],\n",
       "        [0.5343, 0.5090, 0.4927,  ..., 0.5172, 0.4933, 0.5475],\n",
       "        [0.5330, 0.4966, 0.4665,  ..., 0.5575, 0.4819, 0.5316]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_bar[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cf78a3",
   "metadata": {
    "id": "26cf78a3"
   },
   "source": [
    "### Discriminator loss\n",
    "\n",
    "This method quantifies how well the discriminator is able to distinguish real images from fakes. It compares the discriminator's predictions on real images to an array of 1s, and the discriminator's predictions on fake (generated) images to an array of 0s.\n",
    "The discriminator loss is of the form:\n",
    "\n",
    "$\\frac{1}{m}\\sum_{i=1}^{m}-[\\log D(\\boldsymbol{x}^{(i)}) +\\log(1-D(G(\\boldsymbol{z}^{(i)})))]$\n",
    "\n",
    "We inplement one-sided label smoothing to penalize self confidence and imporve the convergence of the training. Thus we substitute the discriminator's predictions on real images to an array of 1s with an array of (1-$\\alpha$)s and the loss function becomes:\n",
    "\n",
    "$\\frac{1}{m}\\sum_{i=1}^{m}-[(1-\\alpha) \\log D(\\boldsymbol{x}^{(i)}) +\\alpha \\log (1-D(\\boldsymbol{x}^{(i)}))+\\log(1-D(G(\\boldsymbol{z}^{(i)})))]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa9329bd",
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1752583243086,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "fa9329bd"
   },
   "outputs": [],
   "source": [
    "cross_entropy = nn.BCEWithLogitsLoss()\n",
    "MSE=nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "778a6afc",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1752583243092,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "778a6afc"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output, device, alpha=0.1):\n",
    "\n",
    "    #real_targets = torch.ones_like(real_output, device=device)                 #no label smoothing -> True output expected output is 1\n",
    "    real_targets = torch.full_like(real_output, 1.0 - alpha, device=device)     #one side label smoothing to penalize self confidence\n",
    "    fake_targets = torch.zeros_like(fake_output, device=device)                 #no label smoothing -> Fake output expected output is 0\n",
    "\n",
    "    real_loss = cross_entropy(real_output, real_targets)\n",
    "    fake_loss = cross_entropy(fake_output, fake_targets)\n",
    "\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04bd362",
   "metadata": {
    "id": "f04bd362"
   },
   "source": [
    "### Generator loss\n",
    "\n",
    "The generator's loss quantifies how well it was able to trick the discriminator. Intuitively, if the generator is performing well, the discriminator will classify the fake images as real (or 1).\n",
    "The generator loss is of the form:\n",
    "\n",
    "$\\frac{1}{m}\\sum_{i=1}^{m}\\log(1-D(G(\\boldsymbol{z}^{(i)})))$\n",
    "\n",
    "However this loss has some convergence issues due to vanishing gradients. So instead we use the following loss which has the same trend but stronger gradient when the discriminator is too good at recognizing fake samples.\n",
    "\n",
    "$\\frac{1}{m}\\sum_{i=1}^{m}-\\log(D(G(\\boldsymbol{z}^{(i)})))$\n",
    "\n",
    "Which is the Binary crossentropy between $D(G(\\boldsymbol{z}^{(i)}))$ and the probability distribution that has $y^{(i)} = 1 \\forall i$, i.e. we are forcing the generator to produce samples that will make the discriminator predict that fake samples are real.\n",
    "\n",
    "Moreover we add a regularizer term so-called feature matching such that the distributions of the real and generated data are enforced to be close.\n",
    "\n",
    "$\\lambda_1 ||E_{x \\sim p(x)} [x] - E_{z\\sim p(z)} [G(z)] ||^2 + \\lambda_2 ||E_{x \\sim p(x)} [f(x)] - E_{z \\sim p(z)} [f(G(z))] ||^2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "367712ab",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1752583243102,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "367712ab"
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output, real_bar, fake_bar, real_f, fake_f, device, lambda1=0.1, lambda2=0.01):\n",
    "\n",
    "    gen_loss = cross_entropy(fake_output, torch.ones_like(fake_output, device=device))\n",
    "\n",
    "    mean_real = torch.mean(real_bar, dim=0)\n",
    "    mean_fake = torch.mean(fake_bar, dim=0)\n",
    "    l2_data = MSE(mean_real, mean_fake)\n",
    "\n",
    "    mean_real_feat = torch.mean(real_f, dim=0)\n",
    "    mean_fake_feat = torch.mean(fake_f, dim=0)\n",
    "    l2_feat = MSE(mean_real_feat, mean_fake_feat)\n",
    "\n",
    "    return gen_loss+lambda1*l2_data+lambda2*l2_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873c39af",
   "metadata": {
    "id": "873c39af"
   },
   "source": [
    "### Optimizers\n",
    "\n",
    "With DCGAN the training is very diffuclt so we decide to use Adam optimizer as suggested by the paper. Note that with Adam we use both momentum and RMSprop to normalized velocities. Discriminator and generator need two different optimizers (conditioner is included in the generator training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3bc9be6",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1752583243104,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "e3bc9be6"
   },
   "outputs": [],
   "source": [
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "gen_opt = optim.Adam(generator.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "dis_opt = optim.Adam(discriminator.parameters(), lr=4e-4, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a476d",
   "metadata": {
    "id": "5c2a476d"
   },
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1216184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LossPenalty(GenBars, ActualLoss):\n",
    "\n",
    "   mean = GenBars.mean().item()\n",
    "   BinaryBar = (GenBars > mean).float().squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "   ActiveNotes = np.sum(BinaryBar, axis = 0)\n",
    "\n",
    "   Notes = (ActiveNotes > 5)\n",
    "   Sums = np.sum(Notes)\n",
    "\n",
    "   #PenaltyTerm on the loss if more that 5 notes are active at the same time\n",
    "   PenaltyTerm = ActualLoss + 0.05*ActualLoss*Sums\n",
    "\n",
    "   return PenaltyTerm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "Y8NU6yHm9LFZ",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1752583441187,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "Y8NU6yHm9LFZ"
   },
   "outputs": [],
   "source": [
    "def train_step(bars, cond_1d, prev_bar, generator, discriminator, batch_size,\n",
    "               noise_dim, device, dis_opt, gen_opt):\n",
    "    # --- Ensure all tensors are on the correct device ---\n",
    "    bars = bars.to(device)\n",
    "    cond_1d = cond_1d.to(device)\n",
    "    prev_bar = prev_bar.to(device)\n",
    "\n",
    "    # --- Discriminator training ---\n",
    "    noise = torch.randn([batch_size, noise_dim], device=device)\n",
    "\n",
    "    bars_noise = bars + torch.randn_like(bars) * 0.1\n",
    "    bars_noise = torch.clamp(bars_noise, 0, 1)\n",
    "\n",
    "    # Generate fake samples\n",
    "    generated_bars = generator(noise, prev_bar, cond_1d, batch_size)\n",
    "\n",
    "    # Forward pass (real + fake)\n",
    "    real_output, real_D, _ = discriminator(bars_noise, prev_bar, cond_1d)\n",
    "    fake_output, fake_D, _ = discriminator(generated_bars.detach(), prev_bar, cond_1d)\n",
    "\n",
    "    # Discriminator loss\n",
    "    disc_loss = discriminator_loss(real_D, fake_D, device)\n",
    "    discriminator.zero_grad()\n",
    "    disc_loss.backward()\n",
    "    dis_opt.step()\n",
    "\n",
    "    # --- Generator training (2 steps) ---\n",
    "    gen_losses = []\n",
    "    for _ in range(1):  # Consistent 2:1 update ratio\n",
    "        noise = torch.randn([batch_size, noise_dim], device=device)\n",
    "        generated_bars = generator(noise, prev_bar, cond_1d, batch_size)\n",
    "        _, fake_D, fake_fm = discriminator(generated_bars, prev_bar, cond_1d)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, real_D, real_fm = discriminator(bars_noise, prev_bar, cond_1d)\n",
    "\n",
    "        gen_loss = generator_loss(fake_D, bars, generated_bars, real_fm, fake_fm, device)\n",
    "\n",
    "        generator.zero_grad()\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "        gen_losses.append(gen_loss.item())\n",
    "\n",
    "    return sum(gen_losses) / len(gen_losses), disc_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3313e656",
   "metadata": {
    "id": "3313e656"
   },
   "source": [
    "supponendo che nel dataloader ogni dato sia una bar + la preavious bar + 1d condition sugli strumenti utilizzati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a670270f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "executionInfo": {
     "elapsed": 282,
     "status": "error",
     "timestamp": 1752583441471,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "a670270f",
    "outputId": "75d763e9-453e-4ca2-9f26-08f62701f198"
   },
   "outputs": [],
   "source": [
    "gloss = []\n",
    "dloss = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    start = time.time()\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    gen_losses = []\n",
    "    disc_losses = []\n",
    "    print('#################')\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "\n",
    "    iterator = tqdm(dataloader)\n",
    "    for bar_batch, prev_bar_batch, instrument_batch in iterator:\n",
    "        bar_batch = bar_batch.to(dtype=torch.float32, device=device)\n",
    "        prev_bar_batch = prev_bar_batch.to(dtype=torch.float32, device=device)\n",
    "        instrument_batch = instrument_batch.to(dtype=torch.float32, device=device)\n",
    "        #instrument_batch = torch.zeros_like(cond_1d)\n",
    "\n",
    "        if Mono:\n",
    "            bar_batch = bar_batch.unsqueeze(1)\n",
    "            prev_bar_batch=prev_bar_batch.unsqueeze(1)\n",
    "\n",
    "        gen_loss, disc_loss = train_step(bar_batch, instrument_batch, prev_bar_batch, generator, discriminator,\n",
    "                                         BATCH_SIZE, noise_dim, device, dis_opt, gen_opt)\n",
    "        gen_losses.append(gen_loss)\n",
    "        disc_losses.append(disc_loss)\n",
    "\n",
    "        iterator.set_description('Discriminator loss: {}, Generator loss: {}'.format(disc_loss, gen_loss))\n",
    "\n",
    "    gloss.append(np.mean(gen_losses))\n",
    "    dloss.append(np.mean(disc_losses))\n",
    "    #print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "    print(f'dLoss: {dloss[-1]}, gLoss: {gloss[-1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60125f78",
   "metadata": {
    "id": "60125f78"
   },
   "source": [
    "### Weights and loss analysis\n",
    "\n",
    "First let's plot the 2 losses over the epochs, if it works correctly the generator loss would have to decrease and the discriminator one would have to increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a427ac8",
   "metadata": {
    "executionInfo": {
     "elapsed": 200162,
     "status": "aborted",
     "timestamp": 1752583441516,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "1a427ac8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(gloss, label='Generator loss')\n",
    "plt.plot(dloss, label='Discriminator loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "afdace0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 50/50 [00:08<00:00,  5.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from Preprocessing import *\n",
    "from PolyphonicPreprocessing import *\n",
    "\n",
    "TEMPO_MIN, TEMPO_MAX = 60, 200  # Typical tempo range\n",
    "PROGRAM_MIN, PROGRAM_MAX = 1, 128  # MIDI program range\n",
    "\n",
    "def NormCond(tempo, programs, Mono):\n",
    "\n",
    "   tempo_norm = (tempo - TEMPO_MIN) / (TEMPO_MAX - TEMPO_MIN)\n",
    "    \n",
    "   if Mono:\n",
    "      programs_norm = (programs - PROGRAM_MIN) / (PROGRAM_MAX - PROGRAM_MIN)\n",
    "      return [tempo_norm] + [programs_norm]\n",
    "   else:\n",
    "      programs_norm = [(p - PROGRAM_MIN) / (PROGRAM_MAX - PROGRAM_MIN) for p in programs]\n",
    "      return [tempo_norm] + programs_norm\n",
    "    \n",
    "   \n",
    "if Mono:\n",
    "   Dataset = PreProcessing(nDir = 50)\n",
    "   \n",
    "else:\n",
    "   Dataset = PolyphonicPreProcessing(nDir = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1420d77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU available')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('GPU not available')\n",
    "\n",
    "\n",
    "def LoadModel(Cond1D_Size, instrumentSize, Which):\n",
    "\n",
    "    Path = os.path.realpath('ModelParameters')\n",
    "\n",
    "    files = [\n",
    "        ['MonoGenParam.torch', 'MonoGenState.torch'],\n",
    "        ['Tradgenerator_parameters.torch', 'Tradgen_opt_state.torch']\n",
    "    ]\n",
    "\n",
    "    generator = Generator(input_size=100, cond_1d_size=Cond1D_Size, instrument_size=instrumentSize, n_hlayers=128)\n",
    "    generator.apply(weights_init)\n",
    "    generator.to(device)\n",
    "    # Load the state dict previously saved\n",
    "    generator_state_dict = torch.load(os.path.join(Path, files[Which][0]), map_location=torch.device('cpu'))\n",
    "    # Update the network parameters\n",
    "    generator.load_state_dict(generator_state_dict)\n",
    "\n",
    "    gen_opt = optim.Adam(generator.parameters(), lr=2e-4)\n",
    "    # Load the state dict previously saved\n",
    "    gen_opt_state_dict = torch.load(os.path.join(Path, files[Which][1]), map_location=torch.device('cpu'))\n",
    "    # Update the network parameters\n",
    "    gen_opt.load_state_dict(gen_opt_state_dict)\n",
    "\n",
    "    return generator\n",
    "\n",
    "                                                    #MOnophonic or polyphonic\n",
    "generator = LoadModel(Cond1D_Size=2, instrumentSize=1, Which=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3fc84211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.058473140001297 0.11776655167341232\n",
      "0.06295771896839142 0.11104864627122879\n",
      "0.06010415032505989 0.09906728565692902\n",
      "0.06128225475549698 0.10777265578508377\n",
      "0.061425499618053436 0.12277766317129135\n",
      "0.06467550992965698 0.13677825033664703\n",
      "0.06275027245283127 0.13554862141609192\n",
      "0.05936496704816818 0.13570091128349304\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "generator.eval().to(device)\n",
    "\n",
    "bar = np.random.randint(0, 100)\n",
    "\n",
    "if Mono:\n",
    "   Instrument = 'Piano'\n",
    "   prev_bar = Dataset[Instrument][bar]['Bars'][0].to_dense().float().to(device)\n",
    "   InstrumentCode = Dataset[Instrument][bar]['Program']\n",
    "   Tempo = Dataset[Instrument][bar]['Tempo'][0]\n",
    "\n",
    "else:\n",
    "   Genre = 'rock'\n",
    "   prev_bar = Dataset[Genre][bar]['Bars'][0].to_dense().float().to(device)\n",
    "   InstrumentCode = Dataset[Genre][bar]['Program'][0]\n",
    "   Tempo = Dataset[Genre][bar]['Tempo'][0]\n",
    "\n",
    "cond_1d = torch.tensor([NormCond(Tempo, InstrumentCode, Mono)], dtype= torch.float32, device = device)\n",
    "Bars = []\n",
    "Bars.append(prev_bar)\n",
    "\n",
    "if Mono:\n",
    "   prev_bar = prev_bar.unsqueeze(0).unsqueeze(0) \n",
    "else:\n",
    "   prev_bar = prev_bar.unsqueeze(0)\n",
    "\n",
    "\n",
    "for i in range(8):\n",
    "   noise = torch.rand([1, 100], device=device)*0.2\n",
    "\n",
    "   #print(np.mean(np.array(noise)))\n",
    "\n",
    "   with torch.no_grad():\n",
    "      generated_bar = generator(noise, prev_bar, cond_1d, 1)\n",
    "\n",
    "   mean = generated_bar.mean().item()\n",
    "   binary_bar = (generated_bar > 0.5).float()\n",
    "   if Mono: Bars.append(binary_bar.squeeze(0).squeeze(0).cpu().numpy()) \n",
    "   else:  Bars.append(binary_bar.squeeze(0).cpu().numpy()) \n",
    "   print(mean, generated_bar.std().item())\n",
    "   prev_bar = binary_bar.detach()\n",
    "\n",
    "\n",
    "\n",
    "if Mono:\n",
    "   ConcBars = np.concatenate(Bars, axis = 1)\n",
    "   MonoBarsToMIDI(ConcBars, title='Monotest', Instrument=InstrumentCode)\n",
    "\n",
    "else:\n",
    "   PolyConcBars = np.concatenate(Bars, axis = 2)\n",
    "   PolyBarsToMIDI(PolyConcBars, title='Polytest', Instrument=InstrumentCode)\n",
    "\n",
    "\n",
    "print(InstrumentCode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f70a8b",
   "metadata": {
    "id": "51f70a8b"
   },
   "source": [
    "Save networks and optimizers states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c479e2c",
   "metadata": {
    "executionInfo": {
     "elapsed": 200163,
     "status": "aborted",
     "timestamp": 1752583441519,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "4c479e2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model\n",
      "Saved Optimizer\n"
     ]
    }
   ],
   "source": [
    "#torch.save(discriminator.state_dict(), 'discriminator_parameters.torch')\n",
    "torch.save(generator.state_dict(), 'generator_parameters.torch')\n",
    "print('Saved Model')\n",
    "\n",
    "#torch.save(dis_opt.state_dict(), 'dis_opt_state.torch')\n",
    "torch.save(gen_opt.state_dict(), 'gen_opt_state.torch')\n",
    "print('Saved Optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226da7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625776cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9eef31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_cond_concat(x, y):\n",
    "    \"\"\"Concatenate conditioning vector on feature map axis.\"\"\"\n",
    "    x_shapes = x.shape  #[batch,n_features,a,b]\n",
    "    y_shapes = y.shape  #[batch,n]\n",
    "    y2 = y.view(x_shapes[0],y_shapes[1],1,1)                              #[batch,n,1,1]\n",
    "    y2 = y2.expand(x_shapes[0],y_shapes[1],x_shapes[2],x_shapes[3])      #[batch,n,a,b]\n",
    "\n",
    "    return torch.cat((x, y2),dim=1)                                     #[batch,n_features+n,a,b]\n",
    "\n",
    "def conv_prev_concat(x, y):\n",
    "    \"\"\"Concatenate conditioning vector on feature map axis.\"\"\"\n",
    "    x_shapes = x.shape  #[batch,n_features,a,b]\n",
    "    y_shapes = y.shape  #[batch,16,a,b]\n",
    "    if x_shapes[2:] == y_shapes[2:]:\n",
    "        y2 = y.expand(x_shapes[0],y_shapes[1],x_shapes[2],x_shapes[3])  #[batch,16,a,b]\n",
    "\n",
    "        return torch.cat((x, y2),dim=1)                                 #[batch,n_features+16,a,b]\n",
    "\n",
    "    else:\n",
    "        print(x_shapes[2:])\n",
    "        print(y_shapes[2:])\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.2)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a78515a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, cond_1d_size, instrument_size=1, n_hlayers=128):\n",
    "            super().__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.instrument_size = instrument_size\n",
    "            self.cond1d_dim = cond_1d_size\n",
    "\n",
    "            #generator layers\n",
    "            #as said in the DCGAN paper always ReLU activation function in the generator excluded the last layer\n",
    "            #as said in the DCGAN paper always batchnorm iin the generator excluded the last layer\n",
    "            self.ff1 = nn.Sequential(\n",
    "                nn.Linear(input_size+cond_1d_size, 1024),                                                               #[batch,1024]\n",
    "                nn.BatchNorm1d(1024),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            self.ff2 = nn.Sequential(\n",
    "                nn.Linear(1024+cond_1d_size,n_hlayers*2),                                                                                    #[batch,512]\n",
    "                nn.BatchNorm1d(n_hlayers*2),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #reshape to [batch size,128,1,2]\n",
    "            # #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn1 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,4]\n",
    "                nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn2 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,8]\n",
    "                nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn3 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,16]\n",
    "                nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn4 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, instrument_size, kernel_size=(128,1), stride=(2,1), bias=False, padding=0),       #[batch,instrument_size,128,16]\n",
    "                nn.Sigmoid()\n",
    "                #Sigmoid funciotn because we want to generate the matrixes of music without velocity, i.e. only (0,1)\n",
    "                #Thus we use the sigmoid which is a smoother version of the sign function\n",
    "                )\n",
    "            #conditioner layers\n",
    "            # #as in Midinet model we use the Leaky activation funciton for the conditioner\n",
    "            self.h0_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=instrument_size, out_channels=16, kernel_size=(128,1), stride=(2,1)),                  #[batch,16,1,16]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()          #note: in the original paper leak=0.2, default leak=0.01\n",
    "                )\n",
    "            self.h1_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,8]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "            self.h2_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,4]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "            self.h3_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,2]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "\n",
    "    def forward(self, z, prev_bar, cond_1d, batch_size):\n",
    "\n",
    "            #2d condiiton\n",
    "            cond0 = self.h0_prev(prev_bar)          #[batch,16,1,16]\n",
    "            cond1 = self.h1_prev(cond0)             #[batch,16,1,8]\n",
    "            cond2 = self.h2_prev(cond1)             #[batch,16,1,4]\n",
    "            cond3 = self.h3_prev(cond2)             #[batch,16,1,2]\n",
    "\n",
    "            #single cond_1d size =[n,1], batch_cond_1d size = [batch_size,n]\n",
    "\n",
    "            input = torch.cat((z,cond_1d), dim=1)   #[batch_size, input_size+cond_1d_size]\n",
    "\n",
    "            h0 = self.ff1(input)                    #[batch,1024]\n",
    "            h0 = torch.cat((h0,cond_1d), dim=1)     #[batch,1024+cond_1d_size]\n",
    "\n",
    "            h1 = self.ff2(h0)                       #[batch,256]\n",
    "            h1 = h1.reshape(batch_size, 128, 1, 2)  #[batch,128,1,2]\n",
    "            h1 = conv_cond_concat(h1,cond_1d)       #[batch,128+cond_1d_size,1,2]\n",
    "            h1 = conv_prev_concat(h1,cond3)         #[batch,128+cond_1d_size+16,1,2]\n",
    "\n",
    "            h2 = self.cnn1(h1)                      #[batch,128,1,4]\n",
    "            h2 = conv_cond_concat(h2,cond_1d)       #[batch,128+cond_1d_size,1,4]\n",
    "            h2 = conv_prev_concat(h2,cond2)         #[batch,128+cond_1d_size+16,1,4]\n",
    "\n",
    "            h3 = self.cnn2(h2)                      #[batch,128,1,8]\n",
    "            h3 = conv_cond_concat(h3,cond_1d)       #[batch,128+cond_1d_size,1,8]\n",
    "            h3 = conv_prev_concat(h3,cond1)         #[batch,128+cond_1d_size+16,1,8]\n",
    "\n",
    "            h4 = self.cnn3(h3)                      #[batch,128,1,16]\n",
    "            h4 = conv_cond_concat(h4,cond_1d)       #[batch,128+cond_1d_size,1,16]\n",
    "            h4 = conv_prev_concat(h4,cond0)         #[batch,128+cond_1d_size+16,1,16]\n",
    "\n",
    "            out = self.cnn4(h4)                     #[batch,instrument_size,128,16]\n",
    "\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "973a5ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU available')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('GPU not available')\n",
    "\n",
    "\n",
    "def LoadModel(Cond1D_Size, instrumentSize, Which):\n",
    "\n",
    "    Path = os.path.realpath('ModelParameters')\n",
    "\n",
    "    files = [\n",
    "        ['GenParam2.torch', 'GenState2.torch'],\n",
    "        ['Tradgenerator_parameters.torch', 'Tradgen_opt_state.torch']\n",
    "    ]\n",
    "\n",
    "    generator = Generator(input_size=100, cond_1d_size=Cond1D_Size, instrument_size=instrumentSize, n_hlayers=128)\n",
    "    generator.apply(weights_init)\n",
    "    generator.to(device)\n",
    "    # Load the state dict previously saved\n",
    "    generator_state_dict = torch.load(os.path.join(Path, files[Which][0]), map_location=torch.device('cpu'))\n",
    "    # Update the network parameters\n",
    "    generator.load_state_dict(generator_state_dict)\n",
    "\n",
    "    gen_opt = optim.Adam(generator.parameters(), lr=2e-4)\n",
    "    # Load the state dict previously saved\n",
    "    gen_opt_state_dict = torch.load(os.path.join(Path, files[Which][1]), map_location=torch.device('cpu'))\n",
    "    # Update the network parameters\n",
    "    gen_opt.load_state_dict(gen_opt_state_dict)\n",
    "\n",
    "    return generator\n",
    "\n",
    "                                                    #MOnophonic or polyphonic\n",
    "generator = LoadModel(Cond1D_Size=2, instrumentSize=1, Which=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ade17df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 50/50 [00:11<00:00,  4.29it/s]\n"
     ]
    }
   ],
   "source": [
    "from Preprocessing import *\n",
    "from PolyphonicPreprocessing import *\n",
    "\n",
    "Mono = True\n",
    "\n",
    "TEMPO_MIN, TEMPO_MAX = 60, 200  # Typical tempo range\n",
    "PROGRAM_MIN, PROGRAM_MAX = 1, 128  # MIDI program range\n",
    "\n",
    "def NormCond(tempo, programs, Mono):\n",
    "\n",
    "   tempo_norm = (tempo - TEMPO_MIN) / (TEMPO_MAX - TEMPO_MIN)\n",
    "    \n",
    "   if Mono:\n",
    "      programs_norm = (programs - PROGRAM_MIN) / (PROGRAM_MAX - PROGRAM_MIN)\n",
    "      return [tempo_norm] + [programs_norm]\n",
    "   else:\n",
    "      programs_norm = [(p - PROGRAM_MIN) / (PROGRAM_MAX - PROGRAM_MIN) for p in programs]\n",
    "      return [tempo_norm] + programs_norm\n",
    "    \n",
    "   \n",
    "if Mono:\n",
    "   Dataset = PreProcessing(nDir = 50)\n",
    "   \n",
    "else:\n",
    "   Dataset = PolyphonicPreProcessing(nDir = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5545c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.040474969893693924 0.037288520485162735\n",
      "0.040903884917497635 0.0352741964161396\n",
      "0.04287290945649147 0.037068646401166916\n",
      "0.043481361120939255 0.037733808159828186\n",
      "0.045786239206790924 0.04097752645611763\n",
      "0.04072435945272446 0.03596627712249756\n",
      "0.04181244224309921 0.03568676859140396\n",
      "0.044527165591716766 0.03919471427798271\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "generator.eval().to(device)\n",
    "\n",
    "bar = np.random.randint(0, 100)\n",
    "\n",
    "if Mono:\n",
    "   Instrument = 'Piano'\n",
    "   prev_bar = Dataset[Instrument][bar]['Bars'][0].to_dense().float().to(device)\n",
    "   InstrumentCode = Dataset[Instrument][bar]['Program']\n",
    "   Tempo = Dataset[Instrument][bar]['Tempo'][0]\n",
    "\n",
    "else:\n",
    "   Genre = 'rock'\n",
    "   prev_bar = Dataset[Genre][bar]['Bars'][0].to_dense().float().to(device)\n",
    "   InstrumentCode = Dataset[Genre][bar]['Program'][0]\n",
    "   Tempo = Dataset[Genre][bar]['Tempo'][0]\n",
    "\n",
    "cond_1d = torch.tensor([NormCond(Tempo, InstrumentCode, Mono)], dtype= torch.float32, device = device)\n",
    "Bars = []\n",
    "Bars.append(prev_bar)\n",
    "\n",
    "if Mono:\n",
    "   prev_bar = prev_bar.unsqueeze(0).unsqueeze(0) \n",
    "else:\n",
    "   prev_bar = prev_bar.unsqueeze(0)\n",
    "\n",
    "\n",
    "for i in range(8):\n",
    "   noise = torch.rand([1, 100], device=device)\n",
    "\n",
    "   #print(np.mean(np.array(noise)))\n",
    "\n",
    "   with torch.no_grad():\n",
    "      generated_bar = generator(noise, prev_bar, cond_1d, 1)\n",
    "\n",
    "   mean = generated_bar.mean().item()\n",
    "   binary_bar = (generated_bar > 0.5).float()\n",
    "   if Mono: Bars.append(binary_bar.squeeze(0).squeeze(0).cpu().numpy()) \n",
    "   else:  Bars.append(binary_bar.squeeze(0).cpu().numpy()) \n",
    "   print(mean, generated_bar.std().item())\n",
    "   prev_bar = binary_bar.detach()\n",
    "\n",
    "\n",
    "\n",
    "if Mono:\n",
    "   ConcBars = np.concatenate(Bars, axis = 1)\n",
    "   MonoBarsToMIDI(ConcBars, title='Monotest1', Instrument=InstrumentCode)\n",
    "\n",
    "else:\n",
    "   PolyConcBars = np.concatenate(Bars, axis = 2)\n",
    "   PolyBarsToMIDI(PolyConcBars, title='Polytest', Instrument=InstrumentCode)\n",
    "\n",
    "\n",
    "print(InstrumentCode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96e203a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Bars[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671be27a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
