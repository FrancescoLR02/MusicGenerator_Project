{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c35efb12",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1752583241686,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "c35efb12"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn #neural network module\n",
    "import torch.optim as optim #optimizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import time as time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "h9nnFhaJi3W1",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1752583242973,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "h9nnFhaJi3W1"
   },
   "outputs": [],
   "source": [
    "datasetpath=os.path.realpath('Dataset_CP.pt')\n",
    "PolDataset = os.path.realpath('PolyphonicDataset.pt')\n",
    "\n",
    "Mono = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "h8DZrVQOhioM",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1752583242974,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "h8DZrVQOhioM"
   },
   "outputs": [],
   "source": [
    "#Loading monophonic and polyphonic classes\n",
    "class MonophonicDataset(Dataset):\n",
    "\n",
    "   def __init__(self, Instruments):\n",
    "\n",
    "      DS = torch.load(datasetpath)\n",
    "      self.Data = []\n",
    "      self.Instruments = Instruments\n",
    "\n",
    "      for inst in Instruments:\n",
    "\n",
    "        self.Data.extend(DS[inst])\n",
    "\n",
    "      del DS\n",
    "      gc.collect()\n",
    "\n",
    "\n",
    "   def __len__(self):\n",
    "      return len(self.Data)\n",
    "\n",
    "   def __getitem__(self, idx):\n",
    "\n",
    "      PreviousBars = self.Data[idx]['Bars'][0].to_dense()\n",
    "      Bars = self.Data[idx]['Bars'][1].to_dense()\n",
    "\n",
    "      prog = self.Data[idx]['Program']\n",
    "      tempo = self.Data[idx]['Tempo'][0]\n",
    "\n",
    "      TEMPO_MIN, TEMPO_MAX = 60, 200\n",
    "      PROGRAM_MIN, PROGRAM_MAX = 1, 128\n",
    "\n",
    "      tempo_norm = (tempo - TEMPO_MIN) / (TEMPO_MAX - TEMPO_MIN)\n",
    "      prog_norm = (prog - PROGRAM_MIN) / (PROGRAM_MAX - PROGRAM_MIN)\n",
    "\n",
    "\n",
    "      Cond1D = torch.tensor([tempo_norm] + [prog_norm], dtype=torch.float, device=Bars.device)\n",
    "      return Bars, PreviousBars, Cond1D\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class PolyphonicDataset(Dataset):\n",
    "\n",
    "   def __init__(self, Genre):\n",
    "\n",
    "         DS = torch.load(PolDataset, weights_only=False)\n",
    "         self.Data = []\n",
    "         self.Genre = Genre\n",
    "\n",
    "         for gen in Genre:\n",
    "            self.Data.extend(DS[gen])\n",
    "\n",
    "         del DS\n",
    "         gc.collect()\n",
    "\n",
    "   def __len__(self):\n",
    "      return len(self.Data)\n",
    "\n",
    "   def __getitem__(self, idx):\n",
    "\n",
    "      PreviousBars = self.Data[idx]['Bars'][0].to_dense()\n",
    "      Bars = self.Data[idx]['Bars'][1].to_dense()\n",
    "\n",
    "      prog = self.Data[idx]['Program'][0]\n",
    "      tempo = self.Data[idx]['Tempo'][0]\n",
    "\n",
    "\n",
    "      TEMPO_MIN, TEMPO_MAX = 60, 200\n",
    "      PROGRAM_MIN, PROGRAM_MAX = 1, 128\n",
    "\n",
    "      tempo_norm = (tempo - TEMPO_MIN) / (TEMPO_MAX - TEMPO_MIN)\n",
    "      prog_norm = [(p - PROGRAM_MIN) / (PROGRAM_MAX - PROGRAM_MIN) for p in prog]\n",
    "\n",
    "\n",
    "      Cond1D = torch.tensor([tempo_norm] + prog_norm, dtype=torch.float, device=Bars.device)\n",
    "      return Bars, PreviousBars, Cond1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b90129f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1752583242975,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "b90129f7",
    "outputId": "cb9ff5a2-5eea-42c3-9bd6-9399046235cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU available')\n",
    "\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print('mps available')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('GPU not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45854c0",
   "metadata": {
    "id": "a45854c0"
   },
   "source": [
    "### Concatenation\n",
    "\n",
    "Definition of the concatenation functions that are used in the hidden layers to concatenate the output and the 1_d and 2_d conditions.\n",
    "\n",
    "1_d conditioning vector of shape $[n,1]$ with an output of shape $[batch,features,a,b]$:\n",
    "* first we have to duplicate the vector $a\\cdot b$ times to get a tensor of shape $[batch,n,a,b]$\n",
    "* then we can concatenate the two tensors in the depth dimension (i.e dim=1)\n",
    "\n",
    "2_d conditioning matrix of the same shape of the output $[batch,features,a,b]$ except the depth dim (it must be that because how we build the conditioner CNN):\n",
    "* first we check that the dimensions are correct\n",
    "* we concatenate the two tensors in the depth dimension (i.e dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1acf0ac5",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1752583242975,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "1acf0ac5"
   },
   "outputs": [],
   "source": [
    "def conv_cond_concat(x, y):\n",
    "    \"\"\"Concatenate conditioning vector on feature map axis.\"\"\"\n",
    "    x_shapes = x.shape  #[batch,n_features,a,b]\n",
    "    y_shapes = y.shape  #[batch,n]\n",
    "    y2 = y.view(x_shapes[0],y_shapes[1],1,1)                              #[batch,n,1,1]\n",
    "    y2 = y2.expand(x_shapes[0],y_shapes[1],x_shapes[2],x_shapes[3])      #[batch,n,a,b]\n",
    "\n",
    "    return torch.cat((x, y2),dim=1)                                     #[batch,n_features+n,a,b]\n",
    "\n",
    "def conv_prev_concat(x, y):\n",
    "    \"\"\"Concatenate conditioning vector on feature map axis.\"\"\"\n",
    "    x_shapes = x.shape  #[batch,n_features,a,b]\n",
    "    y_shapes = y.shape  #[batch,16,a,b]\n",
    "    if x_shapes[2:] == y_shapes[2:]:\n",
    "        y2 = y.expand(x_shapes[0],y_shapes[1],x_shapes[2],x_shapes[3])  #[batch,16,a,b]\n",
    "\n",
    "        return torch.cat((x, y2),dim=1)                                 #[batch,n_features+16,a,b]\n",
    "\n",
    "    else:\n",
    "        print(x_shapes[2:])\n",
    "        print(y_shapes[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dae68f7",
   "metadata": {
    "id": "5dae68f7"
   },
   "source": [
    "### The Generator and the Conditioner\n",
    "\n",
    "The generator uses `ConvTranspose2d` (upsampling) layers to produce an image from a seed (random noise). Start with two `Dense` layers that take this seed as input and transform it to a tensor of shape $[batch size,128,1,2]$, then upsample several times until we reach the desired size of a bar of $[instrument,128,16]$. We use  the `ReLU` activation for each layer, except the output layer which can use `Sigmoid` to predict pixel values in the [0, 1] range.\n",
    "\n",
    "Coupled to the generator there is the conditioner that uses `Conv2d` (sampling) layers to produce the 2_d tensors that serve as informations from the preaviou bar. The conditioner can be viewed as the reverse of the generator because it uses filters with the same shapes of the ones in the generator. In this case we use  the `LeakyReLU` activation for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a88728a6",
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1752583243005,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "a88728a6"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, cond_1d_size, instrument_size=1, n_hlayers=128):\n",
    "            super().__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.instrument_size = instrument_size\n",
    "            self.cond1d_dim = cond_1d_size\n",
    "\n",
    "            #generator layers\n",
    "            #as said in the DCGAN paper always ReLU activation function in the generator excluded the last layer\n",
    "            #as said in the DCGAN paper always batchnorm iin the generator excluded the last layer\n",
    "            self.ff1 = nn.Sequential(\n",
    "                nn.Linear(input_size+cond_1d_size, 1024),                                                               #[batch,1024]\n",
    "                nn.BatchNorm1d(1024),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            self.ff2 = nn.Sequential(\n",
    "                nn.Linear(1024+cond_1d_size,n_hlayers*2),                                                                                    #[batch,512]\n",
    "                nn.BatchNorm1d(n_hlayers*2),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #reshape to [batch size,128,1,2]\n",
    "            # #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn1 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,4]\n",
    "                nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn2 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,8]\n",
    "                nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn3 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,16]\n",
    "                nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn4 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, instrument_size, kernel_size=(128,1), stride=(2,1), bias=False, padding=0),       #[batch,instrument_size,128,16]\n",
    "                nn.Sigmoid()\n",
    "                #Sigmoid funciotn because we want to generate the matrixes of music without velocity, i.e. only (0,1)\n",
    "                #Thus we use the sigmoid which is a smoother version of the sign function\n",
    "                )\n",
    "            #conditioner layers\n",
    "            # #as in Midinet model we use the Leaky activation funciton for the conditioner\n",
    "            self.h0_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=instrument_size, out_channels=16, kernel_size=(128,1), stride=(2,1)),                  #[batch,16,1,16]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()          #note: in the original paper leak=0.2, default leak=0.01\n",
    "                )\n",
    "            self.h1_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,8]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "            self.h2_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,4]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "            self.h3_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,2]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "\n",
    "    def forward(self, z, prev_bar, cond_1d, batch_size):\n",
    "\n",
    "            #2d condiiton\n",
    "            cond0 = self.h0_prev(prev_bar)          #[batch,16,1,16]\n",
    "            cond1 = self.h1_prev(cond0)             #[batch,16,1,8]\n",
    "            cond2 = self.h2_prev(cond1)             #[batch,16,1,4]\n",
    "            cond3 = self.h3_prev(cond2)             #[batch,16,1,2]\n",
    "\n",
    "            #single cond_1d size =[n,1], batch_cond_1d size = [batch_size,n]\n",
    "\n",
    "            input = torch.cat((z,cond_1d), dim=1)   #[batch_size, input_size+cond_1d_size]\n",
    "\n",
    "            h0 = self.ff1(input)                    #[batch,1024]\n",
    "            h0 = torch.cat((h0,cond_1d), dim=1)     #[batch,1024+cond_1d_size]\n",
    "\n",
    "            h1 = self.ff2(h0)                       #[batch,256]\n",
    "            h1 = h1.reshape(batch_size, 128, 1, 2)  #[batch,128,1,2]\n",
    "            h1 = conv_cond_concat(h1,cond_1d)       #[batch,128+cond_1d_size,1,2]\n",
    "            h1 = conv_prev_concat(h1,cond3)         #[batch,128+cond_1d_size+16,1,2]\n",
    "\n",
    "            h2 = self.cnn1(h1)                      #[batch,128,1,4]\n",
    "            h2 = conv_cond_concat(h2,cond_1d)       #[batch,128+cond_1d_size,1,4]\n",
    "            h2 = conv_prev_concat(h2,cond2)         #[batch,128+cond_1d_size+16,1,4]\n",
    "\n",
    "            h3 = self.cnn2(h2)                      #[batch,128,1,8]\n",
    "            h3 = conv_cond_concat(h3,cond_1d)       #[batch,128+cond_1d_size,1,8]\n",
    "            h3 = conv_prev_concat(h3,cond1)         #[batch,128+cond_1d_size+16,1,8]\n",
    "\n",
    "            h4 = self.cnn3(h3)                      #[batch,128,1,16]\n",
    "            h4 = conv_cond_concat(h4,cond_1d)       #[batch,128+cond_1d_size,1,16]\n",
    "            h4 = conv_prev_concat(h4,cond0)         #[batch,128+cond_1d_size+16,1,16]\n",
    "\n",
    "            out = self.cnn4(h4)                     #[batch,instrument_size,128,16]\n",
    "\n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4727b52",
   "metadata": {
    "id": "a4727b52"
   },
   "source": [
    "### The Discriminator\n",
    "\n",
    "The discriminator uses `Conv2d` (sampling) layers to produce a scalar output from a bar input. Start with two `Conv2d` layers that reduce the size of the input, then use two `Dense` layers. We use  the `LeakyReLU` activation for each layer, except the output layer which can use `Sigmoid` to predict true-false probability value in the [0, 1] range. Note that the activation is included in the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4e5cae21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinibatchDiscrimination(nn.Module):\n",
    "    def __init__(self, in_features, out_features, kernel_dim):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.kernel_dim = kernel_dim\n",
    "        self.T = nn.Parameter(torch.randn(in_features, out_features, kernel_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is batch_sizexA\n",
    "        # T is AxBxC\n",
    "        matrices = x @ self.T.view(self.in_features, -1)                # matrix moltiplication, result shape: [batch_size, B*C]\n",
    "        matrices = matrices.view(-1, self.out_features, self.kernel_dim)    #M shape [batch, B, C]\n",
    "\n",
    "        # compute L1 distances between samples\n",
    "        M = matrices.unsqueeze(0)  # [1,batch,B,C]\n",
    "        M_T = M.permute(1, 0, 2, 3)  # [batch,1,B,C]\n",
    "        norm = torch.abs(M - M_T).sum(3)  # first broadcast [batch,batch,B,C], then [batch,batch,B]\n",
    "        cbij = torch.exp(-norm)\n",
    "        o_b = cbij.sum(0)   # [batch,B], if j !=0 i in teh sum then subtract self distance (cbij.sum(0) - 1)\n",
    "\n",
    "        x = torch.cat([x, o_b], 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6646d974",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1752583243006,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "6646d974"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, cond_1d_size, instrument_size=1, mini_size=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.instrument_size = instrument_size\n",
    "        self.cond1d_dim = cond_1d_size\n",
    "\n",
    "        #as said in the DCGAN paper always batchnorm in the discriminator layers excluded the first layer\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(2*instrument_size+cond_1d_size, 32, kernel_size=(128,2), stride=(2,2), padding=0),        #[batch,32,1,8]\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        #+condition [batch,14+cond_1d_size,1,8]\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv2d(32+cond_1d_size, 77, kernel_size=(1,4), stride=2, padding=0),                             #[batch,77,1,3]\n",
    "            #Adding residual block\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        self.ffnn1 = nn.Sequential(\n",
    "             #+condition [batch,231+cond_1d_size]\n",
    "            nn.Linear(231+cond_1d_size, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        self.minibatch = MinibatchDiscrimination(in_features=1024, out_features=mini_size,kernel_dim=5)\n",
    "\n",
    "        #+condition [batch,1024+mini_size+cond_1d_size]\n",
    "        self.ffnn2 = nn.Linear(1024+cond_1d_size+mini_size, 1)      #no sigmoid activation function because it is already in the definition of the cross entropy loss function\n",
    "\n",
    "\n",
    "    def forward(self, x, prev_bar, cond_1d):\n",
    "        input = conv_cond_concat(x,cond_1d)         #[batch,instrument_size+cond_1d_size,128,16]\n",
    "        input = conv_prev_concat(input,prev_bar)    #[batch,2*instrument_size+cond_1d_size,128,16]\n",
    "\n",
    "        h0 = self.cnn1(input)                       #[batch,14,1,8]\n",
    "        fm = h0\n",
    "        h0 = conv_cond_concat(h0, cond_1d)          #[batch,14+cond_1d_size,1,8]\n",
    "\n",
    "        h1 = self.cnn2(h0)                          #[batch,77,1,3]\n",
    "        h1 = torch.flatten(h1, 1)                   #[batch,77*3*1]\n",
    "        h1 = torch.cat((h1,cond_1d),dim=1)          #[batch,231+cond_1d_size]\n",
    "\n",
    "        h2 = self.ffnn1(h1)                         #[batch,1024]\n",
    "        h2 = self.minibatch(h2)                     #[batch,1024+mini_size]\n",
    "        h2 = torch.cat((h2,cond_1d),dim=1)          #[batch,1024+mini_size+cond_1d_size]\n",
    "\n",
    "        h3 = self.ffnn2(h2)                         #[batch,1]\n",
    "        h3_sigmoid = torch.sigmoid(h3)\n",
    "\n",
    "\n",
    "        return h3_sigmoid, h3, fm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d02a387",
   "metadata": {
    "id": "8d02a387"
   },
   "source": [
    "### Weights initialization\n",
    "\n",
    "Is this ok?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9237a67a",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752583243006,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "9237a67a"
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.2)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9059e917",
   "metadata": {
    "id": "9059e917"
   },
   "source": [
    "### Creation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "64e61f6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1752583243012,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "64e61f6a",
    "outputId": "8b8629be-30e1-4679-fc01-f66e513213bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (ff1): Sequential(\n",
       "    (0): Linear(in_features=102, out_features=1024, bias=True)\n",
       "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (ff2): Sequential(\n",
       "    (0): Linear(in_features=1026, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (cnn1): Sequential(\n",
       "    (0): ConvTranspose2d(146, 128, kernel_size=(1, 2), stride=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (cnn2): Sequential(\n",
       "    (0): ConvTranspose2d(146, 128, kernel_size=(1, 2), stride=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (cnn3): Sequential(\n",
       "    (0): ConvTranspose2d(146, 128, kernel_size=(1, 2), stride=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (cnn4): Sequential(\n",
       "    (0): ConvTranspose2d(146, 1, kernel_size=(128, 1), stride=(2, 1), bias=False)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       "  (h0_prev): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(128, 1), stride=(2, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (h1_prev): Sequential(\n",
       "    (0): Conv2d(16, 16, kernel_size=(1, 2), stride=(2, 2))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (h2_prev): Sequential(\n",
       "    (0): Conv2d(16, 16, kernel_size=(1, 2), stride=(2, 2))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (h3_prev): Sequential(\n",
       "    (0): Conv2d(16, 16, kernel_size=(1, 2), stride=(2, 2))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if Mono:\n",
    "  generator = Generator(input_size=100, cond_1d_size=2, instrument_size=1, n_hlayers=128)\n",
    "else:\n",
    "  generator = Generator(input_size=100, cond_1d_size=5, instrument_size=4, n_hlayers=128)\n",
    "generator.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "307a37f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1752583243021,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "307a37f6",
    "outputId": "308c1fd6-2907-45c4-b81d-02d6fe727ed4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (cnn1): Sequential(\n",
       "    (0): Conv2d(4, 32, kernel_size=(128, 2), stride=(2, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (cnn2): Sequential(\n",
       "    (0): Conv2d(34, 77, kernel_size=(1, 4), stride=(2, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (ffnn1): Sequential(\n",
       "    (0): Linear(in_features=233, out_features=1024, bias=True)\n",
       "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (minibatch): MinibatchDiscrimination()\n",
       "  (ffnn2): Linear(in_features=1126, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if Mono:\n",
    "  discriminator = Discriminator(cond_1d_size=2, instrument_size=1)\n",
    "else:\n",
    "  discriminator = Discriminator(cond_1d_size=5, instrument_size=4)\n",
    "discriminator.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a4dac3",
   "metadata": {
    "id": "d6a4dac3"
   },
   "source": [
    "### Dimension testing\n",
    "\n",
    "Produce a noise vector of size `[10, 100]`, a noise 1d condition vector of size `[10, 15]`, and a noise 2d condition tensor of size `[10, 1, 128,16]`. Note that we need a 1d and a 2d contions for each batch input. Then we use the (as yet **untrained**) generator to create an image of expected output shape $[10,1,128,16]$.\n",
    "\n",
    "Then use the (yet **untrained**) discriminator to classify the generated images as real or fake. The model will be trained to output the probability that the image is real in the first output component, thus we expect an output vector of size `[10, 1]` with $x_i \\in [0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4075ff07",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1752583243043,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "4075ff07",
    "outputId": "f94b2760-d3c8-46a3-c40b-95a04dccc008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100])\n",
      "torch.Size([10, 1, 128, 16])\n",
      "tensor([[0.4683],\n",
      "        [0.4361],\n",
      "        [0.4983],\n",
      "        [0.7608],\n",
      "        [0.5469],\n",
      "        [0.3173],\n",
      "        [0.5394],\n",
      "        [0.7076],\n",
      "        [0.6880],\n",
      "        [0.6488]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "############################ input (batch_size=10, vector_size=100) ###############################\n",
    "noise = torch.normal(0, 1, [10, 100])\n",
    "print(noise.shape)\n",
    "############################ conditions ###############################\n",
    "if Mono:\n",
    "  cond_1d = torch.normal(0,1,[10,2])\n",
    "  prev_bar = torch.normal(0, 1, [10, 1, 128, 16])\n",
    "else:\n",
    "  cond_1d = torch.normal(0,1,[10,5])\n",
    "  prev_bar = torch.normal(0, 1, [10, 4, 128, 16])\n",
    "\n",
    "\n",
    "############################ generator ###############################\n",
    "generated_bar = generator(noise, prev_bar, cond_1d, batch_size=10).detach()\n",
    "print(generated_bar.shape)\n",
    "############################ discriminator ###############################\n",
    "decision, __, __= discriminator(generated_bar, prev_bar, cond_1d)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cf78a3",
   "metadata": {
    "id": "26cf78a3"
   },
   "source": [
    "### Discriminator loss\n",
    "\n",
    "This method quantifies how well the discriminator is able to distinguish real images from fakes. It compares the discriminator's predictions on real images to an array of 1s, and the discriminator's predictions on fake (generated) images to an array of 0s.\n",
    "The discriminator loss is of the form:\n",
    "\n",
    "$\\frac{1}{m}\\sum_{i=1}^{m}-[\\log D(\\boldsymbol{x}^{(i)}) +\\log(1-D(G(\\boldsymbol{z}^{(i)})))]$\n",
    "\n",
    "We inplement one-sided label smoothing to penalize self confidence and imporve the convergence of the training. Thus we substitute the discriminator's predictions on real images to an array of 1s with an array of (1-$\\alpha$)s and the loss function becomes:\n",
    "\n",
    "$\\frac{1}{m}\\sum_{i=1}^{m}-[(1-\\alpha) \\log D(\\boldsymbol{x}^{(i)}) +\\alpha \\log (1-D(\\boldsymbol{x}^{(i)}))+\\log(1-D(G(\\boldsymbol{z}^{(i)})))]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fa9329bd",
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1752583243086,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "fa9329bd"
   },
   "outputs": [],
   "source": [
    "cross_entropy = nn.BCEWithLogitsLoss()\n",
    "MSE=nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "778a6afc",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1752583243092,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "778a6afc"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output, device, alpha=0.1):\n",
    "\n",
    "    #real_targets = torch.ones_like(real_output, device=device)                 #no label smoothing -> True output expected output is 1\n",
    "    real_targets = torch.full_like(real_output, 1.0 - alpha, device=device)     #one side label smoothing to penalize self confidence\n",
    "    fake_targets = torch.zeros_like(fake_output, device=device)                 #no label smoothing -> Fake output expected output is 0\n",
    "\n",
    "    real_loss = cross_entropy(real_output, real_targets)\n",
    "    fake_loss = cross_entropy(fake_output, fake_targets)\n",
    "\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04bd362",
   "metadata": {
    "id": "f04bd362"
   },
   "source": [
    "### Generator loss\n",
    "\n",
    "The generator's loss quantifies how well it was able to trick the discriminator. Intuitively, if the generator is performing well, the discriminator will classify the fake images as real (or 1).\n",
    "The generator loss is of the form:\n",
    "\n",
    "$\\frac{1}{m}\\sum_{i=1}^{m}\\log(1-D(G(\\boldsymbol{z}^{(i)})))$\n",
    "\n",
    "However this loss has some convergence issues due to vanishing gradients. So instead we use the following loss which has the same trend but stronger gradient when the discriminator is too good at recognizing fake samples.\n",
    "\n",
    "$\\frac{1}{m}\\sum_{i=1}^{m}-\\log(D(G(\\boldsymbol{z}^{(i)})))$\n",
    "\n",
    "Which is the Binary crossentropy between $D(G(\\boldsymbol{z}^{(i)}))$ and the probability distribution that has $y^{(i)} = 1 \\forall i$, i.e. we are forcing the generator to produce samples that will make the discriminator predict that fake samples are real.\n",
    "\n",
    "Moreover we add a regularizer term so-called feature matching such that the distributions of the real and generated data are enforced to be close.\n",
    "\n",
    "$\\lambda_1 ||E_{x \\sim p(x)} [x] - E_{z\\sim p(z)} [G(z)] ||^2 + \\lambda_2 ||E_{x \\sim p(x)} [f(x)] - E_{z \\sim p(z)} [f(G(z))] ||^2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "367712ab",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1752583243102,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "367712ab"
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output, real_bar, fake_bar, real_f, fake_f, device, lambda1=0.05, lambda2=0.005):\n",
    "\n",
    "    gen_loss = cross_entropy(fake_output, torch.ones_like(fake_output, device=device))\n",
    "\n",
    "    mean_real = torch.mean(real_bar, dim=0)\n",
    "    mean_fake = torch.mean(fake_bar, dim=0)\n",
    "    l2_data = MSE(mean_real, mean_fake)\n",
    "\n",
    "    mean_real_feat = torch.mean(real_f, dim=0)\n",
    "    mean_fake_feat = torch.mean(fake_f, dim=0)\n",
    "    l2_feat = MSE(mean_real_feat, mean_fake_feat)\n",
    "\n",
    "    return gen_loss+lambda1*l2_data+lambda2*l2_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873c39af",
   "metadata": {
    "id": "873c39af"
   },
   "source": [
    "### Optimizers\n",
    "\n",
    "With DCGAN the training is very diffuclt so we decide to use Adam optimizer as suggested by the paper. Note that with Adam we use both momentum and RMSprop to normalized velocities. Discriminator and generator need two different optimizers (conditioner is included in the generator training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e3bc9be6",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1752583243104,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "e3bc9be6"
   },
   "outputs": [],
   "source": [
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "gen_opt = optim.Adam(generator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "dis_opt = optim.Adam(discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a476d",
   "metadata": {
    "id": "5c2a476d"
   },
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b61b71e9",
   "metadata": {
    "executionInfo": {
     "elapsed": 198060,
     "status": "ok",
     "timestamp": 1752583441164,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "b61b71e9"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "noise_dim = 100\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "if Mono: Data = MonophonicDataset(Instruments=['Piano'])\n",
    "else: Data = PolyphonicDataset(Genre = ['rock'])\n",
    "dataloader = DataLoader(Data, BATCH_SIZE, shuffle=True, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "y8_9TtV0iTzs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1752583441172,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "y8_9TtV0iTzs",
    "outputId": "2b5556fa-460e-460b-85b3-b4d65466b517"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def train_step(bars, cond_1d, prev_bar, generator, discriminator, batch_size, noise_dim, device, dis_opt, gen_opt):\\n    noise = torch.randn([batch_size, noise_dim], device=device)*2\\n\\n    # Generate images\\n    generated_bars = generator(noise, prev_bar, cond_1d, batch_size)\\n\\n    # --- Discriminator training ---\\n    disc_losses = []\\n    #Train the discriminator 4 times\\n    for _ in range(2):\\n        # Forward pass (real + fake)\\n        real_output, real_D, _ = discriminator(bars, prev_bar, cond_1d)\\n        fake_output, fake_D, _ = discriminator(generated_bars.detach(), prev_bar, cond_1d)\\n\\n        # Compute and backpropagate loss\\n        disc_loss = discriminator_loss(real_D, fake_D, device)\\n        discriminator.zero_grad()\\n        disc_loss.backward()\\n        dis_opt.step()\\n        disc_losses.append(disc_loss.item())\\n\\n    # --- Generator training ---\\n    _, fake_D, fake_fm = discriminator(generated_bars, prev_bar, cond_1d)\\n    with torch.no_grad():  # No need for real features' gradients\\n        _, real_D, real_fm = discriminator(bars, prev_bar, cond_1d)\\n\\n    gen_loss = generator_loss(fake_D, bars, generated_bars, real_fm, fake_fm, device)\\n    generator.zero_grad()\\n    gen_loss.backward()\\n    gen_opt.step()\\n\\n    return gen_loss, sum(disc_losses) / len(disc_losses)\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def train_step(bars, cond_1d, prev_bar, generator, discriminator, batch_size, noise_dim, device, dis_opt, gen_opt):\n",
    "    noise = torch.randn([batch_size, noise_dim], device=device)*2\n",
    "\n",
    "    # Generate images\n",
    "    generated_bars = generator(noise, prev_bar, cond_1d, batch_size)\n",
    "\n",
    "    # --- Discriminator training ---\n",
    "    disc_losses = []\n",
    "    #Train the discriminator 4 times\n",
    "    for _ in range(2):\n",
    "        # Forward pass (real + fake)\n",
    "        real_output, real_D, _ = discriminator(bars, prev_bar, cond_1d)\n",
    "        fake_output, fake_D, _ = discriminator(generated_bars.detach(), prev_bar, cond_1d)\n",
    "\n",
    "        # Compute and backpropagate loss\n",
    "        disc_loss = discriminator_loss(real_D, fake_D, device)\n",
    "        discriminator.zero_grad()\n",
    "        disc_loss.backward()\n",
    "        dis_opt.step()\n",
    "        disc_losses.append(disc_loss.item())\n",
    "\n",
    "    # --- Generator training ---\n",
    "    _, fake_D, fake_fm = discriminator(generated_bars, prev_bar, cond_1d)\n",
    "    with torch.no_grad():  # No need for real features' gradients\n",
    "        _, real_D, real_fm = discriminator(bars, prev_bar, cond_1d)\n",
    "\n",
    "    gen_loss = generator_loss(fake_D, bars, generated_bars, real_fm, fake_fm, device)\n",
    "    generator.zero_grad()\n",
    "    gen_loss.backward()\n",
    "    gen_opt.step()\n",
    "\n",
    "    return gen_loss, sum(disc_losses) / len(disc_losses)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1216184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LossPenalty(GenBars, ActualLoss):\n",
    "\n",
    "   mean = GenBars.mean().item()\n",
    "   BinaryBar = (GenBars > mean).float().squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "   ActiveNotes = np.sum(BinaryBar, axis = 0)\n",
    "\n",
    "   Notes = (ActiveNotes > 5)\n",
    "   Sums = np.sum(Notes)\n",
    "\n",
    "   #PenaltyTerm on the loss if more that 5 notes are active at the same time\n",
    "   PenaltyTerm = ActualLoss + 0.05*ActualLoss*Sums\n",
    "\n",
    "   return PenaltyTerm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "Y8NU6yHm9LFZ",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1752583441187,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "Y8NU6yHm9LFZ"
   },
   "outputs": [],
   "source": [
    "def train_step(bars, cond_1d, prev_bar, generator, discriminator, batch_size,\n",
    "               noise_dim, device, dis_opt, gen_opt):\n",
    "    # --- Ensure all tensors are on the correct device ---\n",
    "    bars = bars.to(device)\n",
    "    cond_1d = cond_1d.to(device)\n",
    "    prev_bar = prev_bar.to(device)\n",
    "\n",
    "    # --- Discriminator training ---\n",
    "    noise = torch.randn([batch_size, noise_dim], device=device)\n",
    "\n",
    "    prev_bar = prev_bar + torch.randn_like(prev_bar) * 0.05\n",
    "    prev_bar = torch.clamp(prev_bar, 0, 1)\n",
    "\n",
    "    # Generate fake samples\n",
    "    generated_bars = generator(noise, prev_bar, cond_1d, batch_size)\n",
    "\n",
    "    binary_bar = (generated_bars > 0.5).float()    \n",
    "\n",
    "    # Forward pass (real + fake)\n",
    "    real_output, real_D, _ = discriminator(bars, prev_bar, cond_1d)\n",
    "    fake_output, fake_D, _ = discriminator(binary_bar, prev_bar, cond_1d)\n",
    "\n",
    "    # Discriminator loss\n",
    "    disc_loss = discriminator_loss(real_D, fake_D, device)\n",
    "    discriminator.zero_grad()\n",
    "    disc_loss.backward()\n",
    "    dis_opt.step()\n",
    "\n",
    "    # --- Generator training (2 steps) ---\n",
    "    gen_losses = []\n",
    "    for _ in range(2):  # Consistent 2:1 update ratio\n",
    "        noise = torch.randn([batch_size, noise_dim], device=device)\n",
    "        generated_bars = generator(noise, prev_bar, cond_1d, batch_size) \n",
    "        _, fake_D, fake_fm = discriminator(generated_bars, prev_bar, cond_1d)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, real_D, real_fm = discriminator(bars, prev_bar, cond_1d)\n",
    "\n",
    "        gen_loss = generator_loss(fake_D, bars, generated_bars, real_fm, fake_fm, device)\n",
    "\n",
    "        #Penalty_loss = LossPenalty(generated_bar, gen_loss.item())\n",
    "\n",
    "        generator.zero_grad()\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "        gen_losses.append(gen_loss.item())\n",
    "\n",
    "    return sum(gen_losses) / len(gen_losses), disc_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3313e656",
   "metadata": {
    "id": "3313e656"
   },
   "source": [
    "supponendo che nel dataloader ogni dato sia una bar + la preavious bar + 1d condition sugli strumenti utilizzati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a670270f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "executionInfo": {
     "elapsed": 282,
     "status": "error",
     "timestamp": 1752583441471,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "a670270f",
    "outputId": "75d763e9-453e-4ca2-9f26-08f62701f198"
   },
   "outputs": [],
   "source": [
    "gloss = []\n",
    "dloss = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    start = time.time()\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    gen_losses = []\n",
    "    disc_losses = []\n",
    "    print('#################')\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "\n",
    "    iterator = tqdm(dataloader)\n",
    "    for bar_batch, prev_bar_batch, instrument_batch in iterator:\n",
    "        bar_batch = bar_batch.to(dtype=torch.float32, device=device)\n",
    "        prev_bar_batch = prev_bar_batch.to(dtype=torch.float32, device=device)\n",
    "        instrument_batch = instrument_batch.to(dtype=torch.float32, device=device)\n",
    "        #instrument_batch = torch.zeros_like(cond_1d)\n",
    "\n",
    "        if Mono:\n",
    "            bar_batch = bar_batch.unsqueeze(1)\n",
    "            prev_bar_batch=prev_bar_batch.unsqueeze(1)\n",
    "\n",
    "        gen_loss, disc_loss = train_step(bar_batch, instrument_batch, prev_bar_batch, generator, discriminator,\n",
    "                                         BATCH_SIZE, noise_dim, device, dis_opt, gen_opt)\n",
    "        gen_losses.append(gen_loss)\n",
    "        disc_losses.append(disc_loss)\n",
    "\n",
    "        iterator.set_description('Discriminator loss: {}, Generator loss: {}'.format(disc_loss, gen_loss))\n",
    "\n",
    "    gloss.append(np.mean(gen_losses))\n",
    "    dloss.append(np.mean(disc_losses))\n",
    "    #print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "    print(f'dLoss: {dloss[-1]}, gLoss: {gloss[-1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60125f78",
   "metadata": {
    "id": "60125f78"
   },
   "source": [
    "### Weights and loss analysis\n",
    "\n",
    "First let's plot the 2 losses over the epochs, if it works correctly the generator loss would have to decrease and the discriminator one would have to increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a427ac8",
   "metadata": {
    "executionInfo": {
     "elapsed": 200162,
     "status": "aborted",
     "timestamp": 1752583441516,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "1a427ac8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(gloss, label='Generator loss')\n",
    "plt.plot(dloss, label='Discriminator loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afdace0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 50/50 [00:11<00:00,  4.27it/s]\n"
     ]
    }
   ],
   "source": [
    "from Preprocessing import *\n",
    "from PolyphonicPreprocessing import *\n",
    "\n",
    "TEMPO_MIN, TEMPO_MAX = 60, 200  # Typical tempo range\n",
    "PROGRAM_MIN, PROGRAM_MAX = 1, 128  # MIDI program range\n",
    "\n",
    "def NormCond(tempo, programs, Mono):\n",
    "\n",
    "   tempo_norm = (tempo - TEMPO_MIN) / (TEMPO_MAX - TEMPO_MIN)\n",
    "    \n",
    "   if Mono:\n",
    "      programs_norm = (programs - PROGRAM_MIN) / (PROGRAM_MAX - PROGRAM_MIN)\n",
    "      return [tempo_norm] + [programs_norm]\n",
    "   else:\n",
    "      programs_norm = [(p - PROGRAM_MIN) / (PROGRAM_MAX - PROGRAM_MIN) for p in programs]\n",
    "      return [tempo_norm] + programs_norm\n",
    "    \n",
    "   \n",
    "if Mono:\n",
    "   Dataset = PreProcessing(nDir = 50)\n",
    "   \n",
    "else:\n",
    "   Dataset = PolyphonicPreProcessing(nDir = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc84211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026114508509635925 0.12707994878292084\n",
      "0.03844175860285759 0.1669192612171173\n",
      "0.040052711963653564 0.1776416152715683\n",
      "0.037479158490896225 0.17174996435642242\n",
      "0.03553536534309387 0.1665717512369156\n",
      "0.038596607744693756 0.17486374080181122\n",
      "0.039276301860809326 0.17695827782154083\n",
      "0.04019451513886452 0.17969770729541779\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "generator.eval().to(device)\n",
    "\n",
    "#bar = np.random.randint(0, 100)\n",
    "bar = 10\n",
    "\n",
    "if Mono:\n",
    "   Instrument = 'Piano'\n",
    "   prev_bar = Dataset[Instrument][bar]['Bars'][0].to_dense().float().to(device)\n",
    "   InstrumentCode = Dataset[Instrument][bar]['Program']\n",
    "   Tempo = Dataset[Instrument][bar]['Tempo'][0]\n",
    "\n",
    "else:\n",
    "   Genre = 'rock'\n",
    "   prev_bar = Dataset[Genre][bar]['Bars'][0].to_dense().float().to(device)\n",
    "   InstrumentCode = Dataset[Genre][bar]['Program'][0]\n",
    "   Tempo = Dataset[Genre][bar]['Tempo'][0]\n",
    "\n",
    "cond_1d = torch.tensor([NormCond(Tempo, InstrumentCode, Mono)], dtype= torch.float32, device = device)\n",
    "Bars = []\n",
    "Bars.append(prev_bar)\n",
    "\n",
    "if Mono:\n",
    "   prev_bar = prev_bar.unsqueeze(0).unsqueeze(0) \n",
    "else:\n",
    "   prev_bar = prev_bar.unsqueeze(0)\n",
    "\n",
    "\n",
    "for i in range(8):\n",
    "   noise = torch.rand([1, 100], device=device)*0.2\n",
    "\n",
    "   #print(np.mean(np.array(noise)))\n",
    "\n",
    "   with torch.no_grad():\n",
    "      generated_bar = generator(noise, prev_bar, cond_1d, 1)\n",
    "\n",
    "   mean = generated_bar.mean().item()\n",
    "   binary_bar = (generated_bar > 0.5).float()\n",
    "   if Mono: Bars.append(binary_bar.squeeze(0).squeeze(0).cpu().numpy()) \n",
    "   else:  Bars.append(binary_bar.squeeze(0).cpu().numpy()) \n",
    "   print(mean, generated_bar.std().item())\n",
    "   prev_bar = binary_bar.detach()\n",
    "\n",
    "\n",
    "\n",
    "if Mono:\n",
    "   ConcBars = np.concatenate(Bars, axis = 1)\n",
    "   MonoBarsToMIDI(ConcBars, title='Monotest', Instrument=InstrumentCode)\n",
    "\n",
    "else:\n",
    "   PolyConcBars = np.concatenate(Bars, axis = 2)\n",
    "   PolyBarsToMIDI(PolyConcBars, title='Polytest', Instrument=InstrumentCode)\n",
    "\n",
    "\n",
    "print(InstrumentCode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f70a8b",
   "metadata": {
    "id": "51f70a8b"
   },
   "source": [
    "Save networks and optimizers states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c479e2c",
   "metadata": {
    "executionInfo": {
     "elapsed": 200163,
     "status": "aborted",
     "timestamp": 1752583441519,
     "user": {
      "displayName": "Francesco",
      "userId": "10872488784171972787"
     },
     "user_tz": -120
    },
    "id": "4c479e2c"
   },
   "outputs": [],
   "source": [
    "#torch.save(discriminator.state_dict(), 'discriminator_parameters.torch')\n",
    "torch.save(generator.state_dict(), 'generator_parameters.torch')\n",
    "print('Saved Model')\n",
    "\n",
    "#torch.save(dis_opt.state_dict(), 'dis_opt_state.torch')\n",
    "torch.save(gen_opt.state_dict(), 'gen_opt_state.torch')\n",
    "print('Saved Optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226da7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625776cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9eef31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_cond_concat(x, y):\n",
    "    \"\"\"Concatenate conditioning vector on feature map axis.\"\"\"\n",
    "    x_shapes = x.shape  #[batch,n_features,a,b]\n",
    "    y_shapes = y.shape  #[batch,n]\n",
    "    y2 = y.view(x_shapes[0],y_shapes[1],1,1)                              #[batch,n,1,1]\n",
    "    y2 = y2.expand(x_shapes[0],y_shapes[1],x_shapes[2],x_shapes[3])      #[batch,n,a,b]\n",
    "\n",
    "    return torch.cat((x, y2),dim=1)                                     #[batch,n_features+n,a,b]\n",
    "\n",
    "def conv_prev_concat(x, y):\n",
    "    \"\"\"Concatenate conditioning vector on feature map axis.\"\"\"\n",
    "    x_shapes = x.shape  #[batch,n_features,a,b]\n",
    "    y_shapes = y.shape  #[batch,16,a,b]\n",
    "    if x_shapes[2:] == y_shapes[2:]:\n",
    "        y2 = y.expand(x_shapes[0],y_shapes[1],x_shapes[2],x_shapes[3])  #[batch,16,a,b]\n",
    "\n",
    "        return torch.cat((x, y2),dim=1)                                 #[batch,n_features+16,a,b]\n",
    "\n",
    "    else:\n",
    "        print(x_shapes[2:])\n",
    "        print(y_shapes[2:])\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.2)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a78515a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, cond_1d_size, instrument_size=1, n_hlayers=128):\n",
    "            super().__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.instrument_size = instrument_size\n",
    "            self.cond1d_dim = cond_1d_size\n",
    "\n",
    "            #generator layers\n",
    "            #as said in the DCGAN paper always ReLU activation function in the generator excluded the last layer\n",
    "            #as said in the DCGAN paper always batchnorm iin the generator excluded the last layer\n",
    "            self.ff1 = nn.Sequential(\n",
    "                nn.Linear(input_size+cond_1d_size, 1024),                                                               #[batch,1024]\n",
    "                nn.BatchNorm1d(1024),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            self.ff2 = nn.Sequential(\n",
    "                nn.Linear(1024+cond_1d_size,n_hlayers*2),                                                                                    #[batch,512]\n",
    "                nn.BatchNorm1d(n_hlayers*2),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #reshape to [batch size,128,1,2]\n",
    "            # #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn1 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,4]\n",
    "                nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn2 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,8]\n",
    "                nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn3 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,16]\n",
    "                nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn4 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, instrument_size, kernel_size=(128,1), stride=(2,1), bias=False, padding=0),       #[batch,instrument_size,128,16]\n",
    "                nn.Sigmoid()\n",
    "                #Sigmoid funciotn because we want to generate the matrixes of music without velocity, i.e. only (0,1)\n",
    "                #Thus we use the sigmoid which is a smoother version of the sign function\n",
    "                )\n",
    "            #conditioner layers\n",
    "            # #as in Midinet model we use the Leaky activation funciton for the conditioner\n",
    "            self.h0_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=instrument_size, out_channels=16, kernel_size=(128,1), stride=(2,1)),                  #[batch,16,1,16]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()          #note: in the original paper leak=0.2, default leak=0.01\n",
    "                )\n",
    "            self.h1_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,8]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "            self.h2_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,4]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "            self.h3_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,2]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "\n",
    "    def forward(self, z, prev_bar, cond_1d, batch_size):\n",
    "\n",
    "            #2d condiiton\n",
    "            cond0 = self.h0_prev(prev_bar)          #[batch,16,1,16]\n",
    "            cond1 = self.h1_prev(cond0)             #[batch,16,1,8]\n",
    "            cond2 = self.h2_prev(cond1)             #[batch,16,1,4]\n",
    "            cond3 = self.h3_prev(cond2)             #[batch,16,1,2]\n",
    "\n",
    "            #single cond_1d size =[n,1], batch_cond_1d size = [batch_size,n]\n",
    "\n",
    "            input = torch.cat((z,cond_1d), dim=1)   #[batch_size, input_size+cond_1d_size]\n",
    "\n",
    "            h0 = self.ff1(input)                    #[batch,1024]\n",
    "            h0 = torch.cat((h0,cond_1d), dim=1)     #[batch,1024+cond_1d_size]\n",
    "\n",
    "            h1 = self.ff2(h0)                       #[batch,256]\n",
    "            h1 = h1.reshape(batch_size, 128, 1, 2)  #[batch,128,1,2]\n",
    "            h1 = conv_cond_concat(h1,cond_1d)       #[batch,128+cond_1d_size,1,2]\n",
    "            h1 = conv_prev_concat(h1,cond3)         #[batch,128+cond_1d_size+16,1,2]\n",
    "\n",
    "            h2 = self.cnn1(h1)                      #[batch,128,1,4]\n",
    "            h2 = conv_cond_concat(h2,cond_1d)       #[batch,128+cond_1d_size,1,4]\n",
    "            h2 = conv_prev_concat(h2,cond2)         #[batch,128+cond_1d_size+16,1,4]\n",
    "\n",
    "            h3 = self.cnn2(h2)                      #[batch,128,1,8]\n",
    "            h3 = conv_cond_concat(h3,cond_1d)       #[batch,128+cond_1d_size,1,8]\n",
    "            h3 = conv_prev_concat(h3,cond1)         #[batch,128+cond_1d_size+16,1,8]\n",
    "\n",
    "            h4 = self.cnn3(h3)                      #[batch,128,1,16]\n",
    "            h4 = conv_cond_concat(h4,cond_1d)       #[batch,128+cond_1d_size,1,16]\n",
    "            h4 = conv_prev_concat(h4,cond0)         #[batch,128+cond_1d_size+16,1,16]\n",
    "\n",
    "            out = self.cnn4(h4)                     #[batch,instrument_size,128,16]\n",
    "\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "973a5ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU available')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('GPU not available')\n",
    "\n",
    "\n",
    "def LoadModel(Cond1D_Size, instrumentSize, Which):\n",
    "\n",
    "    Path = os.path.realpath('ModelParameters')\n",
    "\n",
    "    files = [\n",
    "        ['GenParam2.torch', 'GenState2.torch'],\n",
    "        ['Tradgenerator_parameters.torch', 'Tradgen_opt_state.torch']\n",
    "    ]\n",
    "\n",
    "    generator = Generator(input_size=100, cond_1d_size=Cond1D_Size, instrument_size=instrumentSize, n_hlayers=128)\n",
    "    generator.apply(weights_init)\n",
    "    generator.to(device)\n",
    "    # Load the state dict previously saved\n",
    "    generator_state_dict = torch.load(os.path.join(Path, files[Which][0]), map_location=torch.device('cpu'))\n",
    "    # Update the network parameters\n",
    "    generator.load_state_dict(generator_state_dict)\n",
    "\n",
    "    gen_opt = optim.Adam(generator.parameters(), lr=2e-4)\n",
    "    # Load the state dict previously saved\n",
    "    gen_opt_state_dict = torch.load(os.path.join(Path, files[Which][1]), map_location=torch.device('cpu'))\n",
    "    # Update the network parameters\n",
    "    gen_opt.load_state_dict(gen_opt_state_dict)\n",
    "\n",
    "    return generator\n",
    "\n",
    "                                                    #MOnophonic or polyphonic\n",
    "generator = LoadModel(Cond1D_Size=2, instrumentSize=1, Which=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ade17df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 50/50 [00:11<00:00,  4.41it/s]\n"
     ]
    }
   ],
   "source": [
    "from Preprocessing import *\n",
    "from PolyphonicPreprocessing import *\n",
    "\n",
    "Mono = True\n",
    "\n",
    "TEMPO_MIN, TEMPO_MAX = 60, 200  # Typical tempo range\n",
    "PROGRAM_MIN, PROGRAM_MAX = 1, 128  # MIDI program range\n",
    "\n",
    "def NormCond(tempo, programs, Mono):\n",
    "\n",
    "   tempo_norm = (tempo - TEMPO_MIN) / (TEMPO_MAX - TEMPO_MIN)\n",
    "    \n",
    "   if Mono:\n",
    "      programs_norm = (programs - PROGRAM_MIN) / (PROGRAM_MAX - PROGRAM_MIN)\n",
    "      return [tempo_norm] + [programs_norm]\n",
    "   else:\n",
    "      programs_norm = [(p - PROGRAM_MIN) / (PROGRAM_MAX - PROGRAM_MIN) for p in programs]\n",
    "      return [tempo_norm] + programs_norm\n",
    "    \n",
    "   \n",
    "if Mono:\n",
    "   Dataset = PreProcessing(nDir = 50)\n",
    "   \n",
    "else:\n",
    "   Dataset = PolyphonicPreProcessing(nDir = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5545c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0404377356171608 0.04237191006541252\n",
      "0.04056130349636078 0.038086481392383575\n",
      "0.04117608070373535 0.038293324410915375\n",
      "0.042619507759809494 0.04223497956991196\n",
      "0.040712714195251465 0.034808170050382614\n",
      "0.04187113419175148 0.03810318559408188\n",
      "0.03990750014781952 0.03623295947909355\n",
      "0.039211615920066833 0.03449992835521698\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "generator.eval().to(device)\n",
    "\n",
    "bar = np.random.randint(0, 100)\n",
    "\n",
    "if Mono:\n",
    "   Instrument = 'Piano'\n",
    "   prev_bar = Dataset[Instrument][bar]['Bars'][0].to_dense().float().to(device)\n",
    "   InstrumentCode = Dataset[Instrument][bar]['Program']\n",
    "   Tempo = Dataset[Instrument][bar]['Tempo'][0]\n",
    "\n",
    "else:\n",
    "   Genre = 'rock'\n",
    "   prev_bar = Dataset[Genre][bar]['Bars'][0].to_dense().float().to(device)\n",
    "   InstrumentCode = Dataset[Genre][bar]['Program'][0]\n",
    "   Tempo = Dataset[Genre][bar]['Tempo'][0]\n",
    "\n",
    "cond_1d = torch.tensor([NormCond(Tempo, InstrumentCode, Mono)], dtype= torch.float32, device = device)\n",
    "Bars = []\n",
    "Bars.append(prev_bar)\n",
    "\n",
    "if Mono:\n",
    "   prev_bar = prev_bar.unsqueeze(0).unsqueeze(0) \n",
    "else:\n",
    "   prev_bar = prev_bar.unsqueeze(0)\n",
    "\n",
    "\n",
    "for i in range(8):\n",
    "   noise = torch.rand([1, 100], device=device)\n",
    "\n",
    "   #print(np.mean(np.array(noise)))\n",
    "\n",
    "   with torch.no_grad():\n",
    "      generated_bar = generator(noise, prev_bar, cond_1d, 1)\n",
    "\n",
    "   mean = generated_bar.mean().item()\n",
    "   binary_bar = (generated_bar > 0.5).float()\n",
    "   if Mono: Bars.append(binary_bar.squeeze(0).squeeze(0).cpu().numpy()) \n",
    "   else:  Bars.append(binary_bar.squeeze(0).cpu().numpy()) \n",
    "   print(mean, generated_bar.std().item())\n",
    "   prev_bar = binary_bar.detach()\n",
    "\n",
    "\n",
    "\n",
    "if Mono:\n",
    "   ConcBars = np.concatenate(Bars, axis = 1)\n",
    "   MonoBarsToMIDI(ConcBars, title='Monotest1', Instrument=InstrumentCode)\n",
    "\n",
    "else:\n",
    "   PolyConcBars = np.concatenate(Bars, axis = 2)\n",
    "   PolyBarsToMIDI(PolyConcBars, title='Polytest', Instrument=InstrumentCode)\n",
    "\n",
    "\n",
    "print(InstrumentCode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96e203a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Bars[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671be27a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
