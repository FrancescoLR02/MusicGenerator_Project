{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ccc183",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pretty_midi\n",
    "import librosa\n",
    "import librosa.display\n",
    "import gc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from pympler import asizeof\n",
    "import torch.optim as optim \n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from Preprocessing import *\n",
    "#from ExtractGenre import *\n",
    "from CNN_ExtractGenre import *\n",
    "from PolyphonicPreprocessing import *\n",
    "import Util as Util\n",
    "\n",
    "import DatasetLoader as DL\n",
    "import Model as M\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "GenreMapping = {'metal': 0, 'disco': 1, 'classical': 2, 'hiphop': 3, 'jazz': 4,\n",
    "          'country': 5, 'pop': 6, 'blues': 7, 'reggae': 8, 'rock': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb100a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path = os.path.realpath('clean_midi/Eminem/Stan.mid')\n",
    "mid = mido.MidiFile(Path)\n",
    "#print(mid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3da44683",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Data \u001b[38;5;241m=\u001b[39m DL\u001b[38;5;241m.\u001b[39mMonophonicDataset(Instruments\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBass\u001b[39m\u001b[38;5;124m'\u001b[39m], EightBars\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m Bars \u001b[38;5;241m=\u001b[39m DataLoader(Data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/UniversitaÌ€/PhysicsOfData/Neural Network and Deep Learning/MusicGenerator_Project/DatasetLoader.py:15\u001b[0m, in \u001b[0;36mMonophonicDataset.__init__\u001b[0;34m(self, Instruments, EightBars)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, Instruments, EightBars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 15\u001b[0m    DS \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset_CP.pt\u001b[39m\u001b[38;5;124m'\u001b[39m, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mData \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     17\u001b[0m    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mInstruments \u001b[38;5;241m=\u001b[39m Instruments\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/serialization.py:1471\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1469\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1470\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1471\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[1;32m   1472\u001b[0m             opened_zipfile,\n\u001b[1;32m   1473\u001b[0m             map_location,\n\u001b[1;32m   1474\u001b[0m             pickle_module,\n\u001b[1;32m   1475\u001b[0m             overall_storage\u001b[38;5;241m=\u001b[39moverall_storage,\n\u001b[1;32m   1476\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[1;32m   1477\u001b[0m         )\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1479\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/serialization.py:1964\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[1;32m   1963\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[0;32m-> 1964\u001b[0m result \u001b[38;5;241m=\u001b[39m unpickler\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m   1965\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1967\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/serialization.py:1928\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1928\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m load_tensor(\n\u001b[1;32m   1929\u001b[0m         dtype, nbytes, key, _maybe_decode_ascii(location)\n\u001b[1;32m   1930\u001b[0m     )\n\u001b[1;32m   1932\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/serialization.py:1880\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1878\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_tensor\u001b[39m(dtype, numel, key, location):\n\u001b[1;32m   1879\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_guards\u001b[38;5;241m.\u001b[39mdetect_fake_mode(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1881\u001b[0m         nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[1;32m   1882\u001b[0m         storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mUntypedStorage(nbytes, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/_guards.py:972\u001b[0m, in \u001b[0;36mdetect_fake_mode\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FakeTensor, FakeTensorMode\n\u001b[1;32m    970\u001b[0m fake_modes \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 972\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;241m:=\u001b[39m TracingContext\u001b[38;5;241m.\u001b[39mtry_get():\n\u001b[1;32m    973\u001b[0m     fake_mode \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mfake_mode\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fake_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/_guards.py:713\u001b[0m, in \u001b[0;36mTracingContext.try_get\u001b[0;34m()\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtry_get\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[TracingContext]:\n\u001b[0;32m--> 713\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(_TLS, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtracing_context\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Data = DL.MonophonicDataset(Instruments=['Bass'], EightBars=True)\n",
    "Bars = DataLoader(Data, batch_size=10, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3149b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69262965",
   "metadata": {},
   "source": [
    "# 1 Instrument "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b55097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = PreProcessing(nDir = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2182d38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b3a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU available')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('GPU not available')\n",
    "\n",
    "\n",
    "def LoadModel(Cond1D_Size, instrumentSize, Which):\n",
    "\n",
    "    Path = os.path.realpath('ModelParameters')\n",
    "\n",
    "    files = [\n",
    "        ['generator_parameters.torch', 'gen_opt_state.torch'],\n",
    "        ['Polygenerator_parameters3.torch', 'Polygen_opt_state3.torch']\n",
    "    ]\n",
    "\n",
    "    generator = M.Generator(input_size=256, cond_1d_size=Cond1D_Size, instrument_size=instrumentSize, n_hlayers=256)\n",
    "    generator.apply(M.weights_init)\n",
    "    generator.to(device)\n",
    "    # Load the state dict previously saved\n",
    "    generator_state_dict = torch.load(os.path.join(Path, files[Which][0]), map_location=torch.device('cpu'))\n",
    "    # Update the network parameters\n",
    "    generator.load_state_dict(generator_state_dict)\n",
    "\n",
    "    gen_opt = optim.Adam(generator.parameters(), lr=2e-4)\n",
    "    # Load the state dict previously saved\n",
    "    gen_opt_state_dict = torch.load(os.path.join(Path, files[Which][1]), map_location=torch.device('cpu'))\n",
    "    # Update the network parameters\n",
    "    gen_opt.load_state_dict(gen_opt_state_dict)\n",
    "\n",
    "    return generator\n",
    "\n",
    "                                                    #MOnophonic or polyphonic\n",
    "generator = LoadModel(Cond1D_Size=5, instrumentSize=4, Which=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7600e9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "PolyDataset = PolyphonicPreProcessing(nDir = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02b02c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "noise = torch.randn([1, 256], device=device)\n",
    "\n",
    "Genre = 'classical'\n",
    "bar = 20\n",
    "\n",
    "prev_bar = PolyDataset[Genre][bar]['Bars'][0].to_dense().float().to(device)\n",
    "InstrumentCode = PolyDataset[Genre][bar]['Program'][0]\n",
    "Tempo = PolyDataset[Genre][bar]['Tempo'][0]\n",
    "\n",
    "#prev_bar = torch.tensor(np.random.randint(0, 1, (4, 128, 16))).float().to(device)\n",
    "\n",
    "cond_1d = torch.tensor([[Tempo] + InstrumentCode], dtype= torch.float32)\n",
    "Bars = []\n",
    "Bars.append(prev_bar)\n",
    "#If polyphonic only 1 unsqueeze\n",
    "prev_bar = prev_bar.unsqueeze(0)#.unsqueeze(0) \n",
    "\n",
    "\n",
    "for i in range(8):\n",
    "   with torch.no_grad():\n",
    "      generated_bar = generator(noise, prev_bar, cond_1d, 1)\n",
    "\n",
    "   generated_bar=generated_bar.cpu().numpy()\n",
    "   binary_bar = (generated_bar.reshape(4, 128, 16) > 0.5).astype(int)\n",
    "\n",
    "   #if i % 2 == 0:\n",
    "   #prev_bar = torch.tensor(binary_bar, dtype=torch.float32, device=device).unsqueeze(0).unsqueeze(0)\n",
    "      #prev_bar = PolyDataset[Genre][bar+i]['Bars'][0].to_dense().float().to(device).unsqueeze(0)#.unsqueeze(0) \n",
    "   prev_bar = torch.tensor(binary_bar, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "\n",
    "   Bars.append(binary_bar)\n",
    "\n",
    "\n",
    "\n",
    "#ConcBars = np.concatenate(Bars, axis = 1)\n",
    "PolyConcBars = np.concatenate(Bars, axis = 2)\n",
    "\n",
    "#MonoBarsToMIDI(ConcBars, title='test', Instrument=InstrumentCode)\n",
    "\n",
    "PolyBarsToMIDI(PolyConcBars, title='Polytest', Instrument=InstrumentCode)\n",
    "\n",
    "print(InstrumentCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd90c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "polconc = []\n",
    "for i in range(50, 54):\n",
    "   for j in range(2):\n",
    "      polconc.append(PolyDataset['rock'][i]['Bars'][j].to_dense())\n",
    "\n",
    "conc = np.concatenate(polconc, axis = 2)\n",
    "PolyBarsToMIDI(conc, title = 'True', Instrument = [33, 41, 49, 73])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f399a68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
