{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ccc183",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pretty_midi\n",
    "import librosa\n",
    "import librosa.display\n",
    "import gc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from Preprocessing import *\n",
    "from ExtractGenre import *\n",
    "\n",
    "import DatasetLoader as DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe5b0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "InputPath = os.path.realpath('YAMF/genres_original')\n",
    "\n",
    "GenreMapping = {'metal': 0, 'disco': 1, 'classical': 2, 'hiphop': 3, 'jazz': 4,\n",
    "          'country': 5, 'pop': 6, 'blues': 7, 'reggae': 8, 'rock': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cf63f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeSpectrogram(X):\n",
    "   X_min = X.min()\n",
    "   X_max = X.max()\n",
    "   return (X - X_min) / (X_max - X_min)\n",
    "\n",
    "\n",
    "def DataCNN(InputPath = os.path.realpath('YAMF/genres_original'), length = 128):\n",
    "\n",
    "   numErr = 0\n",
    "\n",
    "   TrainDataList, ValDataList, DataList = [], [], []\n",
    "   for dir in tqdm(os.listdir(InputPath)):\n",
    "      \n",
    "      DirPath = os.path.join(InputPath, dir)\n",
    "\n",
    "      if not os.path.isdir(DirPath):\n",
    "         continue\n",
    "\n",
    "      genre = GenreMapping[dir]\n",
    "\n",
    "      trainSong = 0\n",
    "      for song in os.listdir(DirPath):\n",
    "         warnings.filterwarnings('ignore')\n",
    "\n",
    "         trainSong += 1\n",
    "         SongPath = os.path.join(DirPath, song)\n",
    "\n",
    "         #Train data\n",
    "         if trainSong <= 80:\n",
    "            try:\n",
    "               y, sr = librosa.load(SongPath, sr=22050)\n",
    "               mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "               S_db = librosa.amplitude_to_db(mel_spec, ref=np.max)\n",
    "            except:\n",
    "               numErr += 1\n",
    "               continue \n",
    "\n",
    "            for _ in range(50):\n",
    "\n",
    "               rIDX = np.random.randint(0, np.shape(S_db)[1] - length)\n",
    "               indexs = np.arange(rIDX, rIDX + length)\n",
    "\n",
    "               X = S_db[:, indexs]\n",
    "\n",
    "               NormX = NormalizeSpectrogram(X)\n",
    "               TrainDataList.append((NormX, genre))\n",
    "\n",
    "         #Validation data\n",
    "         elif trainSong > 80:\n",
    "            try:\n",
    "               y, sr = librosa.load(SongPath, sr=22050)\n",
    "               mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "               S_db = librosa.amplitude_to_db(mel_spec, ref=np.max)\n",
    "            except:\n",
    "               numErr += 1\n",
    "               continue \n",
    "\n",
    "            SeparateSong = np.shape(S_db)[1] // length\n",
    "            for i in range(SeparateSong):\n",
    "\n",
    "               indexs = np.arange(i * length, i * length + length)\n",
    "               X = S_db[:, indexs]\n",
    "               NormX = NormalizeSpectrogram(X)\n",
    "               ValDataList.append((NormX, genre))\n",
    "\n",
    "   DataList.extend((TrainDataList, ValDataList))\n",
    "   return DataList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aced47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:21<00:00,  1.96s/it]\n"
     ]
    }
   ],
   "source": [
    "#DataList = DataCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f3ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('YAMF/test.pkl', 'wb') as f:\n",
    "#    pickle.dump(DataList, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f0e1e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class GenreDataset(Dataset):\n",
    "    def __init__(self, path='YAMF/test.pkl', Train = True, transform=None):\n",
    "\n",
    "        with open(path, 'rb') as f:\n",
    "            TD = pickle.load(f)\n",
    "\n",
    "        if Train:\n",
    "            self.X = np.array([TD[0][i][0] for i in range(len(TD[0]))])\n",
    "            self.Y = np.array([TD[0][i][1] for i in range(len(TD[0]))])\n",
    "\n",
    "        else:\n",
    "            self.X = np.array([TD[1][i][0] for i in range(len(TD[1]))])\n",
    "            self.Y = np.array([TD[1][i][1] for i in range(len(TD[1]))])\n",
    "\n",
    "        del TD\n",
    "        gc.collect()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        xTensor = self.X[idx]\n",
    "        yTensor = self.Y[idx]\n",
    "\n",
    "        xTensor = torch.tensor(xTensor, dtype=torch.float32).unsqueeze(0)\n",
    "        return xTensor, torch.tensor(yTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d02b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = GenreDataset(Train = True)\n",
    "valData = GenreDataset(Train = False)\n",
    "trainLoader = DataLoader(trainData, batch_size = 32, shuffle=True, num_workers=0)\n",
    "valLoader = DataLoader(valData, batch_size = 32, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90d3f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GenreCNN(nn.Module):\n",
    "    def __init__(self, n_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((4, 4)),  # Force 4×4 output\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(4*4*128, 256),      # 4*4*128 = 2048\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)  # AdaptiveAvgPool2d and Flatten are inside classifier\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5538df19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1249/1249 [01:31<00:00, 13.61it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 54.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.4736919403076172, accuracy: 0.5879999995231628\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 124/1249 [00:08<01:20, 14.05it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m iterator \u001b[38;5;241m=\u001b[39m trainLoader\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_x, batch_y \u001b[38;5;129;01min\u001b[39;00m tqdm(iterator):\n\u001b[0;32m---> 18\u001b[0m     batch_x \u001b[38;5;241m=\u001b[39m batch_x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     19\u001b[0m     batch_y \u001b[38;5;241m=\u001b[39m batch_y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     21\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model(batch_x)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = GenreCNN()\n",
    "opt = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, patience=3, factor=0.5)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "model.to(device)\n",
    "\n",
    "print(device)\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for batch_x, batch_y in tqdm(trainLoader):\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        y_pred = model(batch_x)\n",
    "        loss = loss_fn(y_pred, batch_y)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(y_pred.data, 1)\n",
    "        train_total += batch_y.size(0)\n",
    "        train_correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(trainLoader)\n",
    "    train_acc = train_correct / train_total\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        true = []\n",
    "        for batch_x, batch_y in tqdm(valLoader):\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            y_pred = model(batch_x)\n",
    "            predictions.append(y_pred)\n",
    "            true.append(batch_y)\n",
    "\n",
    "        predictions = torch.cat(predictions, axis=0)\n",
    "        true = torch.cat(true, axis=0)\n",
    "        val_loss = loss_fn(predictions, true)\n",
    "        predicted_classes = torch.argmax(predictions, dim=1)\n",
    "        val_acc = (predicted_classes == true).float().mean()\n",
    "\n",
    "    # Store metrics\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(val_loss.item())\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc.item())\n",
    "\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14380a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
