{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ccc183",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pretty_midi\n",
    "import librosa\n",
    "import librosa.display\n",
    "import gc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from Preprocessing import *\n",
    "from ExtractGenre import *\n",
    "from CNN_ExtractGenre import *\n",
    "import Util as Util\n",
    "\n",
    "import DatasetLoader as DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe5b0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "InputPath = os.path.realpath('YAMF/genres_original')\n",
    "\n",
    "GenreMapping = {'metal': 0, 'disco': 1, 'classical': 2, 'hiphop': 3, 'jazz': 4,\n",
    "          'country': 5, 'pop': 6, 'blues': 7, 'reggae': 8, 'rock': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f238c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('GenreDataset.pkl', 'rb') as f:\n",
    "#    GenreDataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58d1846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13164/13164 [00:00<00:00, 28717.90it/s]\n",
      "100%|██████████| 13164/13164 [00:30<00:00, 425.59it/s]\n",
      "100%|██████████| 13164/13164 [00:16<00:00, 785.38it/s] \n",
      "100%|██████████| 13164/13164 [00:00<00:00, 28594.27it/s]\n",
      "100%|██████████| 13164/13164 [00:17<00:00, 771.74it/s]\n",
      "100%|██████████| 13164/13164 [00:19<00:00, 683.34it/s]\n",
      "100%|██████████| 13164/13164 [00:18<00:00, 702.80it/s] \n",
      "100%|██████████| 13164/13164 [00:03<00:00, 4380.56it/s]\n",
      "100%|██████████| 13164/13164 [00:06<00:00, 1975.59it/s]\n",
      "100%|██████████| 13164/13164 [02:01<00:00, 108.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317\n"
     ]
    }
   ],
   "source": [
    "#CNN_GenreDataset = DiscriminateSongGenre(GenreDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5141157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('CNN_GenreDataset.pkl', 'rb') as f:\n",
    "#    CNN_GenreDataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6085bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('CNN_GenreDataset.pkl', 'wb') as f:\n",
    "#    pickle.dump(CNN_GenreDataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2025e375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset = torch.load('Dataset.pt', map_location='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3f7447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToBars(track, TicksPerBeat, length = 16):\n",
    "\n",
    "   #since these tracks are all 4/4\n",
    "   TicksPerBar = TicksPerBeat * 4\n",
    "   TicksPerSixteenth = TicksPerBar // length\n",
    "\n",
    "   currTime = 0\n",
    "   Note = []\n",
    "\n",
    "   for msg in track:\n",
    "      currTime += msg.time\n",
    "      if msg.type == 'note_on' and msg.velocity > 0:\n",
    "         barNumber = currTime // TicksPerBar\n",
    "         posInBar = (currTime % TicksPerBar) // TicksPerSixteenth\n",
    "   \n",
    "         if posInBar < length:\n",
    "            Note.append((barNumber, msg.note, posInBar))\n",
    "\n",
    "   Bars = {}\n",
    "   for barNum, note, pos in Note:\n",
    "      if barNum not in Bars:\n",
    "         Bars[barNum] = np.zeros((128, length), dtype = int)\n",
    "\n",
    "      #Fill the matrix with the note at it's correct position\n",
    "      Bars[barNum][note, pos] = 1\n",
    "\n",
    "   barList = []\n",
    "\n",
    "   for barNum, matrix in Bars.items():\n",
    "      if len(np.where(np.ravel(matrix) != 0)[0]) >= 5:\n",
    "         Tensor = torch.tensor(matrix, dtype=torch.int)\n",
    "         barList.append(Tensor.to_sparse())\n",
    "\n",
    "   #Keeping only 10 sequential random bars\n",
    "   # if len(barList) > 10:\n",
    "   #    maxLen = len(barList)\n",
    "   #    rIdx = np.random.randint(0, maxLen-10)\n",
    "   #    FinalBarList = barList[rIdx:rIdx+10]\n",
    "   \n",
    "   return barList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad435a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToGeneralInfo(mid, Dataset, file):\n",
    "\n",
    "   Func_Tempo = lambda t: 60_000_000 / t\n",
    "   TicksPerBeat = mid.ticks_per_beat\n",
    "\n",
    "   #defining the tempo of file (one for each)\n",
    "   if len(mid.tracks) > 0:\n",
    "      InitialTrack = mid.tracks[0]\n",
    "      for msg in InitialTrack:\n",
    "         if msg.type == 'set_tempo':\n",
    "\n",
    "            Tempo = Func_Tempo(msg.tempo)\n",
    "            break\n",
    "         else:\n",
    "            Tempo = 120\n",
    "\n",
    "   #Loop over all tracks (beside the first --> metadata)\n",
    "   for track in mid.tracks[1:]:\n",
    "      #Consider only the tracks that have an instrument in it (remove grabage)\n",
    "      HasProgramChange = any(msg.type == 'program_change' for msg in track)\n",
    "      TrackName = f'{file[:-4]}'\n",
    "\n",
    "      if HasProgramChange:\n",
    "\n",
    "         Program = [msg.program for msg in track if msg.type == 'program_change'][0]\n",
    "         Channel = [msg.channel for msg in track if msg.type == 'program_change'][0]\n",
    "\n",
    "         if Program == 0 or Channel == 10:\n",
    "            continue\n",
    "\n",
    "         #Compute the (128x16) bars matrix for each track\n",
    "         Bars = ToBars(track, TicksPerBeat)\n",
    "\n",
    "         if Bars is None or len(Bars) < 2:\n",
    "            continue\n",
    "\n",
    "         #Counts the number of pair of bars\n",
    "         numPair = [(i, i+1) for i in range(0, len(Bars)//2 - 1, 2)]\n",
    "         BarsPair = [(Bars[i], Bars[i+1]) for i in range(0, len(Bars)//2 - 1, 2)]\n",
    "\n",
    "\n",
    "         #If there is not the track in the dataset, add it\n",
    "         if TrackName not in Dataset:               \n",
    "            Dataset[TrackName] = {\n",
    "               'Bars': [],\n",
    "               'Tempo': [], \n",
    "               'Program': [], \n",
    "               'Channel': [], \n",
    "               'SongName': [],\n",
    "               'numBar': [] \n",
    "            }\n",
    "\n",
    "         #Maps the program into one instrument of the same category\n",
    "         NewProgram = Util.InstrumentMap[Program]\n",
    "         \n",
    "         #and add the information to the Dataset dictionary\n",
    "         Dataset[TrackName]['Bars'].extend(BarsPair)\n",
    "         Dataset[TrackName]['Tempo'].extend([(int(Tempo), int(Tempo)) for _ in range(0, len(Bars)//2-1, 2)])\n",
    "         Dataset[TrackName]['Program'].extend([(NewProgram, NewProgram) for _ in range(0, len(Bars)//2-1, 2)])\n",
    "         Dataset[TrackName]['Channel'].extend([(Channel, Channel) for _ in range(0, len(Bars)//2-1, 2)])\n",
    "         Dataset[TrackName]['SongName'].extend([(f'{TrackName}', f'{TrackName}') for _ in range(0, len(Bars)//2-1, 2)])\n",
    "         Dataset[TrackName]['numBar'].extend(numPair)\n",
    "\n",
    "   return Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2103c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreProcessing(nDir = 300):\n",
    "\n",
    "   Dataset = {}\n",
    "\n",
    "   InputPath = os.path.relpath('Mono_CleanMidi')\n",
    "\n",
    "   #Selecting a random number of directory\n",
    "   all_dirs = [d for d in os.listdir(InputPath) if os.path.isdir(os.path.join(InputPath, d))]\n",
    "\n",
    "   random_dirs = np.random.choice(all_dirs, nDir)\n",
    "\n",
    "   for dir in tqdm(random_dirs, desc='Preprocessing'):\n",
    "      DirPath = os.path.join(InputPath, dir)\n",
    "\n",
    "      if not os.path.isdir(DirPath):\n",
    "         continue\n",
    "\n",
    "      #Real all the file in each folder\n",
    "      for file in os.listdir(DirPath):\n",
    "\n",
    "         FilePath = os.path.join(DirPath, file)\n",
    "\n",
    "         #Cleaned monophonic: Some songs are corrupted:\n",
    "         mid = Func_CorruptedFile(FilePath, file, dir)\n",
    "\n",
    "         if mid is None:\n",
    "            continue\n",
    "\n",
    "         Dataset = ToGeneralInfo(mid, Dataset, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
