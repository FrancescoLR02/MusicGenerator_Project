{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57ccc183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pretty_midi\n",
    "import librosa\n",
    "import librosa.display\n",
    "import gc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from Preprocessing import *\n",
    "from ExtractGenre import *\n",
    "\n",
    "import DatasetLoader as DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe5b0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "InputPath = os.path.realpath('YAMF/genres_original')\n",
    "\n",
    "GenreMapping = {'metal': 0, 'disco': 1, 'classical': 2, 'hiphop': 3, 'jazz': 4,\n",
    "          'country': 5, 'pop': 6, 'blues': 7, 'reggae': 8, 'rock': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cf63f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeSpectrogram(X):\n",
    "   mean = np.mean(X)\n",
    "   std = np.std(X)\n",
    "   return (X - mean) / (std + 1e-6)\n",
    "\n",
    "\n",
    "def DataCNN(InputPath = os.path.realpath('YAMF/genres_original'), length = 256):\n",
    "\n",
    "   numErr = 0\n",
    "\n",
    "   TrainDataList, ValDataList, DataList = [], [], []\n",
    "   for dir in tqdm(os.listdir(InputPath)):\n",
    "      \n",
    "      DirPath = os.path.join(InputPath, dir)\n",
    "\n",
    "      if not os.path.isdir(DirPath):\n",
    "         continue\n",
    "\n",
    "      genre = GenreMapping[dir]\n",
    "\n",
    "      trainSong = 0\n",
    "      for song in os.listdir(DirPath):\n",
    "         warnings.filterwarnings('ignore')\n",
    "\n",
    "         trainSong += 1\n",
    "         SongPath = os.path.join(DirPath, song)\n",
    "\n",
    "         #Train data\n",
    "         if trainSong <= 80:\n",
    "            try:\n",
    "               y, sr = librosa.load(SongPath, sr=22050)\n",
    "               mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "               S_db = librosa.amplitude_to_db(mel_spec, ref=np.max)\n",
    "            except:\n",
    "               numErr += 1\n",
    "               continue \n",
    "\n",
    "            for _ in range(20):\n",
    "\n",
    "               rIDX = np.random.randint(0, np.shape(S_db)[1] - length)\n",
    "               indexs = np.arange(rIDX, rIDX + length)\n",
    "\n",
    "               X = S_db[:, indexs]\n",
    "\n",
    "               NormX = NormalizeSpectrogram(X)\n",
    "               TrainDataList.append((NormX, genre))\n",
    "\n",
    "         #Validation data\n",
    "         elif trainSong > 80:\n",
    "            try:\n",
    "               y, sr = librosa.load(SongPath, sr=22050)\n",
    "               mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "               S_db = librosa.amplitude_to_db(mel_spec, ref=np.max)\n",
    "            except:\n",
    "               numErr += 1\n",
    "               continue \n",
    "\n",
    "            \n",
    "            #SeparateSong = np.shape(S_db)[1] // length\n",
    "            #for i in range(SeparateSong):\n",
    "               # indexs = np.arange(i * length, i * length + length)\n",
    "               # X = S_db[:, indexs]\n",
    "               # NormX = NormalizeSpectrogram(X)\n",
    "               # ValDataList.append((NormX, genre))\n",
    "            \n",
    "            for _ in range(8):\n",
    "\n",
    "               rIDX = np.random.randint(0, np.shape(S_db)[1] - length)\n",
    "               indexs = np.arange(rIDX, rIDX + length)\n",
    "\n",
    "               X = S_db[:, indexs]\n",
    "\n",
    "               NormX = NormalizeSpectrogram(X)\n",
    "               ValDataList.append((NormX, genre))\n",
    "\n",
    "\n",
    "   DataList.extend((TrainDataList, ValDataList))\n",
    "   return DataList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aced47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:29<00:00,  2.72s/it]\n"
     ]
    }
   ],
   "source": [
    "#DataList = DataCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f3ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('YAMF/Test1.pkl', 'wb') as f:\n",
    "#    pickle.dump(DataList, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f0e1e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class GenreDataset(Dataset):\n",
    "    def __init__(self, path='YAMF/test.pkl', Train = True, transform=None):\n",
    "\n",
    "        with open(path, 'rb') as f:\n",
    "            TD = pickle.load(f)\n",
    "\n",
    "        if Train:\n",
    "            self.X = np.array([TD[0][i][0] for i in range(len(TD[0]))])\n",
    "            self.Y = np.array([TD[0][i][1] for i in range(len(TD[0]))])\n",
    "\n",
    "        else:\n",
    "            self.X = np.array([TD[1][i][0] for i in range(len(TD[1]))])\n",
    "            self.Y = np.array([TD[1][i][1] for i in range(len(TD[1]))])\n",
    "\n",
    "        del TD\n",
    "        gc.collect()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        xTensor = self.X[idx]\n",
    "        yTensor = self.Y[idx]\n",
    "\n",
    "        xTensor = torch.tensor(xTensor, dtype=torch.float32).unsqueeze(0)\n",
    "        return xTensor, torch.tensor(yTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d02b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainData = GenreDataset(Train = True)\n",
    "# valData = GenreDataset(Train = False)\n",
    "# trainLoader = DataLoader(trainData, batch_size = 32, shuffle=True, num_workers=0)\n",
    "# valLoader = DataLoader(valData, batch_size = 32, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c90d3f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenreCNN(nn.Module):\n",
    "    def __init__(self, n_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((4, 4)),  # Force 4×4 output\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(4*4*64, 128),      # 4*4*128 = 2048\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)  # AdaptiveAvgPool2d and Flatten are inside classifier\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5538df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.optim import Adam\n",
    "# from torch.nn import CrossEntropyLoss\n",
    "\n",
    "\n",
    "# from torch.optim import Adam\n",
    "# from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model = GenreCNN()\n",
    "# opt = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, patience=3, factor=0.5)\n",
    "# loss_fn = CrossEntropyLoss()\n",
    "# model.to(device)\n",
    "\n",
    "# print(device)\n",
    "\n",
    "# epochs = 30\n",
    "\n",
    "# train_losses = []\n",
    "# val_losses = []\n",
    "# train_accuracies = []\n",
    "# val_accuracies = []\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     print(f\"Epoch: {epoch+1}\")\n",
    "\n",
    "#     # Training phase\n",
    "#     model.train()\n",
    "#     train_loss = 0\n",
    "#     train_correct = 0\n",
    "#     train_total = 0\n",
    "\n",
    "#     for batch_x, batch_y in tqdm(trainLoader):\n",
    "#         batch_x = batch_x.to(device)\n",
    "#         batch_y = batch_y.to(device)\n",
    "\n",
    "#         y_pred = model(batch_x)\n",
    "#         loss = loss_fn(y_pred, batch_y)\n",
    "\n",
    "#         opt.zero_grad()\n",
    "#         loss.backward()\n",
    "#         opt.step()\n",
    "\n",
    "#         train_loss += loss.item()\n",
    "\n",
    "#         _, predicted = torch.max(y_pred.data, 1)\n",
    "#         train_total += batch_y.size(0)\n",
    "#         train_correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "#     avg_train_loss = train_loss / len(trainLoader)\n",
    "#     train_acc = train_correct / train_total\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         predictions = []\n",
    "#         true = []\n",
    "#         for batch_x, batch_y in tqdm(valLoader):\n",
    "#             batch_x = batch_x.to(device)\n",
    "#             batch_y = batch_y.to(device)\n",
    "#             y_pred = model(batch_x)\n",
    "#             predictions.append(y_pred)\n",
    "#             true.append(batch_y)\n",
    "\n",
    "#         predictions = torch.cat(predictions, axis=0)\n",
    "#         true = torch.cat(true, axis=0)\n",
    "#         val_loss = loss_fn(predictions, true)\n",
    "#         predicted_classes = torch.argmax(predictions, dim=1)\n",
    "#         val_acc = (predicted_classes == true).float().mean()\n",
    "\n",
    "#     # Store metrics\n",
    "#     train_losses.append(avg_train_loss)\n",
    "#     val_losses.append(val_loss.item())\n",
    "#     train_accuracies.append(train_acc)\n",
    "#     val_accuracies.append(val_acc.item())\n",
    "\n",
    "#     print(f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "#     print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533672a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34db77f4",
   "metadata": {},
   "source": [
    "### Another dataset with genre recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8673243",
   "metadata": {},
   "outputs": [],
   "source": [
    "InputPath = os.path.realpath('clean_midi')\n",
    "#GenreDict = Classifier(InputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6fddeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "GenreMapping = {'metal': 0, 'disco': 1, 'classical': 2, 'hiphop': 3, 'jazz': 4,\n",
    "          'country': 5, 'pop': 6, 'blues': 7, 'reggae': 8, 'rock': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13817aee",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m      9\u001b[0m ClassificationModel \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenreCNN_Working.pth\u001b[39m\u001b[38;5;124m'\u001b[39m, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 11\u001b[0m ClassificationModel\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Move outside for efficiency\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mCount\u001b[39m(PredictedClass):\n\u001b[1;32m     14\u001b[0m     count \u001b[38;5;241m=\u001b[39m Counter(np\u001b[38;5;241m.\u001b[39marray(np\u001b[38;5;241m.\u001b[39mravel(PredictedClass)))\u001b[38;5;241m.\u001b[39mmost_common(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from collections import Counter\n",
    "import os, numpy as np\n",
    "import pretty_midi\n",
    "import librosa\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "ClassificationModel = torch.load('GenreCNN_Working.pth', map_location=torch.device('cpu'))\n",
    "\n",
    "ClassificationModel.eval()  # Move outside for efficiency\n",
    "\n",
    "def Count(PredictedClass):\n",
    "    count = Counter(np.array(np.ravel(PredictedClass))).most_common(1)[0]\n",
    "    out = (count[0], np.round(count[1]/12, 2))\n",
    "    return out\n",
    "\n",
    "def LoadMidi(path):\n",
    "    try:\n",
    "        return pretty_midi.PrettyMIDI(path)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def ProcessFile(dir, file, input_path):\n",
    "    FilePath = os.path.join(input_path, dir, file)\n",
    "\n",
    "    midi_data = LoadMidi(FilePath)\n",
    "    if midi_data is None:\n",
    "        return (f'{dir}/{file}', None)\n",
    "\n",
    "    audio = midi_data.fluidsynth(fs= 22050, sf2_path = 'FluidR3_GM/FluidR3_GM.sf2')\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=22050, n_mels=128)\n",
    "    S_db = librosa.amplitude_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "    PredictedClass = []\n",
    "    for _ in range(12):\n",
    "        rIDX = np.random.randint(0, S_db.shape[1] - 128)\n",
    "        X = S_db[:, rIDX:rIDX+128]\n",
    "\n",
    "        NormX = NormalizeSpectrogram(X)\n",
    "        xTensor = torch.tensor(NormX, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_pred = ClassificationModel(xTensor)\n",
    "            predictions = torch.softmax(y_pred, dim=1)\n",
    "            PredictedClass.append(torch.argmax(predictions, dim=1))\n",
    "\n",
    "    del S_db\n",
    "    gc.collect()\n",
    "\n",
    "    return (f'{dir}/{file[:-4]}', Count(PredictedClass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "10c2f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def Classifier(InputPath, n_jobs=-1):  # -1 = use all CPUs\n",
    "\n",
    "    tasks = []\n",
    "    #50\n",
    "    for dir in os.listdir(InputPath)[1900:-1]:\n",
    "        DirPath = os.path.join(InputPath, dir)\n",
    "        if not os.path.isdir(DirPath):\n",
    "            continue\n",
    "        for file in os.listdir(DirPath):\n",
    "            if file.endswith('.mid'):\n",
    "                tasks.append((dir, file))\n",
    "\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(ProcessFile)(dir, file, InputPath) for dir, file in tqdm(tasks)\n",
    "    )\n",
    "\n",
    "    GenreDict = {}\n",
    "    numErr = 0\n",
    "\n",
    "    for key, result in results:\n",
    "        if result is None:\n",
    "            numErr += 1\n",
    "        else:\n",
    "            GenreDict[key] = result\n",
    "\n",
    "    print(f\"Files with errors: {numErr}\")\n",
    "    return GenreDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3a9507",
   "metadata": {},
   "outputs": [],
   "source": [
    "InputPath = os.path.realpath('clean_midi')\n",
    "\n",
    "GenreDict = Classifier(InputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da9a6d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('GenreDict9_1900-2077.npy', GenreDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e169e1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "DatasetList = glob.glob('GenreDict*')\n",
    "GenreDataset = {}\n",
    "for file in DatasetList:\n",
    "   F = np.load(file, allow_pickle=True)\n",
    "   F = F.item()\n",
    "   GenreDataset.update(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "01e13ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13148"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(GenreDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4c8ca3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('GenreDict.npy', GenreDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a431dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
