{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44d021b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pickle\n",
    "\n",
    "from Preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25daceff",
   "metadata": {},
   "source": [
    "# Cleaning data\n",
    "\n",
    "Apply the functions in Preprocessing.py to clean the midi dataset. There are multiple files that are currupted. \n",
    "For this analysis we are also going to use only Midi file with a timestamp of 4/4, like in the reference paper. This filtering is done in CleaningData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3973b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Data : 100%|██████████| 2200/2200 [10:32<00:00,  3.48it/s]\n"
     ]
    }
   ],
   "source": [
    "CleaningData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82aec08",
   "metadata": {},
   "source": [
    "# Preprocessing data:\n",
    "\n",
    "Firstly we reconstruct the database, transforming all the polyphonic audios into monophonic, keeping the information about the tracks in the midi file. It is done by keeping only the highest pitch from each polyphonic note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad18c70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recreating Database : 100%|██████████| 2079/2079 [14:22<00:00,  2.41it/s] \n"
     ]
    }
   ],
   "source": [
    "RecreateDatabase()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a33b80b",
   "metadata": {},
   "source": [
    "The input of the model has to be a 128x16 matrix as in the paper. The following function clasify the midi tracks into 7 instrumental classes:\n",
    "- String\n",
    "- Keyboard\n",
    "- Aereophone\n",
    "- Percussion\n",
    "- Voice\n",
    "- Synth\n",
    "- Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c03fd900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing : 100%|██████████| 2077/2077 [03:47<00:00,  9.12it/s]\n"
     ]
    }
   ],
   "source": [
    "Dataset = PreProcessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2403bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('Dataset.pkl', 'wb') as f:\n",
    "#    pickle.dump(Dataset, f)\n",
    "\n",
    "with open('Dataset.pkl', 'rb') as f:\n",
    "   Dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cbf8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
