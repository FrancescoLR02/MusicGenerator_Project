{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c838e959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gc\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from Preprocessing import *\n",
    "#from ExtractGenre import *\n",
    "from CNN_ExtractGenre import *\n",
    "from PolyphonicPreprocessing import *\n",
    "import Util as Util\n",
    "\n",
    "import DatasetLoader as DL\n",
    "import Model as M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d00c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, cond_1d_size, instrument_size=1, n_hlayers=128):\n",
    "            super().__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.instrument_size = instrument_size\n",
    "            self.cond1d_dim = cond_1d_size\n",
    "\n",
    "            #generator layers\n",
    "            #as said in the DCGAN paper always ReLU activation function in the generator excluded the last layer\n",
    "            #as said in the DCGAN paper always batchnorm iin the generator excluded the last layer\n",
    "            self.ff1 = nn.Sequential(\n",
    "                nn.Linear(input_size+cond_1d_size, 1024),                                                               #[batch,1024]\n",
    "                nn.BatchNorm1d(1024),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            self.ff2 = nn.Sequential(\n",
    "                nn.Linear(1024+cond_1d_size,n_hlayers*2),                                                                                    #[batch,512]\n",
    "                nn.BatchNorm1d(n_hlayers*2),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #reshape to [batch size,128,1,2]\n",
    "            # #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn1 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,4]\n",
    "                nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn2 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,8]\n",
    "                nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn3 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, n_hlayers, kernel_size=(1,2), stride=(2,2), bias=False, padding=0),           #[batch,128,1,16]\n",
    "                nn.BatchNorm2d(n_hlayers),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            #+condition [batch,128+cond_1d_size+16,1,2]\n",
    "            self.cnn4 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(n_hlayers+cond_1d_size+16, instrument_size, kernel_size=(128,1), stride=(2,1), bias=False, padding=0),       #[batch,instrument_size,128,16]\n",
    "                nn.Sigmoid()\n",
    "                #Sigmoid funciotn because we want to generate the matrixes of music without velocity, i.e. only (0,1)\n",
    "                #Thus we use the sigmoid which is a smoother version of the sign function\n",
    "                )\n",
    "            #conditioner layers\n",
    "            # #as in Midinet model we use the Leaky activation funciton for the conditioner\n",
    "            self.h0_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=instrument_size, out_channels=16, kernel_size=(128,1), stride=(2,1)),                  #[batch,16,1,16]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()          #note: in the original paper leak=0.2, default leak=0.01\n",
    "                )\n",
    "            self.h1_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,8]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "            self.h2_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,4]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "            self.h3_prev = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,2), stride=(2,2)),                                  #[batch,16,1,2]\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "\n",
    "    def forward(self, z, prev_bar, cond_1d, batch_size):\n",
    "\n",
    "            #2d condiiton\n",
    "            cond0 = self.h0_prev(prev_bar)          #[batch,16,1,16]\n",
    "            cond1 = self.h1_prev(cond0)             #[batch,16,1,8]\n",
    "            cond2 = self.h2_prev(cond1)             #[batch,16,1,4]\n",
    "            cond3 = self.h3_prev(cond2)             #[batch,16,1,2]\n",
    "\n",
    "            #single cond_1d size =[n,1], batch_cond_1d size = [batch_size,n]\n",
    "\n",
    "            input = torch.cat((z,cond_1d), dim=1)   #[batch_size, input_size+cond_1d_size]\n",
    "\n",
    "            h0 = self.ff1(input)                    #[batch,1024]\n",
    "            h0 = torch.cat((h0,cond_1d), dim=1)     #[batch,1024+cond_1d_size]\n",
    "\n",
    "            h1 = self.ff2(h0)                       #[batch,256]\n",
    "            h1 = h1.reshape(batch_size, 128, 1, 2)  #[batch,128,1,2]\n",
    "            h1 = conv_cond_concat(h1,cond_1d)       #[batch,128+cond_1d_size,1,2]\n",
    "            h1 = conv_prev_concat(h1,cond3)         #[batch,128+cond_1d_size+16,1,2]\n",
    "\n",
    "            h2 = self.cnn1(h1)                      #[batch,128,1,4]\n",
    "            h2 = conv_cond_concat(h2,cond_1d)       #[batch,128+cond_1d_size,1,4]\n",
    "            h2 = conv_prev_concat(h2,cond2)         #[batch,128+cond_1d_size+16,1,4]\n",
    "\n",
    "            h3 = self.cnn2(h2)                      #[batch,128,1,8]\n",
    "            h3 = conv_cond_concat(h3,cond_1d)       #[batch,128+cond_1d_size,1,8]\n",
    "            h3 = conv_prev_concat(h3,cond1)         #[batch,128+cond_1d_size+16,1,8]\n",
    "\n",
    "            h4 = self.cnn3(h3)                      #[batch,128,1,16]\n",
    "            h4 = conv_cond_concat(h4,cond_1d)       #[batch,128+cond_1d_size,1,16]\n",
    "            h4 = conv_prev_concat(h4,cond0)         #[batch,128+cond_1d_size+16,1,16]\n",
    "\n",
    "            out = self.cnn4(h4)                     #[batch,instrument_size,128,16]\n",
    "\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b541860d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU available')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('GPU not available')\n",
    "\n",
    "\n",
    "def LoadModel(Cond1D_Size, instrumentSize, Which):\n",
    "\n",
    "    Path = os.path.realpath('ModelParameters')\n",
    "\n",
    "    files = [\n",
    "        ['generator_parameters.torch', 'gen_opt_state.torch'],\n",
    "        ['Tradgenerator_parameters.torch', 'Tradgen_opt_state.torch']\n",
    "    ]\n",
    "\n",
    "    generator = Generator(input_size=256, cond_1d_size=Cond1D_Size, instrument_size=instrumentSize, n_hlayers=256, n_2dhlayers=16)\n",
    "    generator.apply(M.weights_init)\n",
    "    generator.to(device)\n",
    "    # Load the state dict previously saved\n",
    "    generator_state_dict = torch.load(os.path.join(Path, files[Which][0]), map_location=torch.device('cpu'))\n",
    "    # Update the network parameters\n",
    "    generator.load_state_dict(generator_state_dict)\n",
    "\n",
    "    gen_opt = optim.Adam(generator.parameters(), lr=2e-4)\n",
    "    # Load the state dict previously saved\n",
    "    gen_opt_state_dict = torch.load(os.path.join(Path, files[Which][1]), map_location=torch.device('cpu'))\n",
    "    # Update the network parameters\n",
    "    gen_opt.load_state_dict(gen_opt_state_dict)\n",
    "\n",
    "    return generator\n",
    "\n",
    "                                                    #MOnophonic or polyphonic\n",
    "generator = LoadModel(Cond1D_Size=5, instrumentSize=4, Which=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a78b4a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 50/50 [00:09<00:00,  5.04it/s]\n"
     ]
    }
   ],
   "source": [
    "PolyDataset = PolyphonicPreProcessing(nDir = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f68c043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPO_MIN, TEMPO_MAX = 60, 200  # Typical tempo range\n",
    "PROGRAM_MIN, PROGRAM_MAX = 1, 128  # MIDI program range\n",
    "\n",
    "def NormCond(tempo, programs):\n",
    "    # Normalize tempo to [0, 1]\n",
    "    tempo_norm = (tempo - TEMPO_MIN) / (TEMPO_MAX - TEMPO_MIN)\n",
    "    \n",
    "    # Normalize programs to [0, 1]\n",
    "    programs_norm = [(p - PROGRAM_MIN) / (PROGRAM_MAX - PROGRAM_MIN) for p in programs]\n",
    "    \n",
    "    return [tempo_norm] + programs_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85ecd7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03683403506875038 0.1705053746700287\n",
      "0.056664980947971344 0.21078908443450928\n",
      "0.0657743364572525 0.22884739935398102\n",
      "0.08248093724250793 0.2581101357936859\n",
      "0.05227778106927872 0.20397546887397766\n",
      "0.03434033691883087 0.1685989797115326\n",
      "0.04756946116685867 0.19547688961029053\n",
      "0.03672681748867035 0.17458079755306244\n",
      "[25, 25, 57, 89]\n"
     ]
    }
   ],
   "source": [
    "generator.eval()\n",
    "\n",
    "Genre = 'rock'\n",
    "bar = np.random.randint(0, 100)\n",
    "\n",
    "prev_bar = PolyDataset[Genre][bar]['Bars'][0].to_dense().float().to(device)\n",
    "InstrumentCode = PolyDataset[Genre][bar]['Program'][0]\n",
    "Tempo = PolyDataset[Genre][bar]['Tempo'][0]\n",
    "\n",
    "cond_1d = torch.tensor([NormCond(Tempo, InstrumentCode)], dtype= torch.float32)\n",
    "Bars = []\n",
    "Bars.append(prev_bar)\n",
    "#If polyphonic only 1 unsqueeze\n",
    "prev_bar = prev_bar.unsqueeze(0)#.unsqueeze(0) \n",
    "\n",
    "\n",
    "for i in range(8):\n",
    "   noise = torch.rand([1, 256], device=device)\n",
    "\n",
    "   #print(np.mean(np.array(noise)))\n",
    "\n",
    "   with torch.no_grad():\n",
    "      generated_bar = generator(noise, prev_bar, cond_1d, 1)\n",
    "\n",
    "   binary_bar = (generated_bar > 0.77).float()  # still a tensor\n",
    "   Bars.append(binary_bar.squeeze(0).cpu().numpy())  # only now for MIDI\n",
    "   print(generated_bar.mean().item(), generated_bar.std().item())\n",
    "   prev_bar = binary_bar.detach()\n",
    "\n",
    "   if i % 2 == 0:\n",
    "      prev_bar = binary_bar.detach()\n",
    "   else:\n",
    "      prev_bar = PolyDataset[Genre][bar + i]['Bars'][0].to_dense().float().to(device).unsqueeze(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#ConcBars = np.concatenate(Bars, axis = 1)\n",
    "PolyConcBars = np.concatenate(Bars, axis = 2)\n",
    "\n",
    "PolyBarsToMIDI(PolyConcBars, title='Polytest', Instrument=InstrumentCode)\n",
    "\n",
    "print(InstrumentCode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9d9ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
